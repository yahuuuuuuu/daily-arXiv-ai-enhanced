name: arXiv-daily-ai-enhanced

on:
  schedule:
    - cron: "30 16 * * *"
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Install dependencies
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        uv sync
        sudo apt-get update
        sudo apt-get install -y pandoc

    - name: Crawl arXiv papers
      id: crawl_step
      run: |
        source .venv/bin/activate
        today=$(date -u "+%Y-%m-%d")
        echo "开始爬取 $today 的arXiv论文..."
        if [ -f "data/${today}.jsonl" ]; then
            rm "data/${today}.jsonl"
        fi
        cd daily_arxiv
        export OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
        export OPENAI_BASE_URL=${{ secrets.OPENAI_BASE_URL }}
        export LANGUAGE="${{ vars.LANGUAGE }}"
        export CATEGORIES="${{ vars.CATEGORIES }}"
        export MODEL_NAME="${{ vars.MODEL_NAME }}"
        scrapy crawl arxiv -o ../data/${today}.jsonl
        if [ ! -f "../data/${today}.jsonl" ]; then
            echo "爬取失败"
            exit 1
        fi
        echo "crawl_date=$today" >> $GITHUB_OUTPUT
        echo "爬取完成"

    - name: Check for duplicates
      id: dedup_check
      run: |
        source .venv/bin/activate
        cd daily_arxiv
        set +e
        python daily_arxiv/check_stats.py
        dedup_exit_code=$?
        set -e
        echo "dedup_exit_code=$dedup_exit_code" >> $GITHUB_OUTPUT
        case $dedup_exit_code in
            0) echo "has_new_content=true" >> $GITHUB_OUTPUT ;;
            1) echo "has_new_content=false" >> $GITHUB_OUTPUT
               echo "skip_reason=no_new_content" >> $GITHUB_OUTPUT ;;
            2) echo "has_new_content=false" >> $GITHUB_OUTPUT
               echo "skip_reason=processing_error" >> $GITHUB_OUTPUT
               exit 1 ;;
            *) echo "has_new_content=false" >> $GITHUB_OUTPUT
               echo "skip_reason=unknown_error" >> $GITHUB_OUTPUT
               exit 1 ;;
        esac

    - name: AI Enhancement Processing
      if: steps.dedup_check.outputs.has_new_content == 'true'
      run: |
        source .venv/bin/activate
        today=${{ steps.crawl_step.outputs.crawl_date }}
        cd ai
        export OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}
        export OPENAI_BASE_URL=${{ secrets.OPENAI_BASE_URL }}
        export LANGUAGE="${{ vars.LANGUAGE }}"
        export MODEL_NAME="${{ vars.MODEL_NAME }}"
        python enhance.py --data ../data/${today}.jsonl

    - name: Convert to Markdown
      if: steps.dedup_check.outputs.has_new_content == 'true'
      run: |
        source .venv/bin/activate
        today=${{ steps.crawl_step.outputs.crawl_date }}
        cd to_md
        AI_FILE="../data/${today}_AI_enhanced_${LANGUAGE}.jsonl"
        if [ -f "$AI_FILE" ]; then
            python convert.py --data "$AI_FILE"
        else
            echo "未找到AI增强文件: $AI_FILE"
            exit 1
        fi

    - name: Update file list
      if: steps.dedup_check.outputs.has_new_content == 'true'
      run: |
        ls data/*.jsonl | sed 's|data/||' > assets/file-list.txt

    - name: Commit changes
      if: steps.dedup_check.outputs.has_new_content == 'true'
      run: |
        git config --global user.email "${{ vars.EMAIL }}"
        git config --global user.name "${{ vars.NAME }}"
        git add .
        if git diff --staged --quiet; then exit 0; fi
        git commit -m "update: $(date -u '+%Y-%m-%d') arXiv papers"

    - name: Pull latest changes and push
      if: steps.dedup_check.outputs.has_new_content == 'true'
      run: |
        git config pull.rebase true
        git config rebase.autoStash true
        for i in {1..3}; do
          if git push origin main; then break; else git pull origin main --no-edit || true; fi
        done

    # =========================
    # GitHub Pages 部署部分
    # =========================
    - name: Convert Markdown to HTML for Pages
      run: |
        mkdir -p data/html
        for f in data/*.md; do
          fname=$(basename "$f" .md)
          pandoc "$f" -s -o "data/html/$fname.html"
        done

    - name: Generate index.html
      run: |
        echo "<html><head><meta charset='utf-8'><title>每日文献</title></head><body><h1>每日文献列表</h1><ul>" > data/html/index.html
        for f in $(ls data/html/*.html | sort -r); do
          fname=$(basename $f)
          if [ "$fname" != "index.html" ]; then
            echo "<li><a href='$fname'>$fname</a></li>" >> data/html/index.html
          fi
        done
        echo "</ul></body></html>" >> data/html/index.html

    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v4
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./data/html
        publish_branch: gh-pages
