<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 68]
- [cs.LG](#cs.LG) [Total: 63]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.GR](#cs.GR) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation](https://arxiv.org/abs/2601.00504)
*Miaowei Wang,Jakub Zadrożny,Oisin Mac Aodha,Amir Vaxman*

Main category: cs.CV

TL;DR: MotionPhysics：基于自然语言提示的端到端可微分物理模拟框架，无需真实轨迹或标注视频即可推断物理参数


<details>
  <summary>Details</summary>
Motivation: 传统3D物体和材料模拟需要专家知识和耗时的物理参数调整，难以实现理想的动态行为。需要一种能从自然语言提示自动推断物理参数的方法。

Method: 1. 使用多模态大语言模型估计材料参数值（约束在合理范围内）；2. 提出可学习的运动蒸馏损失，从预训练视频扩散模型中提取鲁棒的运动先验，同时最小化外观和几何归纳偏差来指导模拟。

Result: 在30多个场景中评估，包括真实世界、人工设计和AI生成的3D物体，涵盖弹性固体、金属、泡沫、沙子、牛顿和非牛顿流体等多种材料。MotionPhysics能生成视觉逼真的动态模拟，超越现有技术并自动确定物理合理的参数。

Conclusion: MotionPhysics框架通过自然语言提示实现了物理参数的自动推断，无需真实轨迹或标注视频，为3D动态模拟提供了高效且逼真的解决方案。

Abstract: Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.

</details>


### [2] [TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051)
*Yabo Chen,Yuanzhi Liang,Jiepeng Wang,Tingxi Chen,Junfei Cheng,Zixiao Gu,Yuyang Huang,Zicheng Jiang,Wei Li,Tian Li,Weichen Li,Zuoxin Li,Guangce Liu,Jialun Liu,Junqi Liu,Haoyuan Wang,Qizhen Weng,Xuan'er Wu,Xunzhi Xiang,Xiaoyan Yang,Xin Zhang,Shiwen Zhang,Junyu Zhou,Chengcheng Zhou,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleWorld是一个实时多模态4D世界建模框架，通过生成-重建-引导范式统一视频生成、动态场景重建和长期世界记忆，实现空间、时间和物理一致性。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在实时交互、长期一致性和动态场景持久记忆方面存在局限，阻碍了它们发展成为实用的世界模型。需要一种能够统一视频生成、动态场景重建和长期记忆的框架。

Method: 提出生成-重建-引导范式：生成的视频流被连续重建为动态4D时空表示，该表示反过来指导后续生成以保持一致性。采用自回归扩散视频模型，增强宏观-微观规划（MMPL）层次规划方法，减少从帧级到段级的误差累积，并结合高效的分布匹配蒸馏（DMD）实现实时合成。

Result: TeleWorld在静态和动态世界理解、长期一致性和实时生成效率方面表现出色，实现了动态对象建模和静态场景表示在统一4D框架中的无缝集成。

Conclusion: TeleWorld是迈向实用、交互式、具备记忆功能的世界模型的重要一步，为多模态生成和具身智能提供了实用的世界建模框架。

Abstract: World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.

</details>


### [3] [It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models](https://arxiv.org/abs/2601.00090)
*Anne Harrington,A. Sophia Koepke,Shyamgopal Karthik,Trevor Darrell,Alexei A. Efros*

Main category: cs.CV

TL;DR: 通过噪声优化解决文本到图像生成模型中的模式崩溃问题，提升生成多样性


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型存在显著的模式崩溃问题，即相同文本提示下生成的图像缺乏多样性。现有方法主要通过引导机制或候选池筛选来解决，但本文探索了不同的噪声优化方向。

Method: 提出简单的噪声优化目标来缓解模式崩溃，同时保持基础模型的保真度。分析噪声的频率特性，并展示具有不同频率分布的替代噪声初始化可以改善优化和搜索过程。

Result: 实验证明噪声优化在生成质量和多样性方面都取得了优越的结果，能够有效缓解模式崩溃问题。

Conclusion: 噪声优化是一种有效解决文本到图像模型模式崩溃的方法，通过优化噪声初始化可以显著提升生成多样性而不损害模型保真度。

Abstract: Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.

</details>


### [4] [Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark](https://arxiv.org/abs/2601.00092)
*Pan Wang,Yang Liu,Guile Wu,Eduardo R. Corral-Soto,Chengjie Huang,Binbin Xu,Dongfeng Bai,Xu Yan,Yuan Ren,Xingxin Chen,Yizhe Wu,Tao Huang,Wenjun Wan,Xin Wu,Pei Zhou,Xuyang Dai,Kangbo Lv,Hongbo Zhang,Yosef Fried,Aixue Ye,Bailan Feng,Zhenyu Chen,Zhen Li,Yingcong Chen,Yiyi Liao,Bingbing Liu*

Main category: cs.CV

TL;DR: Spatial4D-Bench是一个包含约40,000个问答对的大规模4D空间智能基准测试，用于评估多模态大语言模型在18个任务上的4D空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 人类天生具有4D空间智能（感知物体随时间变化的能力），但现有空间智能基准测试规模小、多样性有限。需要评估多模态大语言模型是否能达到人类水平的4D空间智能。

Method: 创建Spatial4D-Bench基准测试，包含约40,000个问答对，涵盖18个明确定义的任务，这些任务被系统组织为六个认知类别：物体理解、场景理解、空间关系理解、时空关系理解、空间推理和时空推理。

Result: 评估了各种开源和专有的最先进多模态大语言模型，发现它们在多种4D空间推理方面存在显著局限性，如路径规划、动作识别和物理合理性推理。

Conclusion: 该基准测试为社区提供了有价值的见解，有望促进开发具有人类水平4D空间智能的更强大多模态大语言模型。

Abstract: 4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.

</details>


### [5] [A Spatially Masked Adaptive Gated Network for multimodal post-flood water extent mapping using SAR and incomplete multispectral data](https://arxiv.org/abs/2601.00123)
*Hyunho Lee,Wenwen Li*

Main category: cs.CV

TL;DR: 提出SMAGNet模型，通过自适应门控网络融合SAR和MSI数据，提升洪水淹没范围制图的准确性和对缺失数据的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 洪水期间及时准确的水域范围制图对灾害管理至关重要。虽然SAR数据是主要手段，但结合MSI数据的多模态方法能提高精度，特别是在灾后观测数据有限时。然而，如何自适应地整合部分可用的MSI数据到SAR制图流程中尚未充分探索。

Method: 提出SMAGNet（空间掩码自适应门控网络），以SAR数据为主要输入，通过特征融合整合互补的MSI数据。模型能自适应处理不同程度的MSI数据可用性，包括完全缺失的情况。

Result: 在C2S-MS Floods数据集上，SMAGNet在不同MSI数据可用性水平下均优于其他多模态深度学习模型。即使MSI数据完全缺失，其性能也与仅使用SAR数据训练的U-Net模型统计相当。

Conclusion: SMAGNet增强了模型对缺失数据的鲁棒性，提高了多模态深度学习在真实洪水管理场景中的适用性，为灾害响应提供了更可靠的制图工具。

Abstract: Mapping water extent during a flood event is essential for effective disaster management throughout all phases: mitigation, preparedness, response, and recovery. In particular, during the response stage, when timely and accurate information is important, Synthetic Aperture Radar (SAR) data are primarily employed to produce water extent maps. Recently, leveraging the complementary characteristics of SAR and MSI data through a multimodal approach has emerged as a promising strategy for advancing water extent mapping using deep learning models. This approach is particularly beneficial when timely post-flood observations, acquired during or shortly after the flood peak, are limited, as it enables the use of all available imagery for more accurate post-flood water extent mapping. However, the adaptive integration of partially available MSI data into the SAR-based post-flood water extent mapping process remains underexplored. To bridge this research gap, we propose the Spatially Masked Adaptive Gated Network (SMAGNet), a multimodal deep learning model that utilizes SAR data as the primary input for post-flood water extent mapping and integrates complementary MSI data through feature fusion. In experiments on the C2S-MS Floods dataset, SMAGNet consistently outperformed other multimodal deep learning models in prediction performance across varying levels of MSI data availability. Furthermore, we found that even when MSI data were completely missing, the performance of SMAGNet remained statistically comparable to that of a U-Net model trained solely on SAR data. These findings indicate that SMAGNet enhances the model robustness to missing data as well as the applicability of multimodal deep learning in real-world flood management scenarios.

</details>


### [6] [Compressed Map Priors for 3D Perception](https://arxiv.org/abs/2601.00139)
*Brady Zhou,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: 提出压缩地图先验（CMP）框架，通过历史遍历数据学习空间先验，显著提升3D目标检测性能


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶视觉系统通常将每个位置视为首次访问，忽略了历史遍历信息。人类驾驶员会利用先前经验，而大多数自动驾驶系统缺乏这种空间先验知识

Method: 使用二值化哈希图存储空间先验，压缩率高达20倍（仅需32KB/km²）。该框架可轻松集成到主流3D感知系统中，几乎不增加计算成本

Result: 在nuScenes数据集上，CMP显著且一致地提升了多种架构的3D目标检测性能

Conclusion: 压缩地图先验是一种简单有效的框架，能够从历史遍历中学习空间先验，显著提升自动驾驶3D感知性能，且存储效率高、计算成本低

Abstract: Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\text{KB}/\text{km}^2$, a $20\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.

</details>


### [7] [Attention to Detail: Global-Local Attention for High-Resolution AI-Generated Image Detection](https://arxiv.org/abs/2601.00141)
*Lawrence Han*

Main category: cs.CV

TL;DR: GLASS是一种用于AI生成图像检测的架构，通过全局重采样视图和多个随机采样的局部裁剪相结合，保留细粒度细节，提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI快速发展，AI生成图像越来越逼真和高分辨率。大多数AI生成图像检测架构通常会对图像进行下采样，这可能导致细粒度细节丢失，影响检测准确性。

Method: 提出GLASS架构，结合全局重采样视图和多个随机采样的局部裁剪。局部裁剪通过空间分层采样高效选择原始分辨率区域，并使用基于注意力的评分进行聚合。该架构可集成到各种视觉模型中，处理任意尺寸图像。

Result: 在Vision Transformer、ResNet和ConvNeXt等骨干网络上进行实验，GLASS在可行计算约束下实现了比标准迁移学习更高的预测性能。

Conclusion: GLASS架构通过同时利用图像的全局和局部信息，有效提高了AI生成图像检测的准确性，避免了传统下采样方法导致的细节丢失问题。

Abstract: The rapid development of generative AI has made AI-generated images increasingly realistic and high-resolution. Most AI-generated image detection architectures typically downsample images before inputting them into models, risking the loss of fine-grained details. This paper presents GLASS (Global-Local Attention with Stratified Sampling), an architecture that combines a globally resized view with multiple randomly sampled local crops. These crops are original-resolution regions efficiently selected through spatially stratified sampling and aggregated using attention-based scoring. GLASS can be integrated into vision models to leverage both global and local information in images of any size. Vision Transformer, ResNet, and ConvNeXt models are used as backbones, and experiments show that GLASS outperforms standard transfer learning by achieving higher predictive performance within feasible computational constraints.

</details>


### [8] [FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications](https://arxiv.org/abs/2601.00150)
*Yehui Yang,Dalu Yang,Wenshuo Zhou,Fangxin Shang,Yifan Liu,Jie Ren,Haojun Fei,Qing Yang,Tao Chen*

Main category: cs.CV

TL;DR: FCMBench-V1.0是一个专门针对金融信贷领域的多模态基准测试，包含4,043张隐私合规图像和8,446个QA样本，评估模型在感知、推理和鲁棒性三个维度的表现。


<details>
  <summary>Details</summary>
Motivation: 随着多模态AI在信贷风险评估和文档审查中的广泛应用，迫切需要反映金融信贷特定文档和工作流程、包含信贷特定理解与真实世界鲁棒性、同时保持隐私合规性的领域专用基准测试。

Method: 通过封闭式合成-捕获流程构建样本：手动合成带有虚拟内容的文档模板，并在内部捕获场景感知图像。评估框架包含3个基础感知任务、4个信贷特定推理任务和10种真实世界采集伪影类型用于鲁棒性压力测试。

Result: 在评估的23个最先进视觉语言模型中，Gemini 3 Pro作为商业模型获得最佳F1分数(64.61%)，Qwen3-VL-235B作为开源基线获得最佳分数(57.27%)，而专门针对金融信贷的Qfin-VL-Instruct模型获得最高总分(64.92%)。鲁棒性评估显示即使表现最好的模型在采集伪影下也会出现明显性能下降。

Conclusion: FCMBench能够有效区分现代视觉语言模型的性能差异和鲁棒性，为金融信贷领域的多模态AI评估提供了标准化基准，同时解决了隐私合规和真实性的平衡问题。

Abstract: As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.

</details>


### [9] [Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions](https://arxiv.org/abs/2601.00156)
*Kaiwen Zheng,Junchen Fu,Songpei Xu,Yaoqing He,Joemon M. Jose,Han Hu,Xuri Ge*

Main category: cs.CV

TL;DR: 提出FaceFocalDesc问题，构建多属性面部区域描述数据集，基于Qwen2.5-VL开发Focal-RegionFace模型，通过渐进微调实现可解释的面部状态分析。


<details>
  <summary>Details</summary>
Motivation: 解决面部分析中未充分探索的问题：为任意选择的面部区域生成和识别包含面部动作单元(AUs)、情绪状态和年龄估计的多属性自然语言描述。系统聚焦个体面部区域的能力能带来更好的理解和控制。

Method: 1) 构建新的多属性描述数据集，提供丰富的区域级标注和自然语言描述；2) 基于Qwen2.5-VL开发Focal-RegionFace视觉语言模型，通过多个渐进微调阶段逐步细化对局部面部特征的关注。

Result: Focal-RegionFace在新基准测试中，在传统指标和新提出的指标上都取得了最佳性能，完全验证了其在细粒度多属性面部区域聚焦分析场景中的有效性和多功能性。

Conclusion: 该研究成功解决了面部区域聚焦描述问题，提出的模型在可解释的年龄估计、面部动作单元和情绪检测方面表现出色，为细粒度面部分析提供了新方法。

Abstract: In this paper, we introduce an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions, containing facial action units (AUs), emotional states, and age estimation, for arbitrarily selected face regions (termed FaceFocalDesc). We argue that the system's ability to focus on individual facial areas leads to better understanding and control. To achieve this capability, we construct a new multi-attribute description dataset for arbitrarily selected face regions, providing rich region-level annotations and natural language descriptions. Further, we propose a fine-tuned vision-language model based on Qwen2.5-VL, called Focal-RegionFace for facial state analysis, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages, resulting in interpretable age estimation, FAU and emotion detection. Experimental results show that Focal-RegionFace achieves the best performance on the new benchmark in terms of traditional and widely used metrics, as well as new proposed metrics. This fully verifies its effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.

</details>


### [10] [DichroGAN: Towards Restoration of in-air Colours of Seafloor from Satellite Imagery](https://arxiv.org/abs/2601.00194)
*Salma Gonzalez-Sabbagh,Antonio Robles-Kelly,Shang Gao*

Main category: cs.CV

TL;DR: DichroGAN是一个条件生成对抗网络，用于从卫星图像恢复海底的空中颜色，通过两阶段训练消除水下光衰减影响。


<details>
  <summary>Details</summary>
Motivation: 由于光在水柱中随深度呈指数衰减，从卫星图像恢复海底的空中颜色具有挑战性。现有方法难以准确处理水下光吸收和散射效应。

Method: 提出DichroGAN条件生成对抗网络，采用两阶段同步训练：第一阶段使用两个生成器从高光谱图像立方体估计漫反射和镜面反射，获得大气场景辐射；第二阶段使用第三个生成器处理场景辐射的谱带特征，第四个生成器估计水下光传输。这些生成器基于水下图像形成方程共同工作，消除光吸收和散射效应。

Result: 在PRISMA卫星图像数据集和多个水下数据集上的广泛实验表明，DichroGAN相比最先进的水下恢复技术具有竞争力。

Conclusion: DichroGAN能够有效恢复海底的空中颜色，为卫星海洋遥感提供了一种有前景的水下图像恢复方法。

Abstract: Recovering the in-air colours of seafloor from satellite imagery is a challenging task due to the exponential attenuation of light with depth in the water column. In this study, we present DichroGAN, a conditional generative adversarial network (cGAN) designed for this purpose. DichroGAN employs a two-steps simultaneous training: first, two generators utilise a hyperspectral image cube to estimate diffuse and specular reflections, thereby obtaining atmospheric scene radiance. Next, a third generator receives as input the generated scene radiance containing the features of each spectral band, while a fourth generator estimates the underwater light transmission. These generators work together to remove the effects of light absorption and scattering, restoring the in-air colours of seafloor based on the underwater image formation equation. DichroGAN is trained on a compact dataset derived from PRISMA satellite imagery, comprising RGB images paired with their corresponding spectral bands and masks. Extensive experiments on both satellite and underwater datasets demonstrate that DichroGAN achieves competitive performance compared to state-of-the-art underwater restoration techniques.

</details>


### [11] [MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing](https://arxiv.org/abs/2601.00204)
*Xiaokun Sun,Zeyu Cai,Hao Tang,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: MorphAny3D是一个无需训练的3D变形框架，利用结构化潜在表示实现高质量跨类别3D变形，通过注意力机制融合源和目标特征生成语义一致、时间平滑的变形序列。


<details>
  <summary>Details</summary>
Motivation: 3D变形面临生成语义一致和时间平滑变形的挑战，特别是在跨类别情况下。现有方法难以处理这些挑战，需要一种能够自然产生合理变形序列的解决方案。

Method: 提出MorphAny3D框架，基于结构化潜在表示。核心创新包括：变形交叉注意力机制融合源和目标特征以保证结构一致性；时间融合自注意力机制整合前一帧特征以增强时间一致性；方向校正策略缓解变形过程中的姿态模糊问题。

Result: 实验表明该方法能生成最先进的变形序列，即使在具有挑战性的跨类别情况下也表现优异。进一步支持解耦变形和3D风格迁移等高级应用，并能泛化到其他基于结构化潜在表示的生成模型。

Conclusion: MorphAny3D通过智能融合结构化潜在表示中的注意力机制，实现了高质量、语义一致且时间平滑的3D变形，为跨类别3D变形提供了有效的训练免费解决方案。

Abstract: 3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.

</details>


### [12] [CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting](https://arxiv.org/abs/2601.00207)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 提出基于多视角图像和神经辐射场（NeRF）的3D实例分割框架，用于精确农作物计数，无需作物特定参数调优，在棉花、苹果、梨数据集上验证有效。


<details>
  <summary>Details</summary>
Motivation: 户外农田环境中，部分遮挡和作物聚集导致的视觉模糊给基于图像的农作物计数带来巨大挑战，需要更精确的计数方法支持农业管理和干预决策。

Method: 利用多视角2D图像，结合神经辐射场（NeRF）进行视图合成，引入作物可见性和掩码一致性评分，结合3D信息实现3D实例分割和精确计数。

Result: 在棉花、苹果、梨三种农作物数据集上验证，表现出稳定的计数性能，不受作物颜色、形状、大小变化影响，相比现有方法具有优越性能。

Conclusion: 提出的3D实例分割框架能有效解决户外农作物计数中的遮挡和聚集问题，实现精确计数，并贡献了棉花植物数据集促进后续研究。

Abstract: Rigorous crop counting is crucial for effective agricultural management and informed intervention strategies. However, in outdoor field environments, partial occlusions combined with inherent ambiguity in distinguishing clustered crops from individual viewpoints poses an immense challenge for image-based segmentation methods. To address these problems, we introduce a novel crop counting framework designed for exact enumeration via 3D instance segmentation. Our approach utilizes 2D images captured from multiple viewpoints and associates independent instance masks for neural radiance field (NeRF) view synthesis. We introduce crop visibility and mask consistency scores, which are incorporated alongside 3D information from a NeRF model. This results in an effective segmentation of crop instances in 3D and highly-accurate crop counts. Furthermore, our method eliminates the dependence on crop-specific parameter tuning. We validate our framework on three agricultural datasets consisting of cotton bolls, apples, and pears, and demonstrate consistent counting performance despite major variations in crop color, shape, and size. A comparative analysis against the state of the art highlights superior performance on crop counting tasks. Lastly, we contribute a cotton plant dataset to advance further research on this topic.

</details>


### [13] [IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation](https://arxiv.org/abs/2601.00212)
*Han Liu,Yubo Fan,Hao Li,Dewei Hu,Daniel Moyer,Zhoubing Xu,Benoit M. Dawant,Ipek Oguz*

Main category: cs.CV

TL;DR: 提出IntraStyler方法，通过示例图像引导风格合成，无需先验知识即可捕获多样化的域内风格，提升跨模态域适应的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督域适应方法主要关注源域和目标域之间的域偏移，而域内变异性研究不足。传统方法需要预先指定域内变化进行风格合成，这在实际应用中不切实际。

Method: 提出IntraStyler方法：1）基于示例图像的风格合成，使输出风格匹配示例风格；2）引入风格编码器，基于对比学习判别性地学习风格特征；3）无需先验知识即可捕获多样化的域内风格。

Result: 在最大的跨模态域适应公开数据集CrossMoDA 2023上评估，实验表明该方法在可控风格合成方面有效，且多样化的合成数据对下游分割任务有益。

Conclusion: IntraStyler能够无需先验知识捕获多样化的域内风格，通过示例引导的风格合成方法有效提升了跨模态域适应中分割任务的性能。

Abstract: Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.

</details>


### [14] [From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2601.00215)
*Omar Sharif,Eftekhar Hossain,Patrick Ng*

Main category: cs.CV

TL;DR: 该研究提出使用强化学习来增强多模态大语言模型的视觉推理能力，通过设计多种奖励函数激励模型生成更长的结构化推理过程，从而解决视觉信息整合不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在生成推理链时缺乏对视觉信息的有效整合，这限制了它们解决需要精确视觉感知的任务（如视觉谜题）的能力。研究表明视觉感知是这类任务的关键瓶颈，将图像转换为文本描述能显著提升性能。

Method: 采用奖励驱动的强化学习方法，设计了六种针对不同推理方面的奖励函数（包括图像理解、思考步骤和答案准确性）。使用组相对策略优化（GRPO）来明确激励更长、结构化的推理，并防止视觉信息的绕过。

Result: 在Qwen-2.5-VL-7B模型上实现了5.56%的性能提升，在领域内和领域外设置中都取得了稳定的增益。实验还表明，将图像转换为文本描述能使Claude 3.5和Claude 3.7分别获得26.7%和23.6%的性能提升。

Conclusion: 强化学习是增强多模态大语言模型视觉推理能力的有效机制，能够在不依赖昂贵监督的情况下解锁更长的视觉推理过程，通过设计合适的奖励函数可以显著提升模型在需要精确视觉感知的任务上的表现。

Abstract: Reinforcement learning (RL) has emerged as a promising approach for eliciting reasoning chains before generating final answers. However, multimodal large language models (MLLMs) generate reasoning that lacks integration of visual information. This limits their ability to solve problems that demand accurate visual perception, such as visual puzzles. We show that visual perception is the key bottleneck in such tasks: converting images into textual descriptions significantly improves performance, yielding gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.
  To address this, we investigate reward-driven RL as a mechanism to unlock long visual reasoning in open-source MLLMs without requiring costly supervision. We design and evaluate six reward functions targeting different reasoning aspects, including image understanding, thinking steps, and answer accuracy. Using group relative policy optimization (GRPO), our approach explicitly incentivizes longer, structured reasoning and mitigates bypassing of visual information. Experiments on Qwen-2.5-VL-7B achieve 5.56% improvements over the base model, with consistent gains across both in-domain and out-of-domain settings.

</details>


### [15] [LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization](https://arxiv.org/abs/2601.00222)
*Jie Li,Kwan-Yee K. Wong,Kai Han*

Main category: cs.CV

TL;DR: LooC是一种新的向量量化方法，通过低维码本组合实现更紧凑高效的向量量化，在保持高性能的同时显著减小码本大小。


<details>
  <summary>Details</summary>
Motivation: 随着数据和模型复杂度增加，需要更高容量但更紧凑的向量量化方法。现有方法在码本容量和紧凑性之间存在冲突。

Method: 1) 引入参数高效的码本，将码向量视为特征向量的低维组合单元进行组合；2) 采用参数无关的外推-插值机制增强特征平滑；3) 作为即插即用模块适用于不同下游任务。

Result: 在不同任务、数据集和架构上的广泛评估表明，LooC在显著减小码本大小的同时，性能优于现有VQ方法，达到最先进水平。

Conclusion: LooC成功解决了向量量化中码本容量与紧凑性的冲突，通过低维组合码本实现了高效、高性能的向量量化，可作为通用模块应用于各种VQ任务。

Abstract: Vector quantization (VQ) is a prevalent and fundamental technique that discretizes continuous feature vectors by approximating them using a codebook. As the diversity and complexity of data and models continue to increase, there is an urgent need for high-capacity, yet more compact VQ methods. This paper aims to reconcile this conflict by presenting a new approach called LooC, which utilizes an effective Low-dimensional codebook for Compositional vector quantization. Firstly, LooC introduces a parameter-efficient codebook by reframing the relationship between codevectors and feature vectors, significantly expanding its solution space. Instead of individually matching codevectors with feature vectors, LooC treats them as lower-dimensional compositional units within feature vectors and combines them, resulting in a more compact codebook with improved performance. Secondly, LooC incorporates a parameter-free extrapolation-by-interpolation mechanism to enhance and smooth features during the VQ process, which allows for better preservation of details and fidelity in feature approximation. The design of LooC leads to full codebook usage, effectively utilizing the compact codebook while avoiding the problem of collapse. Thirdly, LooC can serve as a plug-and-play module for existing methods for different downstream tasks based on VQ. Finally, extensive evaluations on different tasks, datasets, and architectures demonstrate that LooC outperforms existing VQ methods, achieving state-of-the-art performance with a significantly smaller codebook.

</details>


### [16] [Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions](https://arxiv.org/abs/2601.00225)
*Aobo Li,Jinjian Wu,Yongxu Liu,Leida Li,Weisheng Dong*

Main category: cs.CV

TL;DR: 提出SynDR-IQA框架，通过重塑合成数据分布来提升盲图像质量评估的泛化能力，解决现有合成数据集训练模型泛化有限的问题


<details>
  <summary>Details</summary>
Motivation: 盲图像质量评估面临大规模标注数据稀缺的挑战，合成数据是潜在解决方案，但现有合成数据集训练的模型泛化能力有限。研究发现合成数据学习到的表征呈现离散聚类模式，阻碍回归性能

Method: 基于样本多样性和冗余度对泛化误差影响的理论推导，提出SynDR-IQA框架：1) 分布感知的多样内容上采样，增强视觉多样性同时保持内容分布；2) 密度感知的冗余聚类下采样，通过减少密集聚类区域的样本密度来平衡样本分布

Result: 在三种跨数据集设置（合成到真实、合成到算法、合成到合成）上的大量实验证明了方法的有效性

Conclusion: 通过重塑合成数据分布可以有效提升盲图像质量评估模型的泛化能力，SynDR-IQA为解决合成数据训练模型的泛化问题提供了有效框架

Abstract: Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.

</details>


### [17] [Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection](https://arxiv.org/abs/2601.00237)
*Chao Yang,Haoyuan Zheng,Yue Ma*

Main category: cs.CV

TL;DR: 提出跨模态数据增强框架，结合CycleGAN和YOLOv8，通过可见光PCB图像生成伪红外数据，解决红外数据稀缺问题，提升PCB缺陷检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决PCB缺陷检测中红外数据稀缺的关键瓶颈问题。传统方法依赖配对监督数据，但实际应用中红外数据获取困难且成本高昂，限制了检测模型的训练效果。

Method: 1. 使用CycleGAN进行无配对图像到图像转换，将丰富的可见光PCB图像映射到红外域，生成高质量伪红外样本；2. 构建异构训练策略，融合生成的伪红外数据和有限的真实红外样本；3. 训练轻量级YOLOv8检测器。

Result: 该方法在低数据条件下有效增强特征学习。增强后的检测器显著优于仅使用有限真实数据训练的模型，性能接近完全监督训练的基准，证明了伪红外合成作为工业检测鲁棒增强策略的有效性。

Conclusion: 提出的跨模态数据增强框架成功解决了红外数据稀缺问题，通过生成伪红外数据有效提升了PCB缺陷检测性能，为工业检测提供了一种实用的数据增强解决方案。

Abstract: This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.

</details>


### [18] [Context-Aware Pesticide Recommendation via Few-Shot Pest Recognition for Precision Agriculture](https://arxiv.org/abs/2601.00243)
*Anirudha Ghosh,Ritam Sarkar,Debaditya Barman*

Main category: cs.CV

TL;DR: 提出轻量级框架用于害虫检测和农药推荐，适用于智能手机和无人机等低资源设备，帮助小农户进行精准农业管理。


<details>
  <summary>Details</summary>
Motivation: 传统害虫管理方法依赖人工检查和化学农药，成本高、耗时长、劳动密集且对环境有害。需要开发适用于小农户的低成本、环保解决方案。

Method: 框架包含两个模块：1) 害虫检测模块使用轻量级CNN结合原型元学习，实现小样本准确识别；2) 农药推荐模块结合作物类型、生长阶段等环境因素，推荐安全环保的农药。通过整合多个公开数据集构建综合训练数据集。

Result: 轻量级CNN在保持与最先进模型相当准确率的同时，显著降低计算复杂度。决策支持系统减少了对传统化学农药的依赖，促进了可持续农业实践。

Conclusion: 该框架在精准农业中具有实时应用潜力，特别适合资源有限的设备和小农户使用，能够有效改善害虫管理并促进环保农业实践。

Abstract: Effective pest management is crucial for enhancing agricultural productivity, especially for crops such as sugarcane and wheat that are highly vulnerable to pest infestations. Traditional pest management methods depend heavily on manual field inspections and the use of chemical pesticides. These approaches are often costly, time-consuming, labor-intensive, and can have a negative impact on the environment. To overcome these challenges, this study presents a lightweight framework for pest detection and pesticide recommendation, designed for low-resource devices such as smartphones and drones, making it suitable for use by small and marginal farmers.
  The proposed framework includes two main components. The first is a Pest Detection Module that uses a compact, lightweight convolutional neural network (CNN) combined with prototypical meta-learning to accurately identify pests even when only a few training samples are available. The second is a Pesticide Recommendation Module that incorporates environmental factors like crop type and growth stage to suggest safe and eco-friendly pesticide recommendations. To train and evaluate our framework, a comprehensive pest image dataset was developed by combining multiple publicly available datasets. The final dataset contains samples with different viewing angles, pest sizes, and background conditions to ensure strong generalization.
  Experimental results show that the proposed lightweight CNN achieves high accuracy, comparable to state-of-the-art models, while significantly reducing computational complexity. The Decision Support System additionally improves pest management by reducing dependence on traditional chemical pesticides and encouraging sustainable practices, demonstrating its potential for real-time applications in precision agriculture.

</details>


### [19] [TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models](https://arxiv.org/abs/2601.00260)
*Kohei Yamamoto,Tomohiro Kikuchi*

Main category: cs.CV

TL;DR: TotalFM是一个放射学基础模型，通过器官分离概念高效学习3D-CT图像与语言表达的对应关系，在零样本器官病变分类任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 放射学基础模型在处理3D-CT体积数据时面临计算成本高的挑战，需要一种既能保持表示能力又能提高计算效率的方法。

Method: 基于器官分离概念，利用14万系列数据集，通过分割技术和LLM处理放射报告自动创建器官体积-发现句子对，结合VideoMAE自监督预训练和体积-文本对比学习。

Result: 在零样本器官病变分类中，83%器官优于CT-CLIP，64%器官优于Merlin；在零样本发现病变分类中，83%类别AUROC优于Merlin；在放射报告生成任务中性能与现有VLM相当。

Conclusion: 器官分离学习框架为3D-CT基础模型的实际应用提供了现实有效的设计指南，展示了在临床评估中的高泛化性能。

Abstract: While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.

</details>


### [20] [S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding](https://arxiv.org/abs/2601.00264)
*He Wang,Longteng Guo,Pengkang Huo,Xuanxu Lin,Yichen Yuan,Jie Jiang,Jing Liu*

Main category: cs.CV

TL;DR: S1-MMAlign是一个大规模多学科科学多模态数据集，包含1550万高质量图像-文本对，通过AI增强管道提升科学图像与文本的对齐质量。


<details>
  <summary>Details</summary>
Motivation: 多模态学习在通用领域已取得革命性进展，但在科学发现中的应用受到阻碍，主要因为复杂科学图像与稀疏文本描述之间存在深刻的语义鸿沟。现有科学多模态数据集存在弱对齐问题。

Method: 从250万篇开放获取科学论文中提取1550万图像-文本对，涵盖物理、生物、工程等多个学科。开发AI就绪的语义增强管道，利用Qwen-VL多模态大模型系列，通过合成论文摘要和引用上下文来重新描述图像，解决原始科学标题的弱对齐问题。

Result: 技术验证表明增强显著提升数据质量：基于SciBERT的伪困惑度指标显示语义模糊性降低，CLIP分数显示图像-文本对齐提升18.21%。数据集为推进科学推理和跨模态理解提供基础资源。

Conclusion: S1-MMAlign为AI for Science时代提供了基础资源，通过大规模高质量多模态数据集和语义增强管道，解决了科学图像与文本之间的对齐问题，有望推动科学发现中的多模态学习应用。

Abstract: Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.

</details>


### [21] [ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching](https://arxiv.org/abs/2601.00267)
*Yi Sun,Xinhao Zhong,Hongyan Li,Yimin Zhou,Junhao Li,Bin Chen,Xuan Wang*

Main category: cs.CV

TL;DR: 提出ActErase：一种无需训练的概念擦除方法，通过分析激活差异区域并动态替换输入激活，在扩散模型中高效移除敏感概念


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型存在安全、版权和伦理问题，现有概念擦除方法大多依赖数据密集且计算昂贵的微调，存在关键限制

Method: 基于模型激活主要由通用概念组成、只有极小部分表示目标概念的观察，通过提示对分析识别激活差异区域，提取目标激活并在前向传播中动态替换输入激活

Result: 在三个关键擦除任务（裸露、艺术风格和对象移除）上实现最先进的擦除性能，有效保持模型整体生成能力，对对抗攻击表现出强鲁棒性

Conclusion: ActErase为扩散模型中的轻量级有效概念操作建立了新的即插即用范式，无需训练即可实现高效概念擦除

Abstract: Recent advances in text-to-image diffusion models have demonstrated remarkable generation capabilities, yet they raise significant concerns regarding safety, copyright, and ethical implications. Existing concept erasure methods address these risks by removing sensitive concepts from pre-trained models, but most of them rely on data-intensive and computationally expensive fine-tuning, which poses a critical limitation. To overcome these challenges, inspired by the observation that the model's activations are predominantly composed of generic concepts, with only a minimal component can represent the target concept, we propose a novel training-free method (ActErase) for efficient concept erasure. Specifically, the proposed method operates by identifying activation difference regions via prompt-pair analysis, extracting target activations and dynamically replacing input activations during forward passes. Comprehensive evaluations across three critical erasure tasks (nudity, artistic style, and object removal) demonstrates that our training-free method achieves state-of-the-art (SOTA) erasure performance, while effectively preserving the model's overall generative capability. Our approach also exhibits strong robustness against adversarial attacks, establishing a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models.

</details>


### [22] [FaithSCAN: Model-Driven Single-Pass Hallucination Detection for Faithful Visual Question Answering](https://arxiv.org/abs/2601.00269)
*Chaodong Tong,Qi Zhang,Chen Li,Lei Jiang,Yanbing Liu*

Main category: cs.CV

TL;DR: FaithSCAN：利用VLM内部信号检测VQA幻觉的轻量级网络，通过融合token级解码不确定性、中间视觉表示和跨模态对齐特征，无需人工标注实现高效检测


<details>
  <summary>Details</summary>
Motivation: 现有VQA幻觉检测方法存在局限性：外部验证方法计算开销大且依赖外部资源质量；不确定性驱动方法仅捕捉有限的不确定性方面，未能充分利用模型内部信号。两种方法在效率、鲁棒性和检测性能上都有不足

Method: 提出FaithSCAN轻量级网络，融合VLM内部信号：token级解码不确定性、中间视觉表示、跨模态对齐特征。采用分支证据编码和不确定性感知注意力进行融合。扩展LLM-as-a-Judge范式到VQA幻觉检测，提出低成本策略自动生成模型依赖的监督信号

Result: 在多个VQA基准测试中，FaithSCAN在效果和效率上都显著优于现有方法。深入分析显示幻觉源于视觉感知、跨模态推理和语言解码的系统性内部状态变化，不同内部信号提供互补诊断线索

Conclusion: FaithSCAN通过有效利用VLM内部信号实现了高效可靠的VQA幻觉检测，无需人工标注。研究发现不同VLM架构的幻觉模式各异，为理解多模态幻觉的根本原因提供了新见解

Abstract: Faithfulness hallucinations in VQA occur when vision-language models produce fluent yet visually ungrounded answers, severely undermining their reliability in safety-critical applications. Existing detection methods mainly fall into two categories: external verification approaches relying on auxiliary models or knowledge bases, and uncertainty-driven approaches using repeated sampling or uncertainty estimates. The former suffer from high computational overhead and are limited by external resource quality, while the latter capture only limited facets of model uncertainty and fail to sufficiently explore the rich internal signals associated with the diverse failure modes. Both paradigms thus have inherent limitations in efficiency, robustness, and detection performance. To address these challenges, we propose FaithSCAN: a lightweight network that detects hallucinations by exploiting rich internal signals of VLMs, including token-level decoding uncertainty, intermediate visual representations, and cross-modal alignment features. These signals are fused via branch-wise evidence encoding and uncertainty-aware attention. We also extend the LLM-as-a-Judge paradigm to VQA hallucination and propose a low-cost strategy to automatically generate model-dependent supervision signals, enabling supervised training without costly human labels while maintaining high detection accuracy. Experiments on multiple VQA benchmarks show that FaithSCAN significantly outperforms existing methods in both effectiveness and efficiency. In-depth analysis shows hallucinations arise from systematic internal state variations in visual perception, cross-modal reasoning, and language decoding. Different internal signals provide complementary diagnostic cues, and hallucination patterns vary across VLM architectures, offering new insights into the underlying causes of multimodal hallucinations.

</details>


### [23] [Disentangling Hardness from Noise: An Uncertainty-Driven Model-Agnostic Framework for Long-Tailed Remote Sensing Classification](https://arxiv.org/abs/2601.00278)
*Chi Ding,Junxiao Xue,Xinyi Yin,Shi Chen,Yunyun Shi,Yiduo Wang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: 提出DUAL框架，通过证据深度学习动态解耦预测不确定性为认知不确定性和偶然不确定性，分别处理长尾遥感数据中的难样本和噪声样本。


<details>
  <summary>Details</summary>
Motivation: 遥感数据中普遍存在长尾分布，传统方法无法区分难样本和噪声样本，导致对噪声数据的过拟合。

Method: 基于证据深度学习，提出模型无关的DUAL框架：1）用认知不确定性指导重加权策略处理难样本；2）用偶然不确定性量化数据模糊性，采用自适应标签平滑抑制噪声影响。

Result: 在多个数据集和骨干网络上验证了框架的有效性和泛化能力，超越了TGN和SADE等强基线，消融研究进一步验证了设计选择的重要性。

Conclusion: DUAL框架成功解决了长尾遥感数据中难样本与噪声样本的区分问题，通过不确定性解耦实现了更鲁棒的模型训练。

Abstract: Long-Tailed distributions are pervasive in remote sensing due to the inherently imbalanced occurrence of grounded objects. However, a critical challenge remains largely overlooked, i.e., disentangling hard tail data samples from noisy ambiguous ones. Conventional methods often indiscriminately emphasize all low-confidence samples, leading to overfitting on noisy data. To bridge this gap, building upon Evidential Deep Learning, we propose a model-agnostic uncertainty-aware framework termed DUAL, which dynamically disentangles prediction uncertainty into Epistemic Uncertainty (EU) and Aleatoric Uncertainty (AU). Specifically, we introduce EU as an indicator of sample scarcity to guide a reweighting strategy for hard-to-learn tail samples, while leveraging AU to quantify data ambiguity, employing an adaptive label smoothing mechanism to suppress the impact of noise. Extensive experiments on multiple datasets across various backbones demonstrate the effectiveness and generalization of our framework, surpassing strong baselines such as TGN and SADE. Ablation studies provide further insights into the crucial choices of our design.

</details>


### [24] [SV-GS: Sparse View 4D Reconstruction with Skeleton-Driven Gaussian Splatting](https://arxiv.org/abs/2601.00285)
*Jun-Jee Chao,Volkan Isler*

Main category: cs.CV

TL;DR: SV-GS：一种在稀疏观测下重建动态目标的方法，通过骨架驱动的变形场和运动估计，在稀疏视角和时间采样下实现高质量动态重建。


<details>
  <summary>Details</summary>
Motivation: 现实世界中动态目标重建面临挑战，因为观测通常稀疏（如安防摄像头），而传统方法需要密集的多视角视频。稀疏观测导致动态重建问题高度不适定。

Method: 提出SV-GS框架，利用粗略骨架图和初始静态重建作为输入，优化骨架驱动的变形场。该场包含粗粒度骨架关节姿态估计器和细粒度变形模块，仅使关节姿态估计器随时间变化，实现平滑运动插值同时保留几何细节。

Result: 在合成数据集上，稀疏观测下PSNR提升达34%；在真实数据集上，使用显著更少的帧数即可达到与密集单目视频方法相当的性能。还可使用扩散生成先验替代初始静态重建，提升实用性。

Conclusion: SV-GS能够在稀疏观测条件下有效重建动态目标，通过骨架引导的变形场实现高质量动态重建，为现实场景中的动态对象重建提供了实用解决方案。

Abstract: Reconstructing a dynamic target moving over a large area is challenging. Standard approaches for dynamic object reconstruction require dense coverage in both the viewing space and the temporal dimension, typically relying on multi-view videos captured at each time step. However, such setups are only possible in constrained environments. In real-world scenarios, observations are often sparse over time and captured sparsely from diverse viewpoints (e.g., from security cameras), making dynamic reconstruction highly ill-posed. We present SV-GS, a framework that simultaneously estimates a deformation model and the object's motion over time under sparse observations. To initialize SV-GS, we leverage a rough skeleton graph and an initial static reconstruction as inputs to guide motion estimation. (Later, we show that this input requirement can be relaxed.) Our method optimizes a skeleton-driven deformation field composed of a coarse skeleton joint pose estimator and a module for fine-grained deformations. By making only the joint pose estimator time-dependent, our model enables smooth motion interpolation while preserving learned geometric details. Experiments on synthetic datasets show that our method outperforms existing approaches under sparse observations by up to 34% in PSNR, and achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames. Moreover, we demonstrate that the input initial static reconstruction can be replaced by a diffusion-based generative prior, making our method more practical for real-world scenarios.

</details>


### [25] [Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies](https://arxiv.org/abs/2601.00286)
*Ali Anaissi,Ali Braytee,Weidong Huang,Junaid Akram,Alaa Farhat,Jie Hua*

Main category: cs.CV

TL;DR: 基于Swin Transformer的深度学习模型在ISIC2019数据集上对8种皮肤病变类别达到87.71%的预测准确率，可作为临床诊断支持工具和患者自我评估辅助。


<details>
  <summary>Details</summary>
Motivation: 皮肤疾病日益普遍，但皮肤科医生资源有限，需要智能工具来支持患者和临床医生进行及时准确的皮肤疾病诊断。

Method: 利用公开皮肤疾病图像数据集进行预训练，采用Swin Transformer架构，优化数据预处理流程，应用针对性数据增强技术，提取视觉特征并准确分类各种皮肤病病例。

Result: 在ISIC2019数据集上对8种皮肤病变类别实现了87.71%的预测准确率。

Conclusion: 该模型展示了作为临床医生诊断支持工具和患者自我评估辅助的潜力，能够帮助解决皮肤科医生资源不足的问题。

Abstract: As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.

</details>


### [26] [TimeColor: Flexible Reference Colorization via Temporal Concatenation](https://arxiv.org/abs/2601.00296)
*Bryan Constantine Sadihin,Yihao Meng,Michael Hua Wang,Matteo Jiahao Chen,Hang Su*

Main category: cs.CV

TL;DR: TimeColor：一种支持多参考输入的基于草图的视频着色模型，通过显式区域分配和时空对应掩码注意力提升色彩保真度、身份一致性和时间稳定性


<details>
  <summary>Details</summary>
Motivation: 现有视频着色模型通常只使用场景第一帧作为参考，忽略了其他条件数据源（如角色设定图、背景图像、任意着色帧等），限制了着色质量和一致性

Method: 1. 将参考帧编码为额外潜在帧进行时间拼接，保持模型参数不变；2. 使用显式每参考区域分配；3. 采用时空对应掩码注意力加强主体-参考绑定；4. 使用模态分离的RoPE索引

Result: 在SAKUGA-42M数据集上的实验表明，TimeColor在单参考和多参考协议下均优于现有基线，在色彩保真度、身份一致性和时间稳定性方面均有提升

Conclusion: TimeColor通过支持异构、可变数量的参考输入，结合显式区域分配和时空对应机制，有效解决了传统视频着色模型的局限性，实现了更高质量的着色效果

Abstract: Most colorization models condition only on a single reference, typically the first frame of the scene. However, this approach ignores other sources of conditional data, such as character sheets, background images, or arbitrary colorized frames. We propose TimeColor, a sketch-based video colorization model that supports heterogeneous, variable-count references with the use of explicit per-reference region assignment. TimeColor encodes references as additional latent frames which are concatenated temporally, permitting them to be processed concurrently in each diffusion step while keeping the model's parameter count fixed. TimeColor also uses spatiotemporal correspondence-masked attention to enforce subject-reference binding in addition to modality-disjoint RoPE indexing. These mechanisms mitigate shortcutting and cross-identity palette leakage. Experiments on SAKUGA-42M under both single- and multi-reference protocols show that TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines.

</details>


### [27] [VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning](https://arxiv.org/abs/2601.00307)
*Anns Ijaz,Muhammad Azeem Javed*

Main category: cs.CV

TL;DR: VisNet是一种计算高效的人员重识别模型，通过多尺度特征融合、语义聚类和动态权重平均等技术，在保持高精度的同时大幅降低计算成本，适合实时监控和移动应用部署。


<details>
  <summary>Details</summary>
Motivation: 当前人员重识别方法虽然精度高但计算成本大，难以在计算资源有限的监控和移动应用中实时部署。需要开发既准确又计算高效的模型。

Method: 提出VisNet模型，包含：1）多尺度特征融合（融合ResNet50的1-4阶段）；2）语义聚类与解剖学身体分区；3）动态权重平均平衡分类语义正则化；4）使用FIDI损失函数改进度量学习。

Result: 在Market-1501数据集上达到87.05% Rank-1准确率和77.65% mAP，仅需32.41M参数和4.601 GFLOPs计算量，显著优于现有高计算成本方法。

Conclusion: VisNet为计算资源有限的实时监控和移动应用提供了一种实用的人员重识别解决方案，在精度和效率之间取得了良好平衡。

Abstract: Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.

</details>


### [28] [ReMA: A Training-Free Plug-and-Play Mixing Augmentation for Video Behavior Recognition](https://arxiv.org/abs/2601.00311)
*Feng-Qi Cui,Jinyang Huang,Sirui Zhao,Jinglong Guo,Qifan Cai,Xin Yan,Zhi Liu*

Main category: cs.CV

TL;DR: ReMA是一种视频行为识别的表示感知混合增强方法，通过控制混合过程来扩展表示同时保持类别条件稳定性，提升模型泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视频数据增强策略大多是扰动驱动的，会引入不可控的变化，放大非判别性因素，削弱类内分布结构，导致表示漂移和跨时间尺度增益不一致。

Method: 提出表示感知混合增强(ReMA)，包含两个互补机制：1) 表示对齐机制(RAM)，在分布对齐约束下进行结构化类内混合；2) 动态选择机制(DSM)，生成运动感知的时空掩码来定位扰动，避开判别敏感区域并促进时间一致性。

Result: 在多种视频行为基准测试上的广泛实验表明，ReMA在不同时空粒度上一致地提升了泛化能力和鲁棒性。

Conclusion: ReMA作为一种即插即用的增强策略，通过联合控制混合的方式和位置，无需额外监督或可训练参数就能改善表示鲁棒性，有效解决了视频行为识别中表示漂移和增益不一致的问题。

Abstract: Video behavior recognition demands stable and discriminative representations under complex spatiotemporal variations. However, prevailing data augmentation strategies for videos remain largely perturbation-driven, often introducing uncontrolled variations that amplify non-discriminative factors, which finally weaken intra-class distributional structure and representation drift with inconsistent gains across temporal scales. To address these problems, we propose Representation-aware Mixing Augmentation (ReMA), a plug-and-play augmentation strategy that formulates mixing as a controlled replacement process to expand representations while preserving class-conditional stability. ReMA integrates two complementary mechanisms. Firstly, the Representation Alignment Mechanism (RAM) performs structured intra-class mixing under distributional alignment constraints, suppressing irrelevant intra-class drift while enhancing statistical reliability. Then, the Dynamic Selection Mechanism (DSM) generates motion-aware spatiotemporal masks to localize perturbations, guiding them away from discrimination-sensitive regions and promoting temporal coherence. By jointly controlling how and where mixing is applied, ReMA improves representation robustness without additional supervision or trainable parameters. Extensive experiments on diverse video behavior benchmarks demonstrate that ReMA consistently enhances generalization and robustness across different spatiotemporal granularities.

</details>


### [29] [Depth-Synergized Mamba Meets Memory Experts for All-Day Image Reflection Separation](https://arxiv.org/abs/2601.00322)
*Siyan Fang,Long Peng,Yuntao Wang,Ruonan Wei,Yuehuan Wang*

Main category: cs.CV

TL;DR: DMDNet利用深度感知扫描和状态空间模型，结合记忆专家补偿模块，在白天和夜间反射分离任务中表现优异，并构建了夜间反射分离数据集。


<details>
  <summary>Details</summary>
Motivation: 现有反射分离方法依赖单张图像信息，当传输层和反射层对比度相似时容易混淆，夜间情况更为严重，需要更有效的解决方案。

Method: 提出深度记忆解耦网络(DMDNet)：1) 深度感知扫描(DAScan)引导Mamba关注显著结构；2) 深度协同状态空间模型(DS-SSM)通过深度调制状态激活敏感性；3) 记忆专家补偿模块(MECM)利用跨图像历史知识提供层特定补偿。

Result: DMDNet在白天和夜间反射分离任务中均优于现有方法，并构建了NightIRS夜间反射分离数据集。

Conclusion: DMDNet通过深度引导和记忆补偿机制有效解决了反射分离中的层混淆问题，特别是在夜间场景下表现优异。

Abstract: Image reflection separation aims to disentangle the transmission layer and the reflection layer from a blended image. Existing methods rely on limited information from a single image, tending to confuse the two layers when their contrasts are similar, a challenge more severe at night. To address this issue, we propose the Depth-Memory Decoupling Network (DMDNet). It employs the Depth-Aware Scanning (DAScan) to guide Mamba toward salient structures, promoting information flow along semantic coherence to construct stable states. Working in synergy with DAScan, the Depth-Synergized State-Space Model (DS-SSM) modulates the sensitivity of state activations by depth, suppressing the spread of ambiguous features that interfere with layer disentanglement. Furthermore, we introduce the Memory Expert Compensation Module (MECM), leveraging cross-image historical knowledge to guide experts in providing layer-specific compensation. To address the lack of datasets for nighttime reflection separation, we construct the Nighttime Image Reflection Separation (NightIRS) dataset. Extensive experiments demonstrate that DMDNet outperforms state-of-the-art methods in both daytime and nighttime.

</details>


### [30] [HarmoniAD: Harmonizing Local Structures and Global Semantics for Anomaly Detection](https://arxiv.org/abs/2601.00327)
*Naiqi Zhang,Chuancheng Shi,Jingtong Dou,Wenhua Wu,Fei Shen,Jianhua Cao*

Main category: cs.CV

TL;DR: HarmoniAD：一种频率引导的双分支框架，通过解耦高、低频特征来平衡结构细节和语义一致性，解决工业异常检测中的结构-语义权衡问题。


<details>
  <summary>Details</summary>
Motivation: 工业产品质量检测中异常检测至关重要，但现有方法面临结构-语义权衡：结构导向模型对噪声敏感，语义导向模型常忽略细节。需要一种能同时处理精细结构和全局语义的方法。

Method: 提出频率引导的双分支框架：1）使用CLIP图像编码器提取特征并转换到频域；2）解耦为高频和低频路径；3）高频分支使用细粒度结构注意力模块增强纹理和边缘；4）低频分支使用全局结构上下文模块捕获长程依赖；5）采用多类别联合训练策略。

Result: 在MVTec-AD、VisA和BTAD数据集上实现最先进性能，同时具备高敏感性和鲁棒性。

Conclusion: HarmoniAD通过频率域特征解耦和双分支互补建模，有效平衡了异常检测中的精细结构细节和全局语义一致性，解决了现有方法的局限性。

Abstract: Anomaly detection is crucial in industrial product quality inspection. Failing to detect tiny defects often leads to serious consequences. Existing methods face a structure-semantics trade-off: structure-oriented models (such as frequency-based filters) are noise-sensitive, while semantics-oriented models (such as CLIP-based encoders) often miss fine details. To address this, we propose HarmoniAD, a frequency-guided dual-branch framework. Features are first extracted by the CLIP image encoder, then transformed into the frequency domain, and finally decoupled into high- and low-frequency paths for complementary modeling of structure and semantics. The high-frequency branch is equipped with a fine-grained structural attention module (FSAM) to enhance textures and edges for detecting small anomalies, while the low-frequency branch uses a global structural context module (GSCM) to capture long-range dependencies and preserve semantic consistency. Together, these branches balance fine detail and global semantics. HarmoniAD further adopts a multi-class joint training strategy, and experiments on MVTec-AD, VisA, and BTAD show state-of-the-art performance with both sensitivity and robustness.

</details>


### [31] [Joint Geometry-Appearance Human Reconstruction in a Unified Latent Space via Bridge Diffusion](https://arxiv.org/abs/2601.00328)
*Yingzhi Tang,Qijian Zhang,Junhui Hou*

Main category: cs.CV

TL;DR: JGA-LBD：通过联合潜在表示和桥接扩散，从单张RGB图像统一重建3D数字人的几何与外观


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将几何估计和外观合成解耦，导致重建不统一和不一致。需要一种能同时建模几何和外观的统一框架。

Method: 提出JGA-LBD框架：1) 将所有条件（深度图、SMPL模型等）统一为3D高斯表示，通过共享稀疏VAE压缩到统一潜在空间；2) 使用桥接扩散从部分观测推断缺失组件；3) 专用解码模块从潜在表示提取完整几何结构并渲染新视角。

Result: 实验表明JGA-LBD在几何保真度和外观质量上优于当前最先进方法，包括具有挑战性的野外场景。

Conclusion: JGA-LBD通过联合潜在表示和桥接扩散，成功实现了从单张RGB图像对3D数字人的统一几何和外观重建，取得了优异性能。

Abstract: Achieving consistent and high-fidelity geometry and appearance reconstruction of 3D digital humans from a single RGB image is inherently a challenging task. Existing studies typically resort to decoupled pipelines for geometry estimation and appearance synthesis, often hindering unified reconstruction and causing inconsistencies. This paper introduces \textbf{JGA-LBD}, a novel framework that unifies the modeling of geometry and appearance into a joint latent representation and formulates the generation process as bridge diffusion. Observing that directly integrating heterogeneous input conditions (e.g., depth maps, SMPL models) leads to substantial training difficulties, we unify all conditions into the 3D Gaussian representations, which can be further compressed into a unified latent space through a shared sparse variational autoencoder (VAE). Subsequently, the specialized form of bridge diffusion enables to start with a partial observation of the target latent code and solely focuses on inferring the missing components. Finally, a dedicated decoding module extracts the complete 3D human geometric structure and renders novel views from the inferred latent representation. Experiments demonstrate that JGA-LBD outperforms current state-of-the-art approaches in terms of both geometry fidelity and appearance quality, including challenging in-the-wild scenarios. Our code will be made publicly available at https://github.com/haiantyz/JGA-LBD.

</details>


### [32] [Intelligent Traffic Surveillance for Real-Time Vehicle Detection, License Plate Recognition, and Speed Estimation](https://arxiv.org/abs/2601.00344)
*Bruce Mugizi,Sudi Murindanyi,Olivia Nakacwa,Andrew Katumba*

Main category: cs.CV

TL;DR: 该研究为乌干达等发展中国家开发了一个实时智能交通监控系统，使用计算机视觉技术实现车辆检测、车牌识别和速度估计，并通过数据库和短信API实现自动化罚单发放。


<details>
  <summary>Details</summary>
Motivation: 超速是道路死亡事故的主要原因，特别是在乌干达等发展中国家，这些地区道路安全基础设施有限，急需有效的交通管理解决方案。

Method: 使用计算机视觉技术构建实时监控系统：1）用YOLOv8进行车牌检测；2）用CNN和Transformer模型进行字符识别；3）使用感兴趣区域进行速度估计；4）建立数据库关联用户信息；5）通过Africa's Talking API实现短信自动化罚单发放。

Result: 车牌检测mAP达到97.9%；字符识别中CNN的CER为3.85%，Transformer降至1.79%；速度估计误差在10km/h以内；成功建立了自动化罚单发放系统。

Conclusion: 该系统针对资源受限环境设计，能够有效解决发展中国家的交通管理需求，通过自动化交通执法有潜力减少道路事故，在急需此类干预措施的地区具有重要应用价值。

Abstract: Speeding is a major contributor to road fatalities, particularly in developing countries such as Uganda, where road safety infrastructure is limited. This study proposes a real-time intelligent traffic surveillance system tailored to such regions, using computer vision techniques to address vehicle detection, license plate recognition, and speed estimation. The study collected a rich dataset using a speed gun, a Canon Camera, and a mobile phone to train the models. License plate detection using YOLOv8 achieved a mean average precision (mAP) of 97.9%. For character recognition of the detected license plate, the CNN model got a character error rate (CER) of 3.85%, while the transformer model significantly reduced the CER to 1.79%. Speed estimation used source and target regions of interest, yielding a good performance of 10 km/h margin of error. Additionally, a database was established to correlate user information with vehicle detection data, enabling automated ticket issuance via SMS via Africa's Talking API. This system addresses critical traffic management needs in resource-constrained environments and shows potential to reduce road accidents through automated traffic enforcement in developing countries where such interventions are urgently needed.

</details>


### [33] [OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning](https://arxiv.org/abs/2601.00352)
*Liuxiang Qiu,Hui Da,Yuzhen Niu,Tiesong Zhao,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 提出OmniVaT框架解决视觉-触觉学习中的单域泛化问题，通过多模态分数傅里叶适配器和离散树生成模块，有效缓解模态差异并增强对未见域的适应能力。


<details>
  <summary>Details</summary>
Motivation: 视觉-触觉学习面临视觉与触觉图像间的模态差异，以及非标准化触觉传感器和不一致数据收集导致的域差距问题。这些挑战被形式化为单域泛化多模态VTL任务。

Method: 提出OmniVaT框架：1) 多模态分数傅里叶适配器(MFFA)将视觉和触觉嵌入映射到统一的嵌入-频率空间，缓解模态差距；2) 离散树生成(DTG)模块通过分层树结构获得多样可靠的多模态分数表示，增强对未见域波动的适应性。

Result: 大量实验证明OmniVaT在SDG-VTL任务上具有优越的跨域泛化性能。

Conclusion: OmniVaT首次成功解决了单域泛化多模态视觉-触觉学习任务，通过统一的嵌入-频率空间映射和分层树表示生成，有效应对模态差异和域偏移挑战。

Abstract: Visual-tactile learning (VTL) enables embodied agents to perceive the physical world by integrating visual (VIS) and tactile (TAC) sensors. However, VTL still suffers from modality discrepancies between VIS and TAC images, as well as domain gaps caused by non-standardized tactile sensors and inconsistent data collection procedures. We formulate these challenges as a new task, termed single domain generalization for multimodal VTL (SDG-VTL). In this paper, we propose an OmniVaT framework that, for the first time, successfully addresses this task. On the one hand, OmniVaT integrates a multimodal fractional Fourier adapter (MFFA) to map VIS and TAC embeddings into a unified embedding-frequency space, thereby effectively mitigating the modality gap without multi-domain training data or careful cross-modal fusion strategies. On the other hand, it also incorporates a discrete tree generation (DTG) module that obtains diverse and reliable multimodal fractional representations through a hierarchical tree structure, thereby enhancing its adaptivity to fluctuating domain shifts in unseen domains. Extensive experiments demonstrate the superior cross-domain generalization performance of OmniVaT on the SDG-VTL task.

</details>


### [34] [Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers](https://arxiv.org/abs/2601.00359)
*Söhnke Benedikt Fischedick,Daniel Seichter,Benedict Stephan,Robin Schmidt,Horst-Michael Gross*

Main category: cs.CV

TL;DR: DVEFormer：基于RGB-D Transformer的高效方法，通过知识蒸馏预测密集文本对齐视觉嵌入，实现实时语义分割和自然语言查询


<details>
  <summary>Details</summary>
Motivation: 家庭环境中，机器人需要全面理解周围环境才能与未经训练的人类有效互动。传统语义分割方法使用固定的预定义类别，缺乏灵活性，无法支持自然语言查询等高级应用。

Method: 提出DVEFormer，基于RGB-D Transformer的架构，通过知识蒸馏从Alpha-CLIP教师模型学习细粒度像素级嵌入。使用教师嵌入指导高效的学生模型，实现文本对齐的视觉嵌入预测。

Result: 在常见室内数据集上达到竞争性性能，满足实时要求：完整模型26.3 FPS，小型变体77.0 FPS（NVIDIA Jetson AGX Orin）。支持传统语义分割（通过线性探测）、灵活文本查询和3D地图构建。

Conclusion: DVEFormer可作为传统分割方法的直接替代，同时支持灵活的自然语言查询，并能无缝集成到移动机器人3D建图流程中，适用于实际应用场景。

Abstract: In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.

</details>


### [35] [Mask-Conditioned Voxel Diffusion for Joint Geometry and Color Inpainting](https://arxiv.org/abs/2601.00368)
*Aarya Sumuk*

Main category: cs.CV

TL;DR: 提出一个轻量级的两阶段框架，用于联合修复受损3D物体的几何结构和颜色，应用于文化遗产数字修复。第一阶段定位损伤区域，第二阶段使用扩散模型进行修复。


<details>
  <summary>Details</summary>
Motivation: 数字修复文化遗产文物需要同时处理几何结构和颜色的修复问题。现有方法可能无法很好地处理复杂的损伤模式，需要一种能够联合修复几何和颜色的方法。

Method: 采用两阶段框架：1) 使用2D卷积网络从体素化对象的RGB切片预测损伤掩码，并聚合成体积掩码；2) 使用基于扩散的3D U-Net在体素网格上进行掩码条件修复，联合预测占用率和颜色，结合占用重建、掩码颜色重建和感知正则化的复合目标函数。

Result: 在合成损伤的纹理文物数据集上评估，与基于对称性的基线方法相比，该方法在固定32^3分辨率下产生更完整的几何结构和更一致的颜色重建。

Conclusion: 显式的掩码条件是一种实用的方法，可以指导体积扩散模型进行联合3D几何和颜色修复，为文化遗产数字修复提供了有效解决方案。

Abstract: We present a lightweight two-stage framework for joint geometry and color inpainting of damaged 3D objects, motivated by the digital restoration of cultural heritage artifacts. The pipeline separates damage localization from reconstruction. In the first stage, a 2D convolutional network predicts damage masks on RGB slices extracted from a voxelized object, and these predictions are aggregated into a volumetric mask. In the second stage, a diffusion-based 3D U-Net performs mask-conditioned inpainting directly on voxel grids, reconstructing geometry and color while preserving observed regions. The model jointly predicts occupancy and color using a composite objective that combines occupancy reconstruction with masked color reconstruction and perceptual regularization. We evaluate the approach on a curated set of textured artifacts with synthetically generated damage using standard geometric and color metrics. Compared to symmetry-based baselines, our method produces more complete geometry and more coherent color reconstructions at a fixed 32^3 resolution. Overall, the results indicate that explicit mask conditioning is a practical way to guide volumetric diffusion models for joint 3D geometry and color inpainting.

</details>


### [36] [BHaRNet: Reliability-Aware Body-Hand Modality Expertized Networks for Fine-grained Skeleton Action Recognition](https://arxiv.org/abs/2601.00369)
*Seungyeon Cho,Tae-kyun Kim*

Main category: cs.CV

TL;DR: 提出概率双流框架，统一可靠性建模和多模态集成，用于骨架动作识别，特别关注手部精细动作


<details>
  <summary>Details</summary>
Motivation: 现有骨架动作识别方法主要关注身体大尺度运动，忽略了对手部精细动作的识别，而手部动作对细粒度识别至关重要

Method: 概率双流框架包含三个关键组件：1) 无校准预处理管道，直接从原生坐标学习；2) 概率Noisy-OR融合，稳定可靠性感知的双流学习；3) 从骨架模态到RGB表示的跨模态集成，耦合四种骨架模态

Result: 在多个基准测试(NTU RGB+D~60/120, PKU-MMD, N-UCLA)和新定义的手部中心基准上表现出持续改进和鲁棒性，在噪声和异构条件下表现良好

Conclusion: 提出的概率双流框架能够有效统一可靠性建模和多模态集成，在骨架动作识别中实现更好的细粒度识别，特别是在手部精细动作识别方面

Abstract: Skeleton-based human action recognition (HAR) has achieved remarkable progress with graph-based architectures. However, most existing methods remain body-centric, focusing on large-scale motions while neglecting subtle hand articulations that are crucial for fine-grained recognition. This work presents a probabilistic dual-stream framework that unifies reliability modeling and multi-modal integration, generalizing expertized learning under uncertainty across both intra-skeleton and cross-modal domains. The framework comprises three key components: (1) a calibration-free preprocessing pipeline that removes canonical-space transformations and learns directly from native coordinates; (2) a probabilistic Noisy-OR fusion that stabilizes reliability-aware dual-stream learning without requiring explicit confidence supervision; and (3) an intra- to cross-modal ensemble that couples four skeleton modalities (Joint, Bone, Joint Motion, and Bone Motion) to RGB representations, bridging structural and visual motion cues in a unified cross-modal formulation. Comprehensive evaluations across multiple benchmarks (NTU RGB+D~60/120, PKU-MMD, N-UCLA) and a newly defined hand-centric benchmark exhibit consistent improvements and robustness under noisy and heterogeneous conditions.

</details>


### [37] [NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393)
*Yuxue Yang,Lue Fan,Ziqi Shi,Junran Peng,Feng Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: NeoVerse是一个多功能4D世界模型，能够进行4D重建、新轨迹视频生成和丰富的下游应用，通过无姿态前馈4D重建和在线单目退化模式模拟等技术，实现了对多样化单目视频的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前4D世界建模方法存在可扩展性限制，主要源于昂贵的多视角4D数据或繁琐的训练预处理，需要一种能够适应多样化单目视频的可扩展解决方案。

Method: 采用无姿态前馈4D重建、在线单目退化模式模拟等技术，使整个流程能够扩展到多样化的单目视频，无需昂贵的多视角数据或复杂预处理。

Result: 在标准重建和生成基准测试中达到最先进性能，同时展现出对不同领域的泛化能力和多功能性。

Conclusion: NeoVerse通过创新的可扩展设计，成功解决了当前4D世界建模的可扩展性问题，为4D重建和视频生成提供了强大且通用的解决方案。

Abstract: In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io

</details>


### [38] [RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection](https://arxiv.org/abs/2601.00398)
*Tao Wu,Qing Xu,Xiangjian He,Oakleigh Weekes,James Brown,Wenting Duan*

Main category: cs.CV

TL;DR: RoLID-11K是首个用于车载摄像头路边垃圾检测的大规模数据集，包含1.1万张标注图像，专注于极端小目标检测，并评估了多种现代检测器在动态驾驶场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前路边垃圾监测依赖人工调查和公众报告，空间覆盖有限。现有视觉数据集主要针对街景、航拍或水环境，无法反映车载摄像头中垃圾目标极小、稀疏且背景杂乱的特点。

Method: 构建了RoLID-11K数据集，包含超过1.1万张标注图像，涵盖英国多样化驾驶条件。对多种现代检测器进行基准测试，包括精度导向的Transformer架构和实时YOLO模型。

Result: CO-DETR及相关Transformer模型获得最佳定位精度，但实时模型受限于粗糙的特征层次结构。数据集呈现出明显的长尾分布和小目标分布特征。

Conclusion: RoLID-11K为动态驾驶场景中的极端小目标检测建立了具有挑战性的基准，旨在支持开发可扩展、低成本的路边垃圾监测系统。

Abstract: Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.

</details>


### [39] [ABFR-KAN: Kolmogorov-Arnold Networks for Functional Brain Analysis](https://arxiv.org/abs/2601.00416)
*Tyler Ward,Abdullah Imran*

Main category: cs.CV

TL;DR: 提出ABFR-KAN模型，结合先进脑功能表示组件与KAN网络，用于自闭症谱系障碍分类，在ABIDE I数据集上超越现有方法


<details>
  <summary>Details</summary>
Motivation: 传统功能连接分析依赖图谱分割，存在选择偏差和缺乏个体特异性问题，需要更可靠的功能连接估计方法

Method: 基于Transformer的分类网络，整合先进脑功能表示组件和Kolmogorov-Arnold Networks (KANs)，减少结构偏差，提高解剖一致性

Result: 在ABIDE I数据集上，包括跨站点评估和消融实验，ABFR-KAN在自闭症分类任务中持续优于现有最佳基线方法

Conclusion: ABFR-KAN通过结合先进脑功能表示和KAN网络，有效缓解了传统图谱分割的局限性，提高了功能连接估计的可靠性和分类性能

Abstract: Functional connectivity (FC) analysis, a valuable tool for computer-aided brain disorder diagnosis, traditionally relies on atlas-based parcellation. However, issues relating to selection bias and a lack of regard for subject specificity can arise as a result of such parcellations. Addressing this, we propose ABFR-KAN, a transformer-based classification network that incorporates novel advanced brain function representation components with the power of Kolmogorov-Arnold Networks (KANs) to mitigate structural bias, improve anatomical conformity, and enhance the reliability of FC estimation. Extensive experiments on the ABIDE I dataset, including cross-site evaluation and ablation studies across varying model backbones and KAN configurations, demonstrate that ABFR-KAN consistently outperforms state-of-the-art baselines for autism spectrum distorder (ASD) classification. Our code is available at https://github.com/tbwa233/ABFR-KAN.

</details>


### [40] [Robust Assembly Progress Estimation via Deep Metric Learning](https://arxiv.org/abs/2601.00422)
*Kazuma Miura,Sarthak Pathak,Kazunori Umeda*

Main category: cs.CV

TL;DR: 提出基于四元组损失的异常检测网络，用于在遮挡或视觉变化微小情况下准确估计产品装配进度，在桌面PC数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 智能工厂中手动多日装配任务的进度监控具有挑战性，现有方法在连续任务间视觉变化细微时容易误分类，需要更鲁棒的系统来处理遮挡和微小视觉变化。

Method: 提出异常四元组网络，采用基于四元组损失的学习方法处理异常图像，并引入自定义数据加载器策略性地选择训练样本以提高估计精度。

Result: 在桌面PC装配数据集上，异常四元组网络优于现有方法，估计精度提高1.3%，相邻任务间误分类率降低1.9%。

Conclusion: 提出的方法在遮挡或视觉变化微小情况下能有效估计装配进度，验证了四元组损失和策略性样本选择的有效性。

Abstract: In recent years, the advancement of AI technologies has accelerated the development of smart factories. In particular, the automatic monitoring of product assembly progress is crucial for improving operational efficiency, minimizing the cost of discarded parts, and maximizing factory productivity. However, in cases where assembly tasks are performed manually over multiple days, implementing smart factory systems remains a challenge. Previous work has proposed Anomaly Triplet-Net, which estimates assembly progress by applying deep metric learning to the visual features of products. Nevertheless, when visual changes between consecutive tasks are subtle, misclassification often occurs. To address this issue, this paper proposes a robust system for estimating assembly progress, even in cases of occlusion or minimal visual change, using a small-scale dataset. Our method leverages a Quadruplet Loss-based learning approach for anomaly images and introduces a custom data loader that strategically selects training samples to enhance estimation accuracy. We evaluated our approach using a image datasets: captured during desktop PC assembly. The proposed Anomaly Quadruplet-Net outperformed existing methods on the dataset. Specifically, it improved the estimation accuracy by 1.3% and reduced misclassification between adjacent tasks by 1.9% in the desktop PC dataset and demonstrating the effectiveness of the proposed method.

</details>


### [41] [CPPO: Contrastive Perception for Vision Language Policy Optimization](https://arxiv.org/abs/2601.00501)
*Ahmad Rezaei,Mohsen Gholami,Saeed Ranjbar Alvar,Kevin Cannons,Mohammad Asiful Hossain,Zhou Weimin,Shunbo Zhou,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: CPPO是一种用于微调视觉语言模型的对比感知策略优化方法，通过检测扰动输入下模型输出的熵变化来识别感知标记，并引入对比感知损失来增强感知一致性，无需额外模型。


<details>
  <summary>Details</summary>
Motivation: 虽然强化学习在语言模型推理方面取得了进展，但将其扩展到多模态推理需要同时改进感知和推理能力。先前的工作主要通过显式感知奖励来解决这一挑战，但分离感知标记和推理标记很困难，需要额外的LLM、真实数据、强制分离感知与推理，或对所有输出标记不加区分地应用奖励。

Method: CPPO通过检测扰动输入图像下模型输出的熵变化来识别感知标记，然后在RL目标函数中引入对比感知损失（CPL），该损失在信息保留扰动下强制一致性，在信息移除扰动下强制敏感性。

Result: 实验表明，CPPO超越了先前的感知奖励方法，同时避免了额外模型，使训练更加高效和可扩展。

Conclusion: CPPO提供了一种有效的方法来改进视觉语言模型的感知能力，通过对比感知损失和熵变化检测，解决了多模态强化学习中感知与推理分离的挑战。

Abstract: We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.

</details>


### [42] [All-in-One Video Restoration under Smoothly Evolving Unknown Weather Degradations](https://arxiv.org/abs/2601.00533)
*Wenrui Li,Hongtao Chen,Yao Xiao,Wangmeng Zuo,Jiantao Zhou,Yonghong Tian,Xiaopeng Fan*

Main category: cs.CV

TL;DR: ORCANet提出了一种处理视频中平滑演化未知退化（SEUD）场景的方法，通过粗强度估计去雾模块和流提示生成模块，结合静态和动态提示，实现视频恢复的时域一致性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视频恢复方法主要关注逐帧的退化变化，忽略了真实世界中退化过程的时域连续性。实际上，退化类型和强度会随时间平滑演化，多种退化可能共存或逐渐过渡。因此需要处理平滑演化未知退化（SEUD）场景的新方法。

Method: 提出ORCANet网络，包含两个核心模块：1）粗强度估计去雾（CIED）模块，利用物理先验估计雾霾强度并提供粗去雾特征作为初始化；2）流提示生成（FPG）模块，提取退化特征，生成捕获片段级退化类型的静态提示和适应帧级强度变化的动态提示。此外，采用标签感知监督机制提升不同退化下静态提示表示的可区分性。

Result: 大量实验表明，ORCANet在恢复质量、时域一致性和鲁棒性方面优于基于图像和视频的基线方法。同时设计了灵活的合成流程，可生成具有单一、复合和演化退化的时域一致视频。

Conclusion: 该研究提出了SEUD场景和ORCANet方法，有效解决了视频中平滑演化未知退化的恢复问题，通过结合物理先验和自适应提示机制，实现了高质量、时域一致的视频恢复。

Abstract: All-in-one image restoration aims to recover clean images from diverse unknown degradations using a single model. But extending this task to videos faces unique challenges. Existing approaches primarily focus on frame-wise degradation variation, overlooking the temporal continuity that naturally exists in real-world degradation processes. In practice, degradation types and intensities evolve smoothly over time, and multiple degradations may coexist or transition gradually. In this paper, we introduce the Smoothly Evolving Unknown Degradations (SEUD) scenario, where both the active degradation set and degradation intensity change continuously over time. To support this scenario, we design a flexible synthesis pipeline that generates temporally coherent videos with single, compound, and evolving degradations. To address the challenges in the SEUD scenario, we propose an all-in-One Recurrent Conditional and Adaptive prompting Network (ORCANet). First, a Coarse Intensity Estimation Dehazing (CIED) module estimates haze intensity using physical priors and provides coarse dehazed features as initialization. Second, a Flow Prompt Generation (FPG) module extracts degradation features. FPG generates both static prompts that capture segment-level degradation types and dynamic prompts that adapt to frame-level intensity variations. Furthermore, a label-aware supervision mechanism improves the discriminability of static prompt representations under different degradations. Extensive experiments show that ORCANet achieves superior restoration quality, temporal consistency, and robustness over image and video-based baselines. Code is available at https://github.com/Friskknight/ORCANet-SEUD.

</details>


### [43] [FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection](https://arxiv.org/abs/2601.00535)
*Ruiqiang Zhang,Hengyi Wang,Chang Liu,Guanjie Wang,Zehua Ma,Weiming Zhang*

Main category: cs.CV

TL;DR: FreeText：无需训练、即插即用的框架，通过利用DiT模型的内在机制，解决文本到图像生成中的文本渲染问题，特别是在多行布局、密集排版和中文等长尾脚本方面。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型在开放域合成方面表现出色，但在精确文本渲染方面仍然存在困难，特别是对于多行布局、密集排版和中文等长尾脚本。现有解决方案通常需要昂贵的重新训练或严格的外部布局约束，这会降低美观性并限制灵活性。

Method: FreeText将问题分解为"在哪里写"和"写什么"两个部分。对于"在哪里写"，通过读取图像到文本注意力的token-wise空间归因来定位书写区域，使用sink-like tokens作为稳定的空间锚点，并通过拓扑感知细化产生高置信度掩码。对于"写什么"，引入频谱调制字形注入（SGMI），通过频域带通调制注入噪声对齐的字形先验，以增强字形结构并抑制语义泄漏。

Result: 在Qwen-Image、FLUX.1-dev和SD3变体上的广泛实验，在长文本基准测试、CVTG和自建的CLT-Bench上显示，文本可读性持续提升，同时很大程度上保持了语义对齐和美学质量，推理开销适中。

Conclusion: FreeText是一个无需训练、即插即用的框架，通过利用DiT模型的内在机制，有效解决了文本到图像生成中的文本渲染问题，在保持语义对齐和美学质量的同时显著提升了文本可读性。

Abstract: Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \emph{Diffusion Transformer (DiT)} models. \textbf{FreeText} decomposes the problem into \emph{where to write} and \emph{what to write}. For \emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.

</details>


### [44] [A Comprehensive Dataset for Human vs. AI Generated Image Detection](https://arxiv.org/abs/2601.00553)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Vasu Sharma,Vinija Jain,Aman Chadha,Aishwarya Naresh Reganti,Amitava Das*

Main category: cs.CV

TL;DR: 发布MS COCOAI数据集，包含96000个真实和AI生成图像，用于检测AI生成图像和识别生成模型


<details>
  <summary>Details</summary>
Motivation: 随着Stable Diffusion、DALL-E等生成式AI系统的发展，合成图像越来越难以与真实照片区分，导致误导性内容和虚假信息传播，因此迫切需要有效的检测方法

Method: 基于MS COCO数据集构建MS COCOAI数据集，使用五种生成器（Stable Diffusion 3、2.1、SDXL、DALL-E 3、MidJourney v6）生成合成图像，提出两个检测任务：图像真实性分类和生成模型识别

Result: 创建了包含96000个数据点的公开数据集，支持AI生成图像检测研究，数据集已在Hugging Face平台发布

Conclusion: MS COCOAI数据集为AI生成图像检测提供了重要资源，有助于应对生成式AI带来的虚假信息挑战，促进相关研究发展

Abstract: Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.

</details>


### [45] [Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios](https://arxiv.org/abs/2601.00537)
*Guangqian Guo,Pengfei Chen,Yong Guo,Huafeng Chen,Boqiang Zhang,Shan Gao*

Main category: cs.CV

TL;DR: VNS-SAM 通过 Mask-Edge Token Interactive decoder 和 Non-Salient Feature Mining module 增强 SAM 在视觉非显著场景下的分割能力，同时保持其零样本泛化性。


<details>
  <summary>Details</summary>
Motivation: SAM 在视觉非显著场景（前景与背景对比度低）中表现不佳，现有方法难以捕捉准确轮廓。需要提升 SAM 对此类场景的感知能力，同时保持其零样本泛化优势。

Method: 提出 VNS-SAM，包含两个核心设计：1) Mask-Edge Token Interactive decoder 通过掩码和边缘标记交互增强轮廓感知；2) Non-Salient Feature Mining module 挖掘 SAM 的低层特征来理解非显著特征。仅需少量参数增量，可在4小时内完成优化。

Result: 构建了包含35K+图像的 VNS-SEG 数据集，涵盖多种视觉非显著场景。实验表明 VNS-SAM 在各种 VNS 分割任务中表现优异，特别是在零样本设置下，展示了广泛的现实应用潜力。

Conclusion: VNS-SAM 有效提升了 SAM 在视觉非显著场景下的分割性能，同时保持了其零样本泛化能力，具有实际可行性和应用价值。

Abstract: Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.

</details>


### [46] [DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction](https://arxiv.org/abs/2601.00542)
*Jiacheng Sui,Yujie Zhou,Li Niu*

Main category: cs.CV

TL;DR: DynaDrag提出了一种新的基于预测-移动框架的图像拖拽编辑方法，通过迭代执行运动预测和运动监督，动态调整有效处理点，解决了传统方法中的跟踪丢失和模糊问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于移动-跟踪框架的图像拖拽编辑方法存在跟踪丢失和模糊跟踪的固有问题，而其他框架的方法则存在源图像与目标编辑图像差距过大、中间点不合理导致编辑性差等问题。

Method: 提出DynaDrag方法，采用预测-移动框架，迭代执行运动预测和运动监督：1）运动预测预测处理点应该移动的位置；2）运动监督根据预测结果拖拽处理点；3）动态调整有效处理点以提升性能。

Result: 在人脸和人体数据集上的实验表明，DynaDrag在图像拖拽编辑任务上优于先前的工作。

Conclusion: DynaDrag通过创新的预测-移动框架和动态处理点调整机制，有效解决了传统图像拖拽编辑方法的局限性，实现了更高质量的像素级图像操作。

Abstract: To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.

</details>


### [47] [SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array](https://arxiv.org/abs/2601.00551)
*Shuang Li,Yibing Wang,Jian Gao,Chulhong Kim,Seongwook Choi,Yu Zhang,Qian Chen,Yao Yao,Changhui Li*

Main category: cs.CV

TL;DR: SlingBAG Pro：一种基于点云迭代的先进重建算法，扩展了不规则几何换能器阵列的兼容性，在保持高质量重建的同时减少换能器数量，并显著缩短重建时间。


<details>
  <summary>Details</summary>
Motivation: 临床应用中需要高质量三维光声成像，但传统不规则几何换能器阵列面临挑战：传统迭代重建算法难以处理不规则阵列配置，存在计算复杂度高、内存需求大、重建时间长等问题。

Method: 基于Sliding ball adaptive growth (SlingBAG)方法的点云迭代概念，扩展至任意阵列几何形状。采用分层优化策略，结合零梯度滤波和迭代过程中逐步增加的时间采样率，快速去除冗余空间点云，加速收敛。

Result: 相比原始SlingBAG算法，SlingBAG Pro在不规则阵列几何下实现了点云三维光声重建速度提升高达2.2倍。通过仿真和活体小鼠实验验证了方法的有效性。

Conclusion: SlingBAG Pro算法能够有效解决不规则几何换能器阵列的三维光声成像重建问题，在保持高质量重建的同时显著提升计算效率，为临床应用提供了实用解决方案。

Abstract: High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.

</details>


### [48] [Noise-Robust Tiny Object Localization with Flows](https://arxiv.org/abs/2601.00617)
*Huixin Sun,Linlin Yang,Ronyu Chen,Kerui Gu,Baochang Zhang,Angela Yao,Xianbin Cao*

Main category: cs.CV

TL;DR: TOLF是一个针对微小目标检测的噪声鲁棒定位框架，使用归一化流进行误差建模和不确定性引导优化，解决了微小目标对标注噪声敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管通用目标检测取得了显著进展，但微小目标的性能仍然明显低于正常尺度目标。研究发现微小目标对标注噪声高度敏感，优化严格的定位目标容易导致噪声过拟合。

Method: 提出Tiny Object Localization with Flows (TOLF)框架：1）使用归一化流进行灵活的误差建模，捕捉复杂的非高斯预测分布；2）采用不确定性感知的梯度调制机制，抑制从高不确定性、易受噪声影响的样本中学习。

Result: 在三个数据集上的广泛实验验证了方法的有效性。特别是在AI-TOD数据集上，TOLF将DINO基线的AP提升了1.2%。

Conclusion: TOLF通过流基误差建模和不确定性引导优化，有效解决了微小目标检测中的噪声鲁棒性问题，显著提升了微小目标的定位性能。

Abstract: Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.

</details>


### [49] [AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models](https://arxiv.org/abs/2601.00561)
*Jintao Lin,Bowen Dong,Weikang Shi,Chenyang Lei,Suiyun Zhang,Rui Liu,Xihui Liu*

Main category: cs.CV

TL;DR: AEGIS是一个评估统一多模态模型世界知识应用能力的多任务基准，包含1050个手动标注的问题，涵盖21个主题和6种推理类型，并提出了确定性检查表评估协议以提高评估可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估统一多模态模型的世界知识应用能力方面存在不足，它们通常是孤立的单任务评估，诊断能力有限。需要更全面的多任务基准来评估模型在不同任务中的世界知识应用能力。

Method: 提出了AEGIS基准，包含1050个具有挑战性的手动标注问题，涵盖视觉理解、生成、编辑和交错生成等任务，涉及21个主题和6种推理类型。同时提出了确定性检查表评估协议，用原子化的"是/否"判断替代模糊的提示评分，提高评估可靠性。

Result: 实验表明大多数统一多模态模型存在严重的世界知识缺陷，在复杂推理任务中性能显著下降。简单的插件式推理模块可以部分缓解这些弱点，这为未来研究指明了方向。

Conclusion: 世界知识推理是统一多模态模型发展的关键前沿领域，需要更全面的评估方法和改进策略来提升模型的世界知识应用能力。

Abstract: The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\emph{i.e.}, \textbf{A}ssessing \textbf{E}diting, \textbf{G}eneration, \textbf{I}nterpretation-Understanding for \textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.

</details>


### [50] [A Cascaded Information Interaction Network for Precise Image Segmentation](https://arxiv.org/abs/2601.00562)
*Hewen Xiao,Jie Mei,Guangfu Ma,Weiren Wu*

Main category: cs.CV

TL;DR: 提出一种集成全局信息引导模块的级联卷积神经网络，通过融合多尺度特征提升复杂场景下的分割精度


<details>
  <summary>Details</summary>
Motivation: 视觉感知对自主行为至关重要，但复杂场景下的鲁棒分割仍是挑战。传统方法在视觉杂乱或模糊环境中表现不佳，需要更好的特征融合机制

Method: 采用级联卷积神经网络，集成新颖的全局信息引导模块，有效融合低层纹理细节与高层语义特征，克服单尺度特征提取的局限性

Result: 在基准图像分割数据集上的实验表明，该框架实现了优越的精度，超越了现有最先进方法，在视觉杂乱或模糊环境中表现尤为突出

Conclusion: 该方法有效提升了分割精度，在实用机器人应用中具有良好部署潜力，证明了多尺度特征融合架构的创新价值

Abstract: Visual perception plays a pivotal role in enabling autonomous behavior, offering a cost-effective and efficient alternative to complex multi-sensor systems. However, robust segmentation remains a challenge in complex scenarios. To address this, this paper proposes a cascaded convolutional neural network integrated with a novel Global Information Guidance Module. This module is designed to effectively fuse low-level texture details with high-level semantic features across multiple layers, thereby overcoming the inherent limitations of single-scale feature extraction. This architectural innovation significantly enhances segmentation accuracy, particularly in visually cluttered or blurred environments where traditional methods often fail. Experimental evaluations on benchmark image segmentation datasets demonstrate that the proposed framework achieves superior precision, outperforming existing state-of-the-art methods. The results highlight the effectiveness of the approach and its promising potential for deployment in practical robotic applications.

</details>


### [51] [GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval](https://arxiv.org/abs/2601.00584)
*Mingyu Jeon,Sunjae Yoon,Jonghee Kim,Junyeoung Kim*

Main category: cs.CV

TL;DR: 提出GranAlign框架，通过粒度感知对齐解决零样本视频时刻检索中的语义粒度不匹配问题，无需训练即可在多个基准上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本视频时刻检索方法虽然利用预训练知识实现视频-语言联合表示，但未能平衡不同模态间的语义粒度，导致检索不准确。

Method: 提出GranAlign框架，包含两个互补技术：1) 基于粒度的查询重写生成多粒度语义；2) 查询感知的标题生成将查询意图嵌入视频内容。通过将多级查询与查询无关和查询感知的标题配对，有效解决语义不匹配。

Result: 在三个主要基准测试(QVHighlights, Charades-STA, ActivityNet-Captions)上均达到新的SOTA，在具有挑战性的QVHighlights数据集上mAP@avg提升3.23%。

Conclusion: GranAlign框架通过粒度感知对齐有效解决了零样本视频时刻检索中的语义粒度不匹配问题，无需训练即可显著提升性能，为跨模态对齐提供了新思路。

Abstract: Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.

</details>


### [52] [SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation](https://arxiv.org/abs/2601.00590)
*Yiling Wang,Zeyu Zhang,Yiran Wang,Hao Tang*

Main category: cs.CV

TL;DR: SafeMo：基于最小化运动遗忘的两阶段机器遗忘策略，在连续空间实现安全人体运动生成，避免离散码本替换的缺陷，并提供首个安全文本-运动数据集。


<details>
  <summary>Details</summary>
Motivation: 现有基于离散VQ-VAE码本替换的安全方法存在两大缺陷：1）替换被良性提示重用的码本条目会导致日常任务性能下降；2）离散令牌方法引入量化和平滑度损失，导致伪影和不连贯过渡。此外，现有文本-运动数据集天然包含不安全内容，不适合安全驱动的机器学习。

Method: 提出SafeMo框架，集成最小化运动遗忘（MMU）的两阶段机器遗忘策略：1）在连续空间进行安全遗忘，避免码本损失；2）保持连续运动学特性。同时构建首个安全文本-运动数据集SafeMoVAE-29K，包含重写的安全文本提示和精炼的连续运动。

Result: 在HumanML3D和Motion-X数据集上，SafeMo的遗忘性能显著优于现有最佳方法LCR，遗忘集FID分别提高2.5倍和14.4倍，同时在安全提示上的良性性能相当或更好，实现了优秀的安全-效用权衡。

Conclusion: SafeMo通过连续空间的两阶段机器遗忘策略，有效解决了现有离散码本替换方法的安全缺陷，在保持运动自然过渡的同时实现了安全人体运动生成，为可信赖的运动生成提供了新框架。

Abstract: Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.

</details>


### [53] [Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model](https://arxiv.org/abs/2601.00716)
*Hao Guan,Li Zhou*

Main category: cs.CV

TL;DR: 该研究提出结合输入数据分布偏移检测和输出置信度指标的方法，用于监控病理视觉语言模型在数据偏移下的性能退化，开发了DomainSAT工具箱进行系统分析。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在医疗图像分析中表现出色，但部署后当输入数据分布发生变化时，性能可能退化。由于缺乏标注数据，检测这种性能退化具有挑战性，但对临床可靠性至关重要。

Method: 研究输入级数据偏移和输出级预测行为，开发DomainSAT工具箱集成代表性偏移检测算法，并引入无标签的置信度退化指标，结合两种方法监控模型可靠性。

Result: 输入数据偏移检测能有效识别分布变化并提供早期诊断信号，但不总是对应实际性能退化。置信度指标与性能退化密切相关，可作为输入偏移检测的有效补充。结合两种方法能更可靠地检测和解释数据偏移下的性能退化。

Conclusion: 结合输入数据偏移检测和输出置信度指标提供了一个实用且互补的框架，用于监控数字病理学中基础模型的可靠性，有助于提高临床应用的可靠性。

Abstract: Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.

</details>


### [54] [Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception](https://arxiv.org/abs/2601.00598)
*Xianhui Liu,Siqi Jiang,Yi Xie,Yuqing Lin,Siao Liu*

Main category: cs.CV

TL;DR: 该论文提出了一种解决RGB-红外多模态感知中优化偏差问题的新方法，通过模态主导指数量化模态主导现象，并开发了模态主导感知跨模态学习框架来平衡优化动态。


<details>
  <summary>Details</summary>
Motivation: RGB-红外多模态感知在复杂物理环境的嵌入式多媒体系统中至关重要，但现有跨模态融合方法存在优化偏差问题。由于信息密度和特征质量的不对称性，训练过程会过度强调主导模态，阻碍有效融合。

Method: 提出模态主导指数(MDI)来量化模态主导现象，通过联合建模特征熵和梯度贡献来测量模态主导程度。基于MDI开发了模态主导感知跨模态学习(MDACL)框架，包含分层跨模态引导(HCG)来增强特征对齐，以及对抗平衡正则化(AER)来平衡融合过程中的优化动态。

Result: 在三个RGB-红外基准测试上的广泛实验表明，MDACL能有效缓解优化偏差，并实现了最先进的性能。

Conclusion: 该研究通过量化模态主导现象并开发相应的平衡优化框架，有效解决了RGB-红外多模态感知中的优化偏差问题，为跨模态融合提供了新的解决方案。

Abstract: RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.

</details>


### [55] [RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation](https://arxiv.org/abs/2601.00625)
*Junxiao Xue,Pavel Smirnov,Ziao Li,Yunyun Shi,Shi Chen,Xinyi Yin,Xiaohan Yue,Lei Wang,Yiduo Wang,Feng Lin,Yijia Chen,Xiao Ma,Xiaoran Yan,Qing Zhang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: RePose：用于康复训练的实时3D人体姿态估计与运动分析方法，通过多摄像头RGB视频输入实现端到端的实时监测与评估，提供即时反馈指导患者正确执行康复动作。


<details>
  <summary>Details</summary>
Motivation: 康复训练中需要实时监测和评估患者动作，提供即时反馈以确保患者正确执行康复练习，帮助恢复肌肉力量和运动功能。现有方法在实时性、多人干扰处理和姿态平滑度方面存在不足。

Method: 1) 提出端到端实时人体姿态估计与运动分析统一流程；2) 针对医疗康复场景设计快速跟踪方法（单帧<1ms）；3) 改进SmoothNet用于实时姿态估计，减少误差并平滑运动；4) 基于Unity平台实现实时监测评估和肌肉应力可视化。

Result: 方法能够实时监测和评估康复训练中的患者动作，提供即时反馈和指导。快速跟踪方法在多人干扰场景下仍能高效工作，改进的姿态估计方法有效减少误差并平滑运动状态。

Conclusion: RePose为康复训练提供了一种有效的实时3D姿态估计与运动分析解决方案，能够帮助患者正确执行康复动作，加速恢复过程，具有实际应用价值。

Abstract: We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.

</details>


### [56] [HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis](https://arxiv.org/abs/2601.00626)
*Shuren Gabriel Yu,Sikang Ren,Yongji Tian*

Main category: cs.CV

TL;DR: 提出HyperPriv-EPN框架，利用超图和学习使用特权信息方法，通过双流蒸馏让学生图仅从视觉特征中学习模拟术后语义结构，实现术前室管膜瘤预后预测


<details>
  <summary>Details</summary>
Motivation: 室管膜瘤术前预后对治疗规划至关重要，但MRI缺乏术后手术报告中的语义信息。现有多模态方法在推理时无法利用这些特权文本数据，需要解决术前数据与术后知识之间的差距

Method: 提出基于超图的LUPI框架HyperPriv-EPN，采用Severed Graph策略，使用共享编码器处理教师图（包含术后特权信息）和学生图（仅限术前数据），通过双流蒸馏让学生学习从视觉特征中模拟语义社区结构

Result: 在311名患者的多中心队列中验证，HyperPriv-EPN实现了最先进的诊断准确性和生存分层，有效将专家知识转移到术前环境

Conclusion: 该框架解锁了历史术后数据的价值，可在推理时无需文本的情况下指导新患者的诊断，解决了术前预后预测中特权信息不可用的问题

Abstract: Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.

</details>


### [57] [Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach](https://arxiv.org/abs/2601.00645)
*Shrikant Kapse,Priyankkumar Dhrangdhariya,Priya Kedia,Manasi Patwardhan,Shankar Kausley,Soumyadipta Maiti,Beena Rai,Shirish Karande*

Main category: cs.CV

TL;DR: 基于图像的深度学习为马铃薯储存期间的质量监测提供了非侵入式、可扩展的解决方案，通过预训练模型实现了发芽检测、重量损失估计和保质期预测。


<details>
  <summary>Details</summary>
Motivation: 解决马铃薯储存期间的质量监测挑战，包括发芽检测、重量损失估计和保质期预测，以实现自动化分类和库存管理，减少食物浪费。

Method: 在200天的温控条件下收集图像和重量数据，利用ResNet、VGG、DenseNet和Vision Transformer等预训练架构，设计了两个专门模型：高精度二分类发芽检测器和多分类重量损失/保质期预测器。

Result: DenseNet在发芽检测中达到98.03%准确率；保质期预测在粗分类（2-5类）时准确率超过89.83%，细分类（6-8类）时因视觉差异细微和数据有限而准确率下降。

Conclusion: 图像模型可集成到自动化系统中，实现早期发芽识别和动态分类，改善库存管理和定价策略。未来需开发适用于不同品种和储存条件的通用模型，增强适应性和可扩展性。

Abstract: Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.

</details>


### [58] [Reconstructing Building Height from Spaceborne TomoSAR Point Clouds Using a Dual-Topology Network](https://arxiv.org/abs/2601.00658)
*Zhaiyu Chen,Yuanyuan Wang,Yilei Shi,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 提出首个基于学习的框架，将原始TomoSAR点云转换为高分辨率建筑高度图，通过双拓扑网络处理噪声和缺失数据问题


<details>
  <summary>Details</summary>
Motivation: TomoSAR点云存在噪声、各向异性点分布和数据空洞等问题，阻碍了准确的建筑高度重建，需要新的解决方案

Method: 采用双拓扑网络架构，交替处理点分支（建模不规则散射特征）和网格分支（强制空间一致性），联合处理两种表示以去噪和填补缺失区域

Result: 在慕尼黑和柏林数据上的实验验证了方法的有效性，并可扩展到结合光学卫星影像进一步提升重建质量

Conclusion: 这是首个直接从TomoSAR点云进行大规模城市高度映射的概念验证，为可靠的建筑高度估计提供了有前景的替代方案

Abstract: Reliable building height estimation is essential for various urban applications. Spaceborne SAR tomography (TomoSAR) provides weather-independent, side-looking observations that capture facade-level structure, offering a promising alternative to conventional optical methods. However, TomoSAR point clouds often suffer from noise, anisotropic point distributions, and data voids on incoherent surfaces, all of which hinder accurate height reconstruction. To address these challenges, we introduce a learning-based framework for converting raw TomoSAR points into high-resolution building height maps. Our dual-topology network alternates between a point branch that models irregular scatterer features and a grid branch that enforces spatial consistency. By jointly processing these representations, the network denoises the input points and inpaints missing regions to produce continuous height estimates. To our knowledge, this is the first proof of concept for large-scale urban height mapping directly from TomoSAR point clouds. Extensive experiments on data from Munich and Berlin validate the effectiveness of our approach. Moreover, we demonstrate that our framework can be extended to incorporate optical satellite imagery, further enhancing reconstruction quality. The source code is available at https://github.com/zhu-xlab/tomosar2height.

</details>


### [59] [CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models](https://arxiv.org/abs/2601.00659)
*Neeraj Anand,Samyak Jha,Udbhav Bamba,Rahul Rahaman*

Main category: cs.CV

TL;DR: CRoPS是一个无需训练的幻觉缓解框架，通过选择性移除关键文本标记构建幻觉模型，并结合广义对比解码，在多个基准测试中显著提升LVLM的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在生成幻觉内容的问题，现有无需训练方法存在两个局限：1) 对幻觉来源的假设过于狭窄；2) 在生成后期效果下降，而这时幻觉最可能发生。

Method: 提出CRoPS框架：1) 构建新的幻觉模型，通过选择性移除关键文本标记来捕捉幻觉效应；2) 引入广义对比解码，整合多个幻觉模型以代表多样化的幻觉来源。

Result: CRoPS将CHAIR分数提升20%，在六个基准测试和三个LVLM家族中取得一致增益，优于最先进的无需训练方法。

Conclusion: CRoPS通过创新的幻觉模型构建和广义对比解码，有效缓解了LVLM的幻觉问题，提高了模型的可靠性，且无需额外训练。

Abstract: Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.

</details>


### [60] [Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678)
*Melonie de Almeida,Daniela Ivanova,Tong Shi,John H. Williamson,Paul Henderson*

Main category: cs.CV

TL;DR: 提出Pixel-to-4D框架，通过单张图像构建3D高斯场景表示并采样物体运动，实现快速、相机引导的视频生成，无需迭代去噪注入物体运动。


<details>
  <summary>Details</summary>
Motivation: 现有单图像视频生成方法缺乏鲁棒的用户可控性（如修改相机路径），且相机控制模型在准确建模相机运动、保持时间一致性和几何完整性方面存在困难。需要一种能同时实现相机控制和时间一致性的方法。

Method: 提出新颖框架：1）从单张图像构建3D高斯场景表示；2）在单次前向传播中采样合理的物体运动；3）实现快速、相机引导的视频生成，无需通过迭代去噪将物体运动注入渲染帧。

Result: 在KITTI、Waymo、RealEstate10K和DL3DV-10K数据集上的实验表明，该方法在视频质量和推理效率方面达到最先进水平。

Conclusion: 提出的Pixel-to-4D框架通过3D高斯表示和物体运动采样，实现了高效、可控的单图像视频生成，解决了现有方法在相机控制和时间一致性方面的局限性。

Abstract: Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.

</details>


### [61] [Efficient Deep Demosaicing with Spatially Downsampled Isotropic Networks](https://arxiv.org/abs/2601.00703)
*Cory Fan,Wenchao Zhang*

Main category: cs.CV

TL;DR: 本文提出在图像去马赛克任务中，通过空间下采样可以显著提升各向同性网络的效率和性能，并设计了JD3Net网络验证了这一观点。


<details>
  <summary>Details</summary>
Motivation: 移动平台上的数字成像应用需要轻量高效的网络，但传统的各向同性网络避免空间下采样，导致计算成本过高，不适合移动应用。

Method: 采用基于DeepMAD的数学架构设计技术，设计包含下采样和不包含下采样的简单全卷积网络，并开发了JD3Net作为下采样变体。

Result: 实验证明下采样能提升经验性能，JD3Net在多种图像去马赛克和联合去马赛克去噪任务上表现出色。

Conclusion: 与先前设计相反，空间下采样可以改善各向同性网络的效率和性能，为移动平台上的深度学习去马赛克应用提供了更实用的解决方案。

Abstract: In digital imaging, image demosaicing is a crucial first step which recovers the RGB information from a color filter array (CFA). Oftentimes, deep learning is utilized to perform image demosaicing. Given that most modern digital imaging applications occur on mobile platforms, applying deep learning to demosaicing requires lightweight and efficient networks. Isotropic networks, also known as residual-in-residual networks, have been often employed for image demosaicing and joint-demosaicing-and-denoising (JDD). Most demosaicing isotropic networks avoid spatial downsampling entirely, and thus are often prohibitively expensive computationally for mobile applications. Contrary to previous isotropic network designs, this paper claims that spatial downsampling to a signficant degree can improve the efficiency and performance of isotropic networks. To validate this claim, we design simple fully convolutional networks with and without downsampling using a mathematical architecture design technique adapted from DeepMAD, and find that downsampling improves empirical performance. Additionally, empirical testing of the downsampled variant, JD3Net, of our fully convolutional networks reveals strong empirical performance on a variety of image demosaicing and JDD tasks.

</details>


### [62] [RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization](https://arxiv.org/abs/2601.00705)
*Wei-Tse Cheng,Yen-Jen Chiou,Yuan-Fu Yang*

Main category: cs.CV

TL;DR: RGS-SLAM提出了一种基于高斯泼溅的鲁棒SLAM框架，通过训练无关的对应到高斯初始化替代了传统的残差驱动致密化阶段，实现了更稳定的早期建图和更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统GS-SLAM采用残差驱动致密化，逐步添加高斯分布来填补缺失几何，这种方法可能导致早期建图不稳定且收敛较慢。作者希望开发一种更鲁棒、更高效的高斯泼溅SLAM初始化方法。

Method: 使用DINOv3描述符提取密集多视角对应关系，通过置信度感知的内点分类器进行精炼，然后一次性三角测量生成结构感知的高斯种子分布，作为优化的先验。这种方法完全兼容现有GS-SLAM流程。

Result: 在TUM RGB-D和Replica数据集上评估，RGS-SLAM相比最先进的高斯和点云SLAM系统，在定位和重建精度上达到竞争性或更优水平，收敛速度提升约20%，在纹理丰富和杂乱场景中渲染保真度更高，实时建图性能可达925 FPS。

Conclusion: RGS-SLAM通过训练无关的对应到高斯初始化方法，为高斯泼溅SLAM提供了更稳定、更高效的替代方案，显著改善了早期建图质量和收敛速度，同时保持了实时性能。

Abstract: We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.

</details>


### [63] [Multi-Level Feature Fusion for Continual Learning in Visual Quality Inspection](https://arxiv.org/abs/2601.00725)
*Johannes C. Bauer,Paul Geng,Stephan Trattnig,Petr Dokládal,Rüdiger Daub*

Main category: cs.CV

TL;DR: 提出多级特征融合方法，在制造业质量检测中实现高效持续学习，减少参数和灾难性遗忘


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在制造业质量检测中应用受限，特别是在再制造等变化场景中，需要频繁适应新产品和缺陷模式，这构成了持续学习问题，需要高效训练同时避免灾难性遗忘

Method: 提出多级特征融合方法，利用预训练网络不同深度的特征表示，减少可训练参数的同时保持性能

Result: 方法在不同质量检测问题上能达到端到端训练的性能，但使用显著更少的可训练参数，减少灾难性遗忘，提高对新产品或缺陷的泛化鲁棒性

Conclusion: 多级特征融合方法有效解决了制造业质量检测中的持续学习挑战，在计算效率和避免遗忘之间取得了良好平衡

Abstract: Deep neural networks show great potential for automating various visual quality inspection tasks in manufacturing. However, their applicability is limited in more volatile scenarios, such as remanufacturing, where the inspected products and defect patterns often change. In such settings, deployed models require frequent adaptation to novel conditions, effectively posing a continual learning problem. To enable quick adaptation, the necessary training processes must be computationally efficient while still avoiding effects like catastrophic forgetting. This work presents a multi-level feature fusion (MLFF) approach that aims to improve both aspects simultaneously by utilizing representations from different depths of a pretrained network. We show that our approach is able to match the performance of end-to-end training for different quality inspection problems while using significantly less trainable parameters. Furthermore, it reduces catastrophic forgetting and improves generalization robustness to new product types or defects.

</details>


### [64] [Grading Handwritten Engineering Exams with Multimodal Large Language Models](https://arxiv.org/abs/2601.00730)
*Janez Perš,Jon Muhovič,Andrej Košir,Boštjan Murovec*

Main category: cs.CV

TL;DR: 提出一个基于多模态大语言模型的端到端手写STEM考试自动评分工作流，通过多阶段设计确保可靠性，在真实课程测验中达到接近人工评分的准确度


<details>
  <summary>Details</summary>
Motivation: 手写STEM考试能捕捉开放式推理和图表，但人工评分速度慢且难以扩展，需要自动化解决方案来保持标准考试流程

Method: 端到端工作流：将手写参考答案转换为文本摘要作为评分依据，采用多阶段设计包括格式检查、独立评分器集成、监督聚合和确定性验证模板

Result: 使用GPT-5.2和Gemini-3 Pro后端，在斯洛文尼亚语真实课程测验中，与讲师评分平均绝对差异约8分，偏差低，手动审核触发率约17%

Conclusion: 结构化提示和参考答案基础对准确性至关重要，该工作流能可靠自动评分手写STEM考试，同时保持可审计性和可扩展性

Abstract: Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\approx$17% at $D_{\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.

</details>


### [65] [Unified Primitive Proxies for Structured Shape Completion](https://arxiv.org/abs/2601.00759)
*Zhaiyu Chen,Yuqing Wang,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: UniCo：通过专用路径解码基元，实现单次前向传播完成结构化形状补全，显著提升几何重建质量


<details>
  <summary>Details</summary>
Motivation: 重新思考基元与点云如何交互，发现通过专用路径解码基元比级联方法更有效，旨在实现从非完整数据中获取结构化3D理解

Method: 提出UniCo框架，使用基元代理（可学习查询）在专用路径中解码基元，通过在线目标更新策略耦合基元与点云优化

Result: 在合成和真实数据集上，使用四种独立装配求解器均优于基线方法，Chamfer距离降低达50%，法线一致性提升达7%

Conclusion: 为从非完整数据中获取结构化3D理解提供了有吸引力的解决方案，建立了基元与点云交互的新范式

Abstract: Structured shape completion recovers missing geometry as primitives rather than as unstructured points, which enables primitive-based surface reconstruction. Instead of following the prevailing cascade, we rethink how primitives and points should interact, and find it more effective to decode primitives in a dedicated pathway that attends to shared shape features. Following this principle, we present UniCo, which in a single feed-forward pass predicts a set of primitives with complete geometry, semantics, and inlier membership. To drive this unified representation, we introduce primitive proxies, learnable queries that are contextualized to produce assembly-ready outputs. To ensure consistent optimization, our training strategy couples primitives and points with online target updates. Across synthetic and real-world benchmarks with four independent assembly solvers, UniCo consistently outperforms recent baselines, lowering Chamfer distance by up to 50% and improving normal consistency by up to 7%. These results establish an attractive recipe for structured 3D understanding from incomplete data. Project page: https://unico-completion.github.io.

</details>


### [66] [Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection](https://arxiv.org/abs/2601.00789)
*Shukesh Reddy,Srijan Das,Abhijit Das*

Main category: cs.CV

TL;DR: 本文探索将自监督学习作为辅助任务来优化深度伪造检测的主要任务，通过融合自监督任务的特征表示来提升检测器的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造检测器在跨数据集评估中泛化能力有限，需要探索如何利用自监督学习作为辅助任务来增强主要任务的性能。

Method: 研究不同的训练方案组合，将自监督学习作为辅助任务，并融合自监督任务的特征表示来构建更强大的特征表示。

Result: 在多个数据集（DF40、FaceForensics++、Celeb-DF、DFD、FaceShifter、UADFV）上实验，结果显示在跨数据集评估中比当前最先进的检测器具有更好的泛化性能。

Conclusion: 融合自监督辅助任务的特征表示能够充分利用两种任务的潜力，为深度伪造检测提供独特的特征表示，从而提升主要任务的性能。

Abstract: In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.

</details>


### [67] [Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI](https://arxiv.org/abs/2601.00794)
*Wenhui Chu,Nikolaos V. Tsekos*

Main category: cs.CV

TL;DR: 本文提出LNU-Net和IBU-Net两种深度学习架构用于左心室MRI图像分割，分别基于层归一化和实例-批量归一化，在性能上优于原始U-Net和其他先进方法。


<details>
  <summary>Details</summary>
Motivation: 左心室分割对心脏图像的临床量化和诊断至关重要，需要更精确的分割方法来提高诊断准确性。

Method: 提出两种新型架构：LNU-Net在卷积块中应用层归一化，IBU-Net在第一个卷积块中结合实例和批量归一化。采用下采样特征提取和上采样精确定位的U-Net结构，并使用仿射变换和弹性变形进行数据增强。

Result: 在包含45名患者805张MRI图像的数据集上评估，提出的方法在Dice系数和平均垂直距离指标上优于原始U-Net和其他先进方法。

Conclusion: LNU-Net和IBU-Net是有效的左心室分割架构，通过不同的归一化策略提升了分割性能，为临床诊断提供了更可靠的量化工具。

Abstract: Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.

</details>


### [68] [AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction](https://arxiv.org/abs/2601.00796)
*Jiewen Chan,Zhenjun Zhao,Yu-Lun Liu*

Main category: cs.CV

TL;DR: AdaGaR提出自适应高斯表示和时序连续性约束的统一框架，用于从单目视频重建动态3D场景，在频率适应性和运动平滑性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：单高斯基元具有低通滤波特性，标准Gabor函数存在能量不稳定问题，且缺乏时序连续性约束导致插值时出现运动伪影。

Method: 1) 自适应Gabor表示：通过可学习频率权重和自适应能量补偿扩展高斯函数；2) 时序连续性：使用三次Hermite样条和时序曲率正则化确保平滑运动；3) 自适应初始化：结合深度估计、点跟踪和前景掩码建立稳定点云分布。

Result: 在Tap-Vid DAVIS数据集上达到SOTA性能（PSNR 35.49, SSIM 0.9433, LPIPS 0.0723），在帧插值、深度一致性、视频编辑和立体视图合成等任务上表现出强泛化能力。

Conclusion: AdaGaR通过统一框架解决了动态场景建模中的频率适应性和时序连续性挑战，在多个评估指标和下游任务上表现出优越性能。

Abstract: Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [69] [Evaluating Anomaly Detectors for Simulated Highly Imbalanced Industrial Classification Problems](https://arxiv.org/abs/2601.00005)
*Lesley Wheat,Martin v. Mohrenschildt,Saeid Habibi*

Main category: cs.LG

TL;DR: 该论文系统评估了14种异常检测算法在不同训练数据规模下的性能，发现最佳检测器高度依赖于训练集中故障样本的总数量，而非健康样本数量。


<details>
  <summary>Details</summary>
Motivation: 工业系统中机器学习面临极端类别不平衡的挑战，主要由于训练期间故障数据有限。需要评估异常检测算法在真实工程约束下的性能。

Method: 使用基于超球面异常分布的合成数据集（2D和10D），在异常率0.05%-20%、训练规模1000-10000的范围内，对14种检测器进行基准测试，测试集大小为40000。

Result: 当故障样本少于20个时，无监督方法（kNN/LOF）表现最佳；当有30-50个故障样本时，半监督（XGBOD）和监督（SVM/CatBoost）方法性能大幅提升。半监督方法在10个特征时优势明显，但在2个特征时无显著优势。

Conclusion: 研究揭示了异常检测方法在小数据集上的泛化性能下降问题，为工业环境中部署异常检测提供了实用指导：最佳检测器选择取决于可用故障样本数量。

Abstract: Machine learning offers potential solutions to current issues in industrial systems in areas such as quality control and predictive maintenance, but also faces unique barriers in industrial applications. An ongoing challenge is extreme class imbalance, primarily due to the limited availability of faulty data during training. This paper presents a comprehensive evaluation of anomaly detection algorithms using a problem-agnostic simulated dataset that reflects real-world engineering constraints. Using a synthetic dataset with a hyper-spherical based anomaly distribution in 2D and 10D, we benchmark 14 detectors across training datasets with anomaly rates between 0.05% and 20% and training sizes between 1 000 and 10 000 (with a testing dataset size of 40 000) to assess performance and generalization error. Our findings reveal that the best detector is highly dependant on the total number of faulty examples in the training dataset, with additional healthy examples offering insignificant benefits in most cases. With less than 20 faulty examples, unsupervised methods (kNN/LOF) dominate; but around 30-50 faulty examples, semi-supervised (XGBOD) and supervised (SVM/CatBoost) detectors, we see large performance increases. While semi-supervised methods do not show significant benefits with only two features, the improvements are evident at ten features. The study highlights the performance drop on generalization of anomaly detection methods on smaller datasets, and provides practical insights for deploying anomaly detection in industrial environments.

</details>


### [70] [Yahtzee: Reinforcement Learning Techniques for Stochastic Combinatorial Games](https://arxiv.org/abs/2601.00007)
*Nicholas A. Pape*

Main category: cs.LG

TL;DR: 该研究将Yahtzee游戏构建为MDP，使用多种策略梯度方法训练自博弈智能体，发现A2C在固定训练预算下表现最稳健，达到接近最优DP分数的95%，但所有模型都难以学习上层奖励策略。


<details>
  <summary>Details</summary>
Motivation: Yahtzee游戏具有随机性、组合结构和延迟奖励的特点，是一个有趣的中等规模强化学习基准。虽然单人Yahtzee的最优策略可以通过动态规划计算，但多人版本难以处理，因此需要近似方法。

Method: 将Yahtzee构建为马尔可夫决策过程，使用REINFORCE、A2C和PPO等策略梯度方法训练自博弈智能体，采用具有共享主干的多头网络。对特征和动作编码、架构、回报估计器和熵正则化进行了消融研究。

Result: 在固定训练预算下，REINFORCE和PPO对超参数敏感且未能达到接近最优性能，而A2C在各种设置下都能稳健训练。最佳智能体在10万次评估游戏中获得中位数分数241.78分，达到最优DP分数254.59的95%，上层奖励和Yahtzee达成率分别为24.9%和34.1%。

Conclusion: A2C在Yahtzee游戏中表现出最稳健的学习性能，但所有模型都难以学习上层奖励策略，过度依赖"四相同"策略，突显了长期信用分配和探索的持续挑战。

Abstract: Yahtzee is a classic dice game with a stochastic, combinatorial structure and delayed rewards, making it an interesting mid-scale RL benchmark. While an optimal policy for solitaire Yahtzee can be computed using dynamic programming methods, multiplayer is intractable, motivating approximation methods. We formulate Yahtzee as a Markov Decision Process (MDP), and train self-play agents using various policy gradient methods: REINFORCE, Advantage Actor-Critic (A2C), and Proximal Policy Optimization (PPO), all using a multi-headed network with a shared trunk. We ablate feature and action encodings, architecture, return estimators, and entropy regularization to understand their impact on learning. Under a fixed training budget, REINFORCE and PPO prove sensitive to hyperparameters and fail to reach near-optimal performance, whereas A2C trains robustly across a range of settings. Our agent attains a median score of 241.78 points over 100,000 evaluation games, within 5.0\% of the optimal DP score of 254.59, achieving the upper section bonus and Yahtzee at rates of 24.9\% and 34.1\%, respectively. All models struggle to learn the upper bonus strategy, overindexing on four-of-a-kind's, highlighting persistent long-horizon credit-assignment and exploration challenges.

</details>


### [71] [The Trojan in the Vocabulary: Stealthy Sabotage of LLM Composition](https://arxiv.org/abs/2601.00065)
*Xiaoze Liu,Weichen Yu,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.LG

TL;DR: 论文提出一种针对LLM模型组合技术的攻击方法，通过设计"破坏性token"在tokenizer移植过程中植入恶意特征，破坏基础模型的生成能力，同时保持捐赠模型功能正常。


<details>
  <summary>Details</summary>
Motivation: 随着开源权重LLM生态系统的发展，模型组合技术（如权重合并、推测解码、词汇表扩展）日益普及。这些技术需要tokenizer移植来对齐不同模型家族的词汇表。作者发现这一关键互操作性步骤存在供应链漏洞，可能被恶意利用。

Method: 通过利用系数重用的几何特性，设计一个在捐赠模型中功能惰性的"破坏性token"，但在移植到基础模型后会可靠地重构为高显著性的恶意特征。将攻击形式化为双目标优化问题，使用稀疏求解器实例化攻击，实现谱模仿以规避异常检测。

Result: 攻击无需训练即可实现，能够有效破坏基础模型的生成能力，同时捐赠模型的效用与正常行为在统计上无法区分。攻击具有结构持久性，能够抵抗微调和权重合并，突显了模块化AI组合流程中的隐藏风险。

Conclusion: tokenizer移植这一关键互操作性步骤存在供应链漏洞，可能被恶意行为者利用来破坏模型组合流程。这种攻击揭示了模块化AI组合管道中的隐藏风险，需要新的安全机制来防范。

Abstract: The open-weight LLM ecosystem is increasingly defined by model composition techniques (such as weight merging, speculative decoding, and vocabulary expansion) that remix capabilities from diverse sources. A critical prerequisite for applying these methods across different model families is tokenizer transplant, which aligns incompatible vocabularies to a shared embedding space. We demonstrate that this essential interoperability step introduces a supply-chain vulnerability: we engineer a single "breaker token" that is functionally inert in a donor model yet reliably reconstructs into a high-salience malicious feature after transplant into a base model. By exploiting the geometry of coefficient reuse, our attack creates an asymmetric realizability gap that sabotages the base model's generation while leaving the donor's utility statistically indistinguishable from nominal behavior. We formalize this as a dual-objective optimization problem and instantiate the attack using a sparse solver. Empirically, the attack is training-free and achieves spectral mimicry to evade outlier detection, while demonstrating structural persistence against fine-tuning and weight merging, highlighting a hidden risk in the pipeline of modular AI composition. Code is available at https://github.com/xz-liu/tokenforge

</details>


### [72] [IMBWatch -- a Spatio-Temporal Graph Neural Network approach to detect Illicit Massage Business](https://arxiv.org/abs/2601.00075)
*Swetha Varadarajan,Abhishek Ray,Lumina Albert*

Main category: cs.LG

TL;DR: IMBWatch是一个时空图神经网络框架，用于大规模检测伪装成合法按摩服务的非法按摩店，这些店铺涉及人口贩卖和性剥削。


<details>
  <summary>Details</summary>
Motivation: 非法按摩店(IMBs)是一种隐蔽且持续的有组织剥削形式，伪装成合法的健康服务，同时促进人口贩卖、性剥削和强迫劳动。传统方法（社区举报和监管检查）主要是被动反应，无法揭示更广泛的运营网络。

Method: IMBWatch是一个时空图神经网络(ST-GNN)框架，从开源情报（在线广告、营业执照记录、众包评论）构建动态图。节点代表企业、别名、电话号码和位置等异构实体，边捕获时空和关系模式（共址、重复电话使用、同步广告）。框架结合图卷积操作和时间注意力机制来建模IMB网络随时间和空间的演变。

Result: 在美国多个城市的真实数据集上的实验表明，IMBWatch优于基线模型，实现了更高的准确率和F1分数。除了性能提升外，IMBWatch还提供了更好的可解释性，为主动和有针对性的干预提供可操作的见解。

Conclusion: 该框架具有可扩展性，可适应其他非法领域，并发布匿名数据和开源代码以支持可重复研究。IMBWatch为检测和打击非法按摩店网络提供了有效的技术解决方案。

Abstract: Illicit Massage Businesses (IMBs) are a covert and persistent form of organized exploitation that operate under the facade of legitimate wellness services while facilitating human trafficking, sexual exploitation, and coerced labor. Detecting IMBs is difficult due to encoded digital advertisements, frequent changes in personnel and locations, and the reuse of shared infrastructure such as phone numbers and addresses. Traditional approaches, including community tips and regulatory inspections, are largely reactive and ineffective at revealing the broader operational networks traffickers rely on.
  To address these challenges, we introduce IMBWatch, a spatio-temporal graph neural network (ST-GNN) framework for large-scale IMB detection. IMBWatch constructs dynamic graphs from open-source intelligence, including scraped online advertisements, business license records, and crowdsourced reviews. Nodes represent heterogeneous entities such as businesses, aliases, phone numbers, and locations, while edges capture spatio-temporal and relational patterns, including co-location, repeated phone usage, and synchronized advertising. The framework combines graph convolutional operations with temporal attention mechanisms to model the evolution of IMB networks over time and space, capturing patterns such as intercity worker movement, burner phone rotation, and coordinated advertising surges.
  Experiments on real-world datasets from multiple U.S. cities show that IMBWatch outperforms baseline models, achieving higher accuracy and F1 scores. Beyond performance gains, IMBWatch offers improved interpretability, providing actionable insights to support proactive and targeted interventions. The framework is scalable, adaptable to other illicit domains, and released with anonymized data and open-source code to support reproducible research.

</details>


### [73] [Exploration in the Limit](https://arxiv.org/abs/2601.00084)
*Brian M. Cho,Nathan Kallus*

Main category: cs.LG

TL;DR: 提出了一种渐近置信度的最佳臂识别框架，通过放松精确误差控制要求，在非参数设置下实现更紧的样本复杂度界限


<details>
  <summary>Details</summary>
Motivation: 现有BAI方法在实际应用中存在局限性：严格的精确误差控制需要使用宽松的尾不等式和/或参数限制，导致效率低下

Method: 引入渐近误差控制框架，开发基于臂索引的渐近随时有效置信序列，设计新BAI算法，灵活纳入协变量进行方差缩减

Result: 在温和收敛假设下获得渐近样本复杂度界限，最坏情况样本复杂度与高斯BAI最佳情况匹配，实验显示减少平均样本复杂度同时保持误差控制

Conclusion: 提出的渐近框架在非参数设置下实现了更优的样本效率，特别适用于弱信号、高显著性要求和长实验周期的实际场景

Abstract: In fixed-confidence best arm identification (BAI), the objective is to quickly identify the optimal option while controlling the probability of error below a desired threshold. Despite the plethora of BAI algorithms, existing methods typically fall short in practical settings, as stringent exact error control requires using loose tail inequalities and/or parametric restrictions. To overcome these limitations, we introduce a relaxed formulation that requires valid error control asymptotically with respect to a minimum sample size. This aligns with many real-world settings that often involve weak signals, high desired significance, and post-experiment inference requirements, all of which necessitate long horizons. This allows us to achieve tighter optimality, while better handling flexible nonparametric outcome distributions and fully leveraging individual-level contexts. We develop a novel asymptotic anytime-valid confidence sequences over arm indices, and we use it to design a new BAI algorithm for our asymptotic framework. Our method flexibly incorporates covariates for variance reduction and ensures approximate error control in fully nonparametric settings. Under mild convergence assumptions, we provide asymptotic bounds on the sample complexity and show the worst-case sample complexity of our approach matches the best-case sample complexity of Gaussian BAI under exact error guarantees and known variances. Experiments suggest our approach reduces average sample complexities while maintaining error control.

</details>


### [74] [Dynamic Bayesian Optimization Framework for Instruction Tuning in Partial Differential Equation Discovery](https://arxiv.org/abs/2601.00088)
*Junqi Qu,Yan Zhang,Shangqian Gao,Shibo Li*

Main category: cs.LG

TL;DR: NeuroSymBO：将提示工程重构为序列决策问题，通过贝叶斯优化自适应选择推理策略，解决LLM方程发现中的指令脆弱性问题


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在方程发现中表现出潜力，但其输出对提示措辞高度敏感（指令脆弱性）。静态提示无法适应多步生成过程的演化状态，导致模型陷入次优解

Method: 提出NeuroSymBO方法，将提示工程重构为序列决策问题。维护离散的推理策略库，使用贝叶斯优化根据数值反馈在每个步骤选择最优指令

Result: 在PDE发现基准测试中，自适应指令选择显著优于固定提示，实现了更高的恢复率和更简洁的解决方案

Conclusion: 自适应提示选择能有效解决LLM方程发现中的指令脆弱性问题，提升模型性能和解的质量

Abstract: Large Language Models (LLMs) show promise for equation discovery, yet their outputs are highly sensitive to prompt phrasing, a phenomenon we term instruction brittleness. Static prompts cannot adapt to the evolving state of a multi-step generation process, causing models to plateau at suboptimal solutions. To address this, we propose NeuroSymBO, which reframes prompt engineering as a sequential decision problem. Our method maintains a discrete library of reasoning strategies and uses Bayesian Optimization to select the optimal instruction at each step based on numerical feedback. Experiments on PDE discovery benchmarks show that adaptive instruction selection significantly outperforms fixed prompts, achieving higher recovery rates with more parsimonious solutions.

</details>


### [75] [GRL-SNAM: Geometric Reinforcement Learning with Path Differential Hamiltonians for Simultaneous Navigation and Mapping in Unknown Environments](https://arxiv.org/abs/2601.00116)
*Aditya Sai Ellendula,Yi Wang,Minh Nguyen,Chandrajit Bajaj*

Main category: cs.LG

TL;DR: GRL-SNAM是一个几何强化学习框架，用于未知环境中的同时导航与建图，仅依赖局部感知而不构建全局地图，通过哈密顿优化实现动态路径搜索。


<details>
  <summary>Details</summary>
Motivation: 解决未知环境中同时导航与建图的挑战性问题，传统方法需要构建全局地图或设计复杂的多智能体策略，而本文旨在仅通过局部感知实现高效导航。

Method: 将路径导航和建图建模为动态最短路径搜索过程，使用受控哈密顿优化：将感知输入转换为局部能量景观，编码可达性、障碍物屏障和变形约束，通过更新哈密顿量来演化感知、规划和重配置策略。

Result: 在2D导航任务上评估，相比局部反应式基线和全局策略学习方法，GRL-SNAM保持安全距离，泛化到未见过的布局，通过局部能量优化而非全局建图实现高质量导航。

Conclusion: 通过哈密顿量更新的几何强化学习能够实现高质量的导航，仅需最小化探索和局部能量优化，无需广泛的全局建图，为未知环境中的同时导航与建图提供了新方法。

Abstract: We present GRL-SNAM, a geometric reinforcement learning framework for Simultaneous Navigation and Mapping(SNAM) in unknown environments. A SNAM problem is challenging as it needs to design hierarchical or joint policies of multiple agents that control the movement of a real-life robot towards the goal in mapless environment, i.e. an environment where the map of the environment is not available apriori, and needs to be acquired through sensors. The sensors are invoked from the path learner, i.e. navigator, through active query responses to sensory agents, and along the motion path. GRL-SNAM differs from preemptive navigation algorithms and other reinforcement learning methods by relying exclusively on local sensory observations without constructing a global map. Our approach formulates path navigation and mapping as a dynamic shortest path search and discovery process using controlled Hamiltonian optimization: sensory inputs are translated into local energy landscapes that encode reachability, obstacle barriers, and deformation constraints, while policies for sensing, planning, and reconfiguration evolve stagewise via updating Hamiltonians. A reduced Hamiltonian serves as an adaptive score function, updating kinetic/potential terms, embedding barrier constraints, and continuously refining trajectories as new local information arrives. We evaluate GRL-SNAM on two different 2D navigation tasks. Comparing against local reactive baselines and global policy learning references under identical stagewise sensing constraints, it preserves clearance, generalizes to unseen layouts, and demonstrates that Geometric RL learning via updating Hamiltonians enables high-quality navigation through minimal exploration via local energy refinement rather than extensive global mapping. The code is publicly available on \href{https://github.com/CVC-Lab/GRL-SNAM}{Github}.

</details>


### [76] [Reinforcement Learning with Function Approximation for Non-Markov Processes](https://arxiv.org/abs/2601.00151)
*Ali Devran Kara*

Main category: cs.LG

TL;DR: 研究非马尔可夫状态和成本过程下的线性函数逼近强化学习方法，证明了策略评估算法的收敛性，并分析了Q-learning在特定基函数选择下的收敛条件。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习通常假设马尔可夫过程，但在实际应用中状态和成本过程往往是非马尔可夫的。本文旨在研究非马尔可夫环境下线性函数逼近强化学习方法的收敛性。

Method: 首先分析策略评估方法，在适当的遍历性条件下证明算法收敛；然后研究Q-learning的收敛性，特别针对基于量化映射选择的基函数；最后将结果应用于部分可观测马尔可夫决策过程。

Result: 证明了策略评估算法在非马尔可夫过程下的收敛性，极限对应于联合算子的不动点；对于Q-learning，在特定基函数选择下也能证明收敛；在部分可观测MDP应用中推导了显式误差界。

Conclusion: 在适当的遍历性条件下，非马尔可夫环境中的线性函数逼近强化学习方法可以收敛，为实际应用中处理非马尔可夫过程提供了理论保证。

Abstract: We study reinforcement learning methods with linear function approximation under non-Markov state and cost processes. We first consider the policy evaluation method and show that the algorithm converges under suitable ergodicity conditions on the underlying non-Markov processes. Furthermore, we show that the limit corresponds to the fixed point of a joint operator composed of an orthogonal projection and the Bellman operator of an auxiliary \emph{Markov} decision process.
  For Q-learning with linear function approximation, as in the Markov setting, convergence is not guaranteed in general. We show, however, that for the special case where the basis functions are chosen based on quantization maps, the convergence can be shown under similar ergodicity conditions. Finally, we apply our results to partially observed Markov decision processes, where finite-memory variables are used as state representations, and we derive explicit error bounds for the limits of the resulting learning algorithms.

</details>


### [77] [The Weather Paradox: Why Precipitation Fails to Predict Traffic Accident Severity in Large-Scale US Data](https://arxiv.org/abs/2601.00152)
*Yann Bellec,Rohan Kaman,Siwen Cui,Aarav Agrawal,Calvin Chen*

Main category: cs.LG

TL;DR: 研究使用XGBoost模型分析美国交通事故严重程度预测，发现时间、地理位置和天气变量是最强预测因子，但模型对极端严重程度案例预测能力有限。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索环境、时间和空间因素对美国交通事故严重程度的预测能力，为基于证据的交通管理提供支持。

Method: 使用2016-2023年50万起美国交通事故数据集，通过随机搜索交叉验证优化XGBoost分类器，并采用类别加权处理类别不平衡问题。

Result: 模型整体准确率达78%，对主要类别（严重程度2）的精确率和召回率均达87%。特征重要性分析显示时间、地理位置和天气变量（能见度、温度、风速）是最强预测因子，但降水和能见度预测能力有限。

Conclusion: 研究为基于证据的交通管理提供了见解，但数据集主要包含中等严重程度事故，限制了模型对极端案例的学习能力，需要替代采样策略、增强特征工程和外部数据集整合。

Abstract: This study investigates the predictive capacity of environmental, temporal, and spatial factors on traffic accident severity in the United States. Using a dataset of 500,000 U.S. traffic accidents spanning 2016-2023, we trained an XGBoost classifier optimized through randomized search cross-validation and adjusted for class imbalance via class weighting. The final model achieves an overall accuracy of 78%, with strong performance on the majority class (Severity 2), attaining 87% precision and recall. Feature importance analysis reveals that time of day, geographic location, and weather-related variables, including visibility, temperature, and wind speed, rank among the strongest predictors of accident severity. However, contrary to initial hypotheses, precipitation and visibility demonstrate limited predictive power, potentially reflecting behavioral adaptation by drivers under overtly hazardous conditions. The dataset's predominance of mid-level severity accidents constrains the model's capacity to learn meaningful patterns for extreme cases, highlighting the need for alternative sampling strategies, enhanced feature engineering, and integration of external datasets. These findings contribute to evidence-based traffic management and suggest future directions for severity prediction research.

</details>


### [78] [Online Finetuning Decision Transformers with Pure RL Gradients](https://arxiv.org/abs/2601.00167)
*Junkai Luo,Yinglun Zhu*

Main category: cs.LG

TL;DR: 本文提出了一种使用纯强化学习梯度在线微调决策变换器的新方法，解决了现有方法依赖监督学习目标的问题，在多个基准测试中取得了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 决策变换器在离线强化学习中表现出色，但在在线设置中仍主要依赖监督序列建模目标。作者发现后见回报重标记这一标准组件与基于重要性采样的强化学习算法不兼容，阻碍了纯强化学习梯度的在线微调。

Method: 提出了几种新算法：将GRPO适配到决策变换器，引入子轨迹优化以改进信用分配，使用序列级似然目标增强稳定性和效率，以及主动采样以在不确定区域鼓励探索。

Result: 通过大量实验证明，该方法优于现有的在线决策变换器基线，在多个基准测试中实现了新的最先进性能。

Conclusion: 纯强化学习梯度的在线微调对决策变换器是有效的，解决了后见回报重标记与重要性采样算法之间的不兼容问题，为序列决策模型提供了更强大的在线适应能力。

Abstract: Decision Transformers (DTs) have emerged as a powerful framework for sequential decision making by formulating offline reinforcement learning (RL) as a sequence modeling problem. However, extending DTs to online settings with pure RL gradients remains largely unexplored, as existing approaches continue to rely heavily on supervised sequence-modeling objectives during online finetuning. We identify hindsight return relabeling -- a standard component in online DTs -- as a critical obstacle to RL-based finetuning: while beneficial for supervised learning, it is fundamentally incompatible with importance sampling-based RL algorithms such as GRPO, leading to unstable training. Building on this insight, we propose new algorithms that enable online finetuning of Decision Transformers using pure reinforcement learning gradients. We adapt GRPO to DTs and introduce several key modifications, including sub-trajectory optimization for improved credit assignment, sequence-level likelihood objectives for enhanced stability and efficiency, and active sampling to encourage exploration in uncertain regions. Through extensive experiments, we demonstrate that our methods outperform existing online DT baselines and achieve new state-of-the-art performance across multiple benchmarks, highlighting the effectiveness of pure-RL-based online finetuning for Decision Transformers.

</details>


### [79] [Sequential Reservoir Computing for Efficient High-Dimensional Spatiotemporal Forecasting](https://arxiv.org/abs/2601.00172)
*Ata Akbari Asanjan,Filip Wudarski,Daniel O'Connor,Shaun Geaney,Elena Strbac,P. Aaron Lott,Davide Venturelli*

Main category: cs.LG

TL;DR: Sequential Reservoir Computing (Sequential RC)通过将大储层分解为一系列小型互联储层，显著降低了高维时空系统预测的计算成本和内存需求，同时提升了预测精度和时效性。


<details>
  <summary>Details</summary>
Motivation: 传统RNN和LSTM在高维时空系统预测中存在梯度训练和内存瓶颈问题，而传统Reservoir Computing虽然通过固定循环层和凸读出优化缓解了这些问题，但在输入维度增加时仍然存在可扩展性问题。

Method: 提出Sequential Reservoir Computing架构，将大型储层分解为一系列小型、相互连接的储层。这种设计在保持长期时间依赖性的同时，显著降低了内存和计算成本。

Result: 在低维混沌系统(Lorenz63)和高维物理模拟(2D涡度和浅水方程)中，Sequential RC相比LSTM和标准RNN基线：1) 有效预测时间延长15-25%；2) 误差指标(SSIM, RMSE)降低20-30%；3) 训练成本降低高达三个数量级。

Conclusion: Sequential RC在保持传统RC简单性和效率的同时，为高维动力系统提供了更好的可扩展性，为科学和工程应用中的实时、节能预测提供了实用路径。

Abstract: Forecasting high-dimensional spatiotemporal systems remains computationally challenging for recurrent neural networks (RNNs) and long short-term memory (LSTM) models due to gradient-based training and memory bottlenecks. Reservoir Computing (RC) mitigates these challenges by replacing backpropagation with fixed recurrent layers and a convex readout optimization, yet conventional RC architectures still scale poorly with input dimensionality. We introduce a Sequential Reservoir Computing (Sequential RC) architecture that decomposes a large reservoir into a series of smaller, interconnected reservoirs. This design reduces memory and computational costs while preserving long-term temporal dependencies. Using both low-dimensional chaotic systems (Lorenz63) and high-dimensional physical simulations (2D vorticity and shallow-water equations), Sequential RC achieves 15-25% longer valid forecast horizons, 20-30% lower error metrics (SSIM, RMSE), and up to three orders of magnitude lower training cost compared to LSTM and standard RNN baselines. The results demonstrate that Sequential RC maintains the simplicity and efficiency of conventional RC while achieving superior scalability for high-dimensional dynamical systems. This approach provides a practical path toward real-time, energy-efficient forecasting in scientific and engineering applications.

</details>


### [80] [Early Prediction of Liver Cirrhosis Up to Three Years in Advance: A Machine Learning Study Benchmarking Against the FIB-4 Score](https://arxiv.org/abs/2601.00175)
*Zhuqi Miao,Sujan Ravi,Abdulaziz Ahmed*

Main category: cs.LG

TL;DR: 开发基于电子健康记录的机器学习模型，用于提前1-3年预测肝硬化发生，相比传统FIB-4评分有显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 肝硬化早期预测对预防和管理至关重要，传统FIB-4评分预测能力有限，需要利用电子健康记录数据和机器学习技术提高预测准确性。

Method: 回顾性队列研究，使用去标识化电子健康记录数据，识别脂肪肝患者并分为肝硬化与非肝硬化队列。构建预测场景，从观察窗口聚合人口统计学、诊断、实验室结果等特征，训练XGBoost模型用于1年、2年、3年预测，并与FIB-4评分进行性能比较。

Result: 机器学习模型在所有预测时间窗口均显著优于FIB-4评分：XGBoost模型的AUC分别为0.81（1年）、0.73（2年）、0.69（3年），而FIB-4的AUC分别为0.71、0.63、0.57。性能优势随预测时间延长而保持。

Conclusion: 基于常规电子健康记录数据的机器学习模型在肝硬化早期预测方面显著优于传统FIB-4评分，能够实现更早、更准确的风险分层，可作为自动化决策支持工具集成到临床工作流程中，支持主动的肝硬化预防和管理。

Abstract: Objective: Develop and evaluate machine learning (ML) models for predicting incident liver cirrhosis one, two, and three years prior to diagnosis using routinely collected electronic health record (EHR) data, and to benchmark their performance against the FIB-4 score. Methods: We conducted a retrospective cohort study using de-identified EHR data from a large academic health system. Patients with fatty liver disease were identified and categorized into cirrhosis and non-cirrhosis cohorts based on ICD-9/10 codes. Prediction scenarios were constructed using observation and prediction windows to emulate real-world clinical use. Demographics, diagnoses, laboratory results, vital signs, and comorbidity indices were aggregated from the observation window. XGBoost models were trained for 1-, 2-, and 3-year prediction horizons and evaluated on held-out test sets. Model performance was compared with FIB-4 using area under the receiver operating characteristic curve (AUC). Results: Final cohorts included 3,043 patients for the 1-year prediction, 1,981 for the 2-year prediction, and 1,470 for the 3-year prediction. Across all prediction windows, ML models consistently outperformed FIB-4. The XGBoost models achieved AUCs of 0.81, 0.73, and 0.69 for 1-, 2-, and 3-year predictions, respectively, compared with 0.71, 0.63, and 0.57 for FIB-4. Performance gains persisted with longer prediction horizons, indicating improved early risk discrimination. Conclusions: Machine learning models leveraging routine EHR data substantially outperform the traditional FIB-4 score for early prediction of liver cirrhosis. These models enable earlier and more accurate risk stratification and can be integrated into clinical workflows as automated decision-support tools to support proactive cirrhosis prevention and management.

</details>


### [81] [Reinforcement-Learned Unequal Error Protection for Quantized Semantic Embeddings](https://arxiv.org/abs/2601.00186)
*Moirangthem Tiken Singh,Adnan Arif*

Main category: cs.LG

TL;DR: 提出基于强化学习的自适应重复编码框架，实现按维度不等错误保护，在有限带宽下显著提升语义通信性能


<details>
  <summary>Details</summary>
Motivation: 解决带宽受限通信系统中语义保持的挑战，传统信道编码（如LDPC、Reed-Solomon）无法提供细粒度语义保护

Method: 基于强化学习的自适应重复编码框架，使用复合语义失真度量（平衡全局嵌入相似性和实体级保持），实现上下文感知的保护分配

Result: 相比均匀保护，在1dB SNR下获得6.8%更高的chrF分数和9.3%更好的实体保持，统计显著

Conclusion: 智能分配的简单重复编码可实现细粒度语义保护，代码结构必须与语义粒度对齐，适用于边缘计算和物联网场景

Abstract: This paper tackles the pressing challenge of preserving semantic meaning in communication systems constrained by limited bandwidth. We introduce a novel reinforcement learning framework that achieves per-dimension unequal error protection via adaptive repetition coding. Central to our approach is a composite semantic distortion metric that balances global embedding similarity with entity-level preservation, empowering the reinforcement learning agent to allocate protection in a context-aware manner. Experiments show statistically significant gains over uniform protection, achieving 6.8% higher chrF scores and 9.3% better entity preservation at 1 dB SNR. The key innovation of our framework is the demonstration that simple, intelligently allocated repetition coding enables fine-grained semantic protection -- an advantage unattainable with conventional codes such as LDPC or Reed-Solomon. Our findings challenge traditional channel coding paradigms by establishing that code structure must align with semantic granularity. This approach is particularly suited to edge computing and IoT scenarios, where bandwidth is scarce, but semantic fidelity is critical, providing a practical pathway for next-generation semantic-aware networks.

</details>


### [82] [SSI-GAN: Semi-Supervised Swin-Inspired Generative Adversarial Networks for Neuronal Spike Classification](https://arxiv.org/abs/2601.00189)
*Danial Sharifrazi,Nouman Javed,Mojtaba Mohammadi,Seyede Sana Salehi,Roohallah Alizadehsani,Prasad N. Paradkar,U. Rajendra Acharya,Asim Bhatti*

Main category: cs.LG

TL;DR: 提出SSI-GAN半监督学习框架，仅需1-3%标注数据即可实现蚊子神经元尖峰信号的高精度分类，用于检测寨卡病毒、登革热病毒感染，大幅减少人工标注工作量。


<details>
  <summary>Details</summary>
Motivation: 蚊子是虫媒病毒的主要传播媒介，手动分类神经元尖峰模式非常耗时且昂贵。现有深度学习解决方案需要完全标注的数据集和高度预处理的信号，限制了在实际场景中的大规模应用。为了解决标注数据稀缺的问题，需要开发更高效的半监督学习方法。

Method: 提出半监督Swin启发式GAN（SSI-GAN）架构，包含基于Transformer的生成器和Swin启发的移位窗口判别器。使用多头自注意力模型在基于窗口的Transformer判别器中学习捕捉稀疏的高频尖峰特征。仅使用1-3%的标注数据，在超过1500万个尖峰样本上训练，使用贝叶斯Optuna框架优化超参数，并通过五折蒙特卡洛交叉验证评估鲁棒性。

Result: SSI-GAN在感染后第三天仅使用3%标注数据达到99.93%的分类准确率，在仅1%监督下在所有感染阶段都保持高准确率。相比标准监督方法，在相同性能水平下减少了97-99%的人工标注工作量。提出的移位窗口Transformer设计大幅超越所有基线方法，在基于尖峰的神经元感染分类中创下新的最佳记录。

Conclusion: SSI-GAN通过创新的半监督GAN架构，有效解决了神经元尖峰信号分类中标注数据稀缺的问题，显著降低了人工标注成本，为实际现场应用中的大规模蚊子病毒感染检测提供了可行的解决方案。

Abstract: Mosquitos are the main transmissive agents of arboviral diseases. Manual classification of their neuronal spike patterns is very labor-intensive and expensive. Most available deep learning solutions require fully labeled spike datasets and highly preprocessed neuronal signals. This reduces the feasibility of mass adoption in actual field scenarios. To address the scarcity of labeled data problems, we propose a new Generative Adversarial Network (GAN) architecture that we call the Semi-supervised Swin-Inspired GAN (SSI-GAN). The Swin-inspired, shifted-window discriminator, together with a transformer-based generator, is used to classify neuronal spike trains and, consequently, detect viral neurotropism. We use a multi-head self-attention model in a flat, window-based transformer discriminator that learns to capture sparser high-frequency spike features. Using just 1 to 3% labeled data, SSI-GAN was trained with more than 15 million spike samples collected at five-time post-infection and recording classification into Zika-infected, dengue-infected, or uninfected categories. Hyperparameters were optimized using the Bayesian Optuna framework, and performance for robustness was validated under fivefold Monte Carlo cross-validation. SSI-GAN reached 99.93% classification accuracy on the third day post-infection with only 3% labeled data. It maintained high accuracy across all stages of infection with just 1% supervision. This shows a 97-99% reduction in manual labeling effort relative to standard supervised approaches at the same performance level. The shifted-window transformer design proposed here beat all baselines by a wide margin and set new best marks in spike-based neuronal infection classification.

</details>


### [83] [Optimized Hybrid Feature Engineering for Resource-Efficient Arrhythmia Detection in ECG Signals: An Optimization Framework](https://arxiv.org/abs/2601.00192)
*Moirangthem Tiken Singh,Manibhushan Yaikhom*

Main category: cs.LG

TL;DR: 提出一种面向资源受限边缘设备的轻量级心律失常检测框架，通过特征工程使高维数据线性可分，在保持高准确率的同时大幅降低模型大小和延迟。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病特别是心律失常是全球主要死因，需要IoMT持续监测。现有深度学习方法计算开销过大，不适合资源受限的边缘设备。

Method: 采用数据为中心的方法，优先特征工程而非模型复杂度。结合时频小波分解和图论结构描述符（如PageRank中心性）构建混合特征空间，再通过互信息和递归消除进行特征选择，最终使用可解释的超轻量级线性分类器。

Result: 在MIT-BIH和INCART数据集上达到98.44%诊断准确率，模型大小仅8.54KB，分类推理延迟0.46μs，每搏处理管道52ms，相比压缩模型KD-Light（25KB，96.32%准确率）实现数量级效率提升。

Conclusion: 该框架为资源受限边缘设备提供了高效的心律失常检测方案，显著降低计算开销和模型大小，支持实时操作，推进无电池心脏传感器的发展。

Abstract: Cardiovascular diseases, particularly arrhythmias, remain a leading global cause of mortality, necessitating continuous monitoring via the Internet of Medical Things (IoMT). However, state-of-the-art deep learning approaches often impose prohibitive computational overheads, rendering them unsuitable for resource-constrained edge devices. This study proposes a resource-efficient, data-centric framework that prioritizes feature engineering over complexity. Our optimized pipeline makes the complex, high-dimensional arrhythmia data linearly separable. This is achieved by integrating time-frequency wavelet decompositions with graph-theoretic structural descriptors, such as PageRank centrality. This hybrid feature space, combining wavelet decompositions and graph-theoretic descriptors, is then refined using mutual information and recursive elimination, enabling interpretable, ultra-lightweight linear classifiers. Validation on the MIT-BIH and INCART datasets yields 98.44% diagnostic accuracy with an 8.54 KB model footprint. The system achieves 0.46 $μ$s classification inference latency within a 52 ms per-beat pipeline, ensuring real-time operation. These outcomes provide an order-of-magnitude efficiency gain over compressed models, such as KD-Light (25 KB, 96.32% accuracy), advancing battery-less cardiac sensors.

</details>


### [84] [Unknown Aware AI-Generated Content Attribution](https://arxiv.org/abs/2601.00218)
*Ellie Thieu,Jifan Zhang,Haoyue Bai*

Main category: cs.LG

TL;DR: 该论文提出了一种利用未标注的互联网图像数据来增强AI生成内容溯源的方法，通过约束优化提升对未见生成器的识别能力


<details>
  <summary>Details</summary>
Motivation: 随着逼真生成模型的快速发展，需要超越简单的真假检测，准确识别特定生成模型产生的图像来源。现有方法在泛化到未见或新发布的生成器时表现不佳

Method: 使用CLIP特征和线性分类器建立基线，提出约束优化方法利用未标注的互联网数据（可能包含真实图像、未知生成器输出或目标模型样本），鼓励野生样本被分类为非目标，同时保持标注数据性能

Result: 实验结果显示，结合野生数据显著提高了对挑战性未见生成器的溯源性能，证明未标注数据可以有效增强开放世界场景下的AI生成内容溯源

Conclusion: 利用未标注的互联网数据可以有效提升AI生成内容溯源在开放世界环境中的泛化能力，特别是在面对未见和新发布生成器时

Abstract: The rapid advancement of photorealistic generative models has made it increasingly important to attribute the origin of synthetic content, moving beyond binary real or fake detection toward identifying the specific model that produced a given image. We study the problem of distinguishing outputs from a target generative model (e.g., OpenAI Dalle 3) from other sources, including real images and images generated by a wide range of alternative models. Using CLIP features and a simple linear classifier, shown to be effective in prior work, we establish a strong baseline for target generator attribution using only limited labeled data from the target model and a small number of known generators. However, this baseline struggles to generalize to harder, unseen, and newly released generators. To address this limitation, we propose a constrained optimization approach that leverages unlabeled wild data, consisting of images collected from the Internet that may include real images, outputs from unknown generators, or even samples from the target model itself. The proposed method encourages wild samples to be classified as non target while explicitly constraining performance on labeled data to remain high. Experimental results show that incorporating wild data substantially improves attribution performance on challenging unseen generators, demonstrating that unlabeled data from the wild can be effectively exploited to enhance AI generated content attribution in open world settings.

</details>


### [85] [Robust Graph Fine-Tuning with Adversarial Graph Prompting](https://arxiv.org/abs/2601.00229)
*Ziyan Zhang,Bo Jiang,Jin Tang*

Main category: cs.LG

TL;DR: 提出对抗性图提示（AGP）框架，将对抗学习融入图提示中，通过min-max优化实现鲁棒的图神经网络微调，提升对图拓扑和节点特征噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调（PEFT）方法在图拓扑和节点特征面临各种噪声和攻击时表现出显著脆弱性，需要开发更鲁棒的图微调方法。

Method: 提出对抗性图提示（AGP）框架，将问题建模为min-max优化问题。内层最大化使用联合投影梯度下降（JointPGD）生成强对抗噪声；外层最小化学习最优节点提示来抵消对抗噪声。该方法可集成到各种预训练GNN模型中。

Result: 理论分析表明AGP能同时处理图拓扑和节点噪声。在多个基准任务上的实验验证了AGP相比现有方法的鲁棒性和有效性。

Conclusion: AGP是首个将对抗学习融入图提示的框架，通过min-max优化实现鲁棒图微调，可集成到各种预训练GNN模型中，显著提升对图噪声的鲁棒性。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) method has emerged as a dominant paradigm for adapting pre-trained GNN models to downstream tasks. However, existing PEFT methods usually exhibit significant vulnerability to various noise and attacks on graph topology and node attributes/features. To address this issue, for the first time, we propose integrating adversarial learning into graph prompting and develop a novel Adversarial Graph Prompting (AGP) framework to achieve robust graph fine-tuning. Our AGP has two key aspects. First, we propose the general problem formulation of AGP as a min-max optimization problem and develop an alternating optimization scheme to solve it. For inner maximization, we propose Joint Projected Gradient Descent (JointPGD) algorithm to generate strong adversarial noise. For outer minimization, we employ a simple yet effective module to learn the optimal node prompts to counteract the adversarial noise. Second, we demonstrate that the proposed AGP can theoretically address both graph topology and node noise. This confirms the versatility and robustness of our AGP fine-tuning method across various graph noise. Note that, the proposed AGP is a general method that can be integrated with various pre-trained GNN models to enhance their robustness on the downstream tasks. Extensive experiments on multiple benchmark tasks validate the robustness and effectiveness of AGP method compared to state-of-the-art methods.

</details>


### [86] [GRIT -- Geometry-Aware PEFT with K-FACPreconditioning, Fisher-Guided Reprojection, andDynamic Rank Adaptation](https://arxiv.org/abs/2601.00231)
*Pritish Saha,Chandrav Rajbangshi,Rudra Goyal,Mohit Goyal,Anurag Deo,Biswajit Roy,Ningthoujam Dhanachandra Singh,Raxit Goswami,Amitava Das*

Main category: cs.LG

TL;DR: GRIT是一种动态、曲率感知的LoRA方法，通过K-FAC预条件梯度、定期重投影到Fisher特征方向、自适应调整有效秩，在减少46%可训练参数的同时达到或超越LoRA/QLoRA性能


<details>
  <summary>Details</summary>
Motivation: 传统LoRA和QLoRA是几何无关的，它们在固定、随机方向的低秩子空间中优化，主要使用一阶下降，忽略了局部损失曲率。这可能导致有效更新预算膨胀和沿弱约束方向的漂移放大

Method: GRIT保持LoRA参数化但：(1)使用K-FAC作为自然梯度代理在秩空间中对梯度进行预条件处理；(2)定期将低秩基重投影到主导Fisher特征方向以抑制漂移；(3)根据谱自适应调整有效秩，使容量集中在信号存在的地方

Result: 在LLaMA骨干上的指令遵循、理解和推理基准测试中，GRIT匹配或超越了LoRA和QLoRA，同时平均减少46%的可训练参数（任务间25-80%），在各种提示风格和数据混合中没有实际质量损失

Conclusion: GRIT通过曲率感知的动态调整，在减少参数的同时保持性能，比强PEFT优化器基线（正交LoRA、IA3、DoRA、Eff-FT、Shampoo）具有更低的漂移和更好的更新与保留边界

Abstract: Parameter-efficient fine-tuning (PEFT) is the default way to adapt LLMs, but widely used LoRA and QLoRA are largely geometry-agnostic: they optimize in fixed, randomly oriented low-rank subspaces with first-order descent, mostly ignoring local loss curvature. This can inflate the effective update budget and amplify drift along weakly constrained directions. We introduce GRIT, a dynamic, curvature-aware LoRA procedure that preserves the LoRA parameterization but: (1) preconditions gradients in rank space using K-FAC as a natural-gradient proxy; (2) periodically reprojects the low-rank basis onto dominant Fisher eigendirections to suppress drift; and (3) adapts the effective rank from the spectrum so capacity concentrates where signal resides. Across instruction-following, comprehension, and reasoning benchmarks on LLaMA backbones, GRIT matches or surpasses LoRA and QLoRA while reducing trainable parameters by 46% on average (25--80% across tasks), without practical quality loss across prompt styles and data mixes. To model forgetting, we fit a curvature-modulated power law. Empirically, GRIT yields lower drift and a better updates-vs-retention frontier than strong PEFT-optimizer baselines (Orthogonal-LoRA, IA3, DoRA, Eff-FT, Shampoo).

</details>


### [87] [Task-Driven Kernel Flows: Label Rank Compression and Laplacian Spectral Filtering](https://arxiv.org/abs/2601.00276)
*Hongxi Li,Chunlin Huang*

Main category: cs.LG

TL;DR: 宽L2正则化网络的特征学习理论表明监督学习本质上是压缩性的，核秩受类别数限制，SGD噪声也是低秩的，这与自监督学习的高秩表示形成对比。


<details>
  <summary>Details</summary>
Motivation: 理解监督学习中特征学习的本质，特别是网络表示如何演化以及为什么监督学习会产生压缩性表示，而自监督学习则产生扩展性表示。

Method: 提出宽L2正则化网络的特征学习理论，推导出预测"水填充"谱演化的核ODE，证明稳定稳态下核秩受类别数限制，并分析SGD噪声的低秩特性。

Result: 证明了监督学习中核秩受类别数C限制，SGD噪声也是O(C)低秩的，动力学被限制在任务相关子空间，监督学习产生低秩压缩表示，而自监督学习产生高秩扩展表示。

Conclusion: 监督学习本质上是压缩性的，表示被限制在任务相关子空间，这与自监督学习的扩展性表示形成鲜明对比，统一了确定性和随机性对齐视角。

Abstract: We present a theory of feature learning in wide L2-regularized networks showing that supervised learning is inherently compressive. We derive a kernel ODE that predicts a "water-filling" spectral evolution and prove that for any stable steady state, the kernel rank is bounded by the number of classes ($C$). We further demonstrate that SGD noise is similarly low-rank ($O(C)$), confining dynamics to the task-relevant subspace. This framework unifies the deterministic and stochastic views of alignment and contrasts the low-rank nature of supervised learning with the high-rank, expansive representations of self-supervision.

</details>


### [88] [Can Optimal Transport Improve Federated Inverse Reinforcement Learning?](https://arxiv.org/abs/2601.00309)
*David Millard,Ali Baheri*

Main category: cs.LG

TL;DR: 提出基于最优传输的联邦逆强化学习方法，通过Wasserstein重心融合异构智能体的本地奖励函数，实现通信高效的跨环境共享奖励学习。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，直接共享数据学习共同奖励函数通常不现实，因为存在动态差异、隐私约束和通信带宽限制等问题。

Method: 每个客户端先在本地执行轻量级最大熵逆强化学习，然后将得到的奖励函数通过Wasserstein重心进行融合，考虑了奖励函数的底层几何结构。

Result: 证明重心融合比传统联邦学习中的参数平均方法能获得更准确的全局奖励估计，提供了原则性且通信高效的框架。

Conclusion: 该方法为异构智能体和环境间的共享奖励学习提供了理论基础和实用框架，解决了数据隐私和通信效率问题。

Abstract: In robotics and multi-agent systems, fleets of autonomous agents often operate in subtly different environments while pursuing a common high-level objective. Directly pooling their data to learn a shared reward function is typically impractical due to differences in dynamics, privacy constraints, and limited communication bandwidth. This paper introduces an optimal transport-based approach to federated inverse reinforcement learning (IRL). Each client first performs lightweight Maximum Entropy IRL locally, adhering to its computational and privacy limitations. The resulting reward functions are then fused via a Wasserstein barycenter, which considers their underlying geometric structure. We further prove that this barycentric fusion yields a more faithful global reward estimate than conventional parameter averaging methods in federated learning. Overall, this work provides a principled and communication-efficient framework for deriving a shared reward that generalizes across heterogeneous agents and environments.

</details>


### [89] [Quantum King-Ring Domination in Chess: A QAOA Approach](https://arxiv.org/abs/2601.00318)
*Gerhard Stenzel,Michael Kölle,Tobias Rohe,Julian Hager,Leo Sünkel,Maximilian Zorn,Claudia Linnhoff-Popien*

Main category: cs.LG

TL;DR: 该论文提出了基于国际象棋战术位置的量子基准测试QKRD，用于系统评估QAOA算法设计选择，发现约束保持混合器、预热策略等能显著提升性能，而CVaR优化效果不佳。


<details>
  <summary>Details</summary>
Motivation: 现有QAOA基准测试主要使用MaxCut、TSP、SAT等随机合成实例，这些实例缺乏语义结构和人类可解释性，无法反映真实世界问题的约束特性，限制了算法在实际问题中的性能评估。

Method: 引入量子国王-车支配问题(QKRD)基准，基于国际象棋战术位置构建5,000个结构化实例，具有独热约束、空间局部性和10-40量子比特规模。该基准结合人类可解释的覆盖度指标和内在验证机制，无需外部预言机。

Result: 约束保持混合器(XY、domain-wall)比标准混合器收敛快约13步；预热策略减少45步收敛时间，能量改进显著；CVaR优化效果更差且无覆盖度优势。QAOA优于贪心启发式12.6%，优于随机选择80.1%。

Conclusion: 结构化基准能揭示问题感知的QAOA技术优势，这些优势在随机实例中被掩盖。研究提供了完整的代码、数据和实验工件，支持可重复的NISQ算法研究。

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is extensively benchmarked on synthetic random instances such as MaxCut, TSP, and SAT problems, but these lack semantic structure and human interpretability, offering limited insight into performance on real-world problems with meaningful constraints. We introduce Quantum King-Ring Domination (QKRD), a NISQ-scale benchmark derived from chess tactical positions that provides 5,000 structured instances with one-hot constraints, spatial locality, and 10--40 qubit scale. The benchmark pairs human-interpretable coverage metrics with intrinsic validation against classical heuristics, enabling algorithmic conclusions without external oracles. Using QKRD, we systematically evaluate QAOA design choices and find that constraint-preserving mixers (XY, domain-wall) converge approximately 13 steps faster than standard mixers (p<10^{-7}, d\approx0.5) while eliminating penalty tuning, warm-start strategies reduce convergence by 45 steps (p<10^{-127}, d=3.35) with energy improvements exceeding d=8, and Conditional Value-at-Risk (CVaR) optimization yields an informative negative result with worse energy (p<10^{-40}, d=1.21) and no coverage benefit. Intrinsic validation shows QAOA outperforms greedy heuristics by 12.6\% and random selection by 80.1\%. Our results demonstrate that structured benchmarks reveal advantages of problem-informed QAOA techniques obscured in random instances. We release all code, data, and experimental artifacts for reproducible NISQ algorithm research.

</details>


### [90] [Smart Fault Detection in Nanosatellite Electrical Power System](https://arxiv.org/abs/2601.00335)
*Alireza Rezaee,Niloofar Nobahari,Amin Asgarifar,Farshid Hajati*

Main category: cs.LG

TL;DR: 提出一种无需姿态确定控制系统的纳米卫星电源故障检测方法，使用神经网络模拟正常状态，结合多种机器学习算法进行故障分类诊断


<details>
  <summary>Details</summary>
Motivation: 纳米卫星在LEO轨道运行时，由于压力容限、发射压力和环境因素，电气系统各部分存在故障风险。光伏子系统可能出现线间故障和开路，DC-DC转换器可能出现IGBT短路和开路，地面电池可能出现调节器故障。传统方法需要姿态确定控制系统，本文旨在开发无需ADCS的故障检测方案。

Method: 1. 使用神经网络建立无故障系统模型：以太阳辐射和太阳能板表面温度为输入，电流和负载为输出；2. 利用神经网络分类器通过故障模式和类型诊断不同故障；3. 采用多种机器学习方法进行故障分类：PCA分类、决策树和KNN算法。

Result: 成功开发了无需姿态确定控制系统的纳米卫星电源故障检测方法。通过神经网络模拟正常状态，结合多种机器学习算法能够有效诊断光伏子系统、DC-DC转换器和地面电池的各种常见故障。

Conclusion: 该方法为纳米卫星提供了一种有效的故障检测方案，无需依赖复杂的姿态确定控制系统，降低了系统复杂性和成本，提高了卫星在轨运行的可靠性。

Abstract: This paper presents a new detection method of faults at Nanosatellites' electrical power without an Attitude Determination Control Subsystem (ADCS) at the LEO orbit. Each part of this system is at risk of fault due to pressure tolerance, launcher pressure, and environmental circumstances. Common faults are line to line fault and open circuit for the photovoltaic subsystem, short circuit and open circuit IGBT at DC to DC converter, and regulator fault of the ground battery. The system is simulated without fault based on a neural network using solar radiation and solar panel's surface temperature as input data and current and load as outputs. Finally, using the neural network classifier, different faults are diagnosed by pattern and type of fault. For fault classification, other machine learning methods are also used, such as PCA classification, decision tree, and KNN.

</details>


### [91] [Real-Time Human Detection for Aerial Captured Video Sequences via Deep Models](https://arxiv.org/abs/2601.00391)
*Nouar AlDahoul,Aznul Qalid Md Sabri,Ali Mohammed Mansoor*

Main category: cs.LG

TL;DR: 论文提出结合光流和三种深度学习模型（监督CNN、预训练CNN特征提取器、分层极限学习机）用于无人机视频中的人体检测，在UCF-ARG数据集上取得高精度。


<details>
  <summary>Details</summary>
Motivation: 传统手工特征方法依赖专家知识，对光照变化、相机抖动等动态事件敏感。需要更廉价、自动化的特征学习方法，特别是针对无人机平台非静态相机拍摄的视频中的人体检测。

Method: 结合光流和三种深度学习模型：1) 监督卷积神经网络（S-CNN），2) 预训练CNN特征提取器，3) 分层极限学习机（H-ELM）。在UCF-ARG无人机数据集上训练测试，评估五种人类动作（挖掘、挥手、投掷、行走、奔跑）。

Result: 预训练CNN平均准确率98.09%；S-CNN使用softmax达到95.6%，使用SVM达到91.7%；H-ELM平均准确率95.9%。H-ELM在CPU上训练时间445秒，S-CNN在GPU上训练时间770秒。

Conclusion: 提出的自动特征学习方法在无人机视频人体检测任务中表现成功，预训练CNN效果最佳。深度学习模型能够自动提取抽象判别特征，优于传统手工特征方法。

Abstract: Human detection in videos plays an important role in various real-life applications. Most traditional approaches depend on utilizing handcrafted features, which are problem-dependent and optimal for specific tasks. Moreover, they are highly susceptible to dynamical events such as illumination changes, camera jitter, and variations in object sizes. On the other hand, the proposed feature learning approaches are cheaper and easier because highly abstract and discriminative features can be produced automatically without the need of expert knowledge. In this paper, we utilize automatic feature learning methods, which combine optical flow and three different deep models (i.e., supervised convolutional neural network (S-CNN), pretrained CNN feature extractor, and hierarchical extreme learning machine) for human detection in videos captured using a nonstatic camera on an aerial platform with varying altitudes. The models are trained and tested on the publicly available and highly challenging UCF-ARG aerial dataset. The comparison between these models in terms of training, testing accuracy, and learning speed is analyzed. The performance evaluation considers five human actions (digging, waving, throwing, walking, and running). Experimental results demonstrated that the proposed methods are successful for the human detection task. The pretrained CNN produces an average accuracy of 98.09%. S-CNN produces an average accuracy of 95.6% with softmax and 91.7% with Support Vector Machines (SVM). H-ELM has an average accuracy of 95.9%. Using a normal Central Processing Unit (CPU), H-ELM's training time takes 445 seconds. Learning in S-CNN takes 770 seconds with a high-performance Graphical Processing Unit (GPU).

</details>


### [92] [Deep Delta Learning](https://arxiv.org/abs/2601.00417)
*Yifan Zhang,Yifeng Liu,Mengdi Wang,Quanquan Gu*

Main category: cs.LG

TL;DR: DDL通过可学习的几何变换（Delta算子）替代传统残差连接，实现动态插值于恒等映射、正交投影和几何反射之间，增强网络建模复杂状态转换的能力。


<details>
  <summary>Details</summary>
Motivation: 传统残差网络的恒等连接虽然缓解了梯度消失问题，但其严格的加性归纳偏置限制了网络建模复杂状态转换的能力。

Method: 提出Deep Delta Learning (DDL)架构，用可学习的、数据依赖的几何变换（Delta算子）调制恒等连接。该算子是对单位矩阵的秩-1扰动，由反射方向向量k(X)和门控标量β(X)参数化。

Result: 谱分析表明门控β(X)能够实现恒等映射、正交投影和几何反射之间的动态插值。通过同步秩-1注入重构残差更新，门控作为动态步长控制旧信息擦除和新特征写入。

Conclusion: DDL统一了网络显式控制层间转移算子谱的能力，使其能够建模复杂非单调动态，同时保持门控残差架构的稳定训练特性。

Abstract: The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to model complex state transitions. In this paper, we introduce Deep Delta Learning (DDL), a novel architecture that generalizes the standard residual connection by modulating the identity shortcut with a learnable, data-dependent geometric transformation. This transformation, termed the Delta Operator, constitutes a rank-1 perturbation of the identity matrix, parameterized by a reflection direction vector $\mathbf{k}(\mathbf{X})$ and a gating scalar $β(\mathbf{X})$. We provide a spectral analysis of this operator, demonstrating that the gate $β(\mathbf{X})$ enables dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection. Furthermore, we restructure the residual update as a synchronous rank-1 injection, where the gate acts as a dynamic step size governing both the erasure of old information and the writing of new features. This unification empowers the network to explicitly control the spectrum of its layer-wise transition operator, enabling the modeling of complex, non-monotonic dynamics while preserving the stable training characteristics of gated residual architectures.

</details>


### [93] [E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models](https://arxiv.org/abs/2601.00423)
*Shengjun Zhang,Zhang Zhang,Chensheng Dai,Yueqi Duan*

Main category: cs.LG

TL;DR: 提出E-GRPO方法，通过熵感知的组相对策略优化增强流匹配模型的人类偏好对齐，通过合并低熵步骤为高熵SDE采样步骤来解决多步去噪中的稀疏奖励问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多步去噪优化中面临稀疏和模糊的奖励信号问题。观察到高熵步骤能实现更高效探索，而低熵步骤导致无区别的roll-out。

Method: 提出E-GRPO（熵感知组相对策略优化）：1）合并连续低熵步骤形成单个高熵SDE采样步骤，其他步骤使用ODE采样；2）引入多步组归一化优势，在共享相同合并SDE去噪步骤的样本中计算组相对优势。

Result: 在不同奖励设置下的实验结果证明了该方法的有效性。

Conclusion: 通过熵感知的SDE采样步骤合并和组相对优势计算，E-GRPO有效解决了多步去噪中的奖励稀疏性问题，提升了流匹配模型的人类偏好对齐性能。

Abstract: Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.

</details>


### [94] [A Comparative Analysis of Interpretable Machine Learning Methods](https://arxiv.org/abs/2601.00428)
*Mattia Billa,Giovanni Orlandi,Veronica Guidetti,Federica Mandreoli*

Main category: cs.LG

TL;DR: 大规模比较16种可解释机器学习方法在216个表格数据集上的表现，发现性能高度依赖数据集特征，EBMs在回归任务中表现最佳，为实践者提供可解释性与预测性能的平衡指导。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在医疗、金融等高风险领域的广泛应用，模型可解释性和责任性日益重要。尽管可解释ML受到关注，但对表格数据的内在可解释模型的系统性评估仍然稀缺，现有研究多集中于聚合性能结果。

Method: 对16种内在可解释方法进行大规模比较评估，包括经典线性模型、决策树以及EBMs、符号回归、GOSDT等新方法。研究涵盖216个真实表格数据集，按维度、样本量、线性度、类别不平衡等结构特征分层分析性能，并评估训练时间和分布偏移下的鲁棒性。

Result: 结果显示清晰的性能层次结构，特别是在回归任务中EBMs始终表现出强大的预测准确性。同时发现性能高度依赖上下文：SR和IGANNs在非线性场景表现优异，而GOSDT模型对类别不平衡表现出明显敏感性。

Conclusion: 这些发现为寻求可解释性与预测性能平衡的实践者提供实用指导，并促进对表格数据可解释建模的深入实证理解。

Abstract: In recent years, Machine Learning (ML) has seen widespread adoption across a broad range of sectors, including high-stakes domains such as healthcare, finance, and law. This growing reliance has raised increasing concerns regarding model interpretability and accountability, particularly as legal and regulatory frameworks place tighter constraints on using black-box models in critical applications. Although interpretable ML has attracted substantial attention, systematic evaluations of inherently interpretable models, especially for tabular data, remain relatively scarce and often focus primarily on aggregated performance outcomes.
  To address this gap, we present a large-scale comparative evaluation of 16 inherently interpretable methods, ranging from classical linear models and decision trees to more recent approaches such as Explainable Boosting Machines (EBMs), Symbolic Regression (SR), and Generalized Optimal Sparse Decision Trees (GOSDT). Our study spans 216 real-world tabular datasets and goes beyond aggregate rankings by stratifying performance according to structural dataset characteristics, including dimensionality, sample size, linearity, and class imbalance. In addition, we assess training time and robustness under controlled distributional shifts. Our results reveal clear performance hierarchies, especially for regression tasks, where EBMs consistently achieve strong predictive accuracy. At the same time, we show that performance is highly context-dependent: SR and Interpretable Generalized Additive Neural Networks (IGANNs) perform particularly well in non-linear regimes, while GOSDT models exhibit pronounced sensitivity to class imbalance. Overall, these findings provide practical guidance for practitioners seeking a balance between interpretability and predictive performance, and contribute to a deeper empirical understanding of interpretable modeling for tabular data.

</details>


### [95] [A Comparative Study of Adaptation Strategies for Time Series Foundation Models in Anomaly Detection](https://arxiv.org/abs/2601.00446)
*Miseon Park,Kijung Yoon*

Main category: cs.LG

TL;DR: 时间序列基础模型（TSFMs）可作为异常检测的通用骨干，通过零样本推理、全模型适应和参数高效微调（PEFT）策略，在类别不平衡情况下显著优于任务特定基线。


<details>
  <summary>Details</summary>
Motivation: 大多数现有时间序列异常检测方法需要大量任务特定训练，而时间序列基础模型（TSFMs）在大规模异构数据上预训练后，可能作为异常检测的通用骨干模型，实现更高效和可扩展的检测。

Method: 通过系统实验比较三种策略：零样本推理、全模型适应和参数高效微调（PEFT），包括LoRA、OFT和HRA等方法，评估TSFMs在多个基准测试上的异常检测性能。

Result: TSFMs在AUC-PR和VUS-PR指标上显著优于任务特定基线，尤其在严重类别不平衡情况下表现突出；PEFT方法不仅降低计算成本，在大多数情况下匹配或超越全微调性能。

Conclusion: 时间序列基础模型可作为异常检测的有前景的通用模型，即使预训练用于预测任务，也能通过高效适应策略实现可扩展和高效的时间序列异常检测。

Abstract: Time series anomaly detection is essential for the reliable operation of complex systems, but most existing methods require extensive task-specific training. We explore whether time series foundation models (TSFMs), pretrained on large heterogeneous data, can serve as universal backbones for anomaly detection. Through systematic experiments across multiple benchmarks, we compare zero-shot inference, full model adaptation, and parameter-efficient fine-tuning (PEFT) strategies. Our results demonstrate that TSFMs outperform task-specific baselines, achieving notable gains in AUC-PR and VUS-PR, particularly under severe class imbalance. Moreover, PEFT methods such as LoRA, OFT, and HRA not only reduce computational cost but also match or surpass full fine-tuning in most cases, indicating that TSFMs can be efficiently adapted for anomaly detection, even when pretrained for forecasting. These findings position TSFMs as promising general-purpose models for scalable and efficient time series anomaly detection.

</details>


### [96] [Controllable Concept Bottleneck Models](https://arxiv.org/abs/2601.00451)
*Hongbin Lin,Chenyang Ren,Juangui Xu,Zhengyu Hu,Cheng-Long Wang,Yao Shu,Hui Xiong,Jingfeng Zhang,Di Wang,Lijie Hu*

Main category: cs.LG

TL;DR: 提出可控概念瓶颈模型(CCBMs)，支持三种粒度的模型编辑：概念-标签级、概念级和数据级，通过影响函数实现无需重新训练的闭式近似编辑。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型主要关注静态场景，而实际应用中模型需要持续维护：删除错误/敏感数据、修正错误标注概念、纳入新样本以适应环境变化。如何在不重新训练的情况下实现高效可编辑的CBMs是一个重要挑战。

Method: 提出可控概念瓶颈模型(CCBMs)，支持三种粒度编辑：概念-标签级、概念级和数据级（包括数据删除和添加）。基于影响函数推导数学严谨的闭式近似，避免重新训练。

Result: 实验结果表明CCBMs具有高效性和适应性，证实了其在实现动态可信CBMs方面的实用价值。

Conclusion: CCBMs通过影响函数实现无需重新训练的多粒度模型编辑，为实际应用中的动态概念瓶颈模型维护提供了有效解决方案。

Abstract: Concept Bottleneck Models (CBMs) have garnered much attention for their ability to elucidate the prediction process through a human-understandable concept layer. However, most previous studies focused on static scenarios where the data and concepts are assumed to be fixed and clean. In real-world applications, deployed models require continuous maintenance: we often need to remove erroneous or sensitive data (unlearning), correct mislabeled concepts, or incorporate newly acquired samples (incremental learning) to adapt to evolving environments. Thus, deriving efficient editable CBMs without retraining from scratch remains a significant challenge, particularly in large-scale applications. To address these challenges, we propose Controllable Concept Bottleneck Models (CCBMs). Specifically, CCBMs support three granularities of model editing: concept-label-level, concept-level, and data-level, the latter of which encompasses both data removal and data addition. CCBMs enjoy mathematically rigorous closed-form approximations derived from influence functions that obviate the need for retraining. Experimental results demonstrate the efficiency and adaptability of our CCBMs, affirming their practical value in enabling dynamic and trustworthy CBMs.

</details>


### [97] [Imitation from Observations with Trajectory-Level Generative Embeddings](https://arxiv.org/abs/2601.00452)
*Yongtao Qu,Shangzhe Li,Weitong Zhang*

Main category: cs.LG

TL;DR: TGE：一种用于离线观察模仿学习（LfO）的轨迹级生成嵌入方法，通过时间扩散模型在潜在空间中估计专家状态密度，构建密集平滑的代理奖励，有效处理专家演示稀缺且离线数据与专家行为差异大的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有分布匹配方法在专家演示稀缺、离线次优数据与专家行为差异大的情况下表现不佳，因为它们施加严格的支撑约束并依赖脆弱的单步模型，难以从非完美数据中提取有用信号。

Method: 提出TGE（轨迹级生成嵌入），通过在离线轨迹数据上训练的时间扩散模型的潜在空间中估计专家状态密度，构建密集平滑的代理奖励。利用学习到的扩散嵌入的平滑几何特性，捕捉长时域时间动态，有效弥合不相交支撑之间的差距。

Result: 在D4RL运动和控制基准测试中，TGE方法持续匹配或优于先前的离线LfO方法，证明了其在处理分布差异大的数据时的有效性。

Conclusion: TGE通过轨迹级生成嵌入方法，利用扩散模型的平滑几何特性，为离线观察模仿学习提供了鲁棒的学习信号，即使在离线数据与专家行为分布差异大的情况下也能有效工作。

Abstract: We consider the offline imitation learning from observations (LfO) where the expert demonstrations are scarce and the available offline suboptimal data are far from the expert behavior. Many existing distribution-matching approaches struggle in this regime because they impose strict support constraints and rely on brittle one-step models, making it hard to extract useful signal from imperfect data. To tackle this challenge, we propose TGE, a trajectory-level generative embedding for offline LfO that constructs a dense, smooth surrogate reward by estimating expert state density in the latent space of a temporal diffusion model trained on offline trajectory data. By leveraging the smooth geometry of the learned diffusion embedding, TGE captures long-horizon temporal dynamics and effectively bridges the gap between disjoint supports, ensuring a robust learning signal even when offline data is distributionally distinct from the expert. Empirically, the proposed approach consistently matches or outperforms prior offline LfO methods across a range of D4RL locomotion and manipulation benchmarks.

</details>


### [98] [Deep Networks Learn Deep Hierarchical Models](https://arxiv.org/abs/2601.00455)
*Amit Daniely*

Main category: cs.LG

TL;DR: 该论文研究了残差网络中层间SGD如何高效学习层次化模型，这类模型超越了先前深度学习可学习模型的深度限制，并探讨了人类"教师"提供层次标签如何促进高效学习。


<details>
  <summary>Details</summary>
Motivation: 研究深度神经网络如何高效学习具有层次结构的模型，这类模型超越了先前已知可学习模型的深度限制。作者认为理解这类层次化模型的学习机制可能最终成为理解深度学习的基础。

Method: 提出一类层次化模型，假设存在未知的标签层次结构 L₁ ⊆ L₂ ⊆ ... ⊆ Lᵣ = [n]，其中L₁中的标签是输入的简单函数，而i>1时，Lᵢ中的标签是较简单标签的简单函数。使用残差网络和层间SGD进行学习。

Result: 证明层间SGD在残差网络上能够高效学习这类层次化模型，这类模型达到了高效可学习性的深度极限（需要多项式深度表达，而先前模型只需对数深度电路）。

Conclusion: 层次化模型的学习可能为理解深度学习提供基础。人类"教师"提供细粒度标签的行为揭示了大脑内部算法的"提示"，在教师部分了解自身内部逻辑的简化模型中，这种层次结构促进了高效学习。

Abstract: We consider supervised learning with $n$ labels and show that layerwise SGD on residual networks can efficiently learn a class of hierarchical models. This model class assumes the existence of an (unknown) label hierarchy $L_1 \subseteq L_2 \subseteq \dots \subseteq L_r = [n]$, where labels in $L_1$ are simple functions of the input, while for $i > 1$, labels in $L_i$ are simple functions of simpler labels.
  Our class surpasses models that were previously shown to be learnable by deep learning algorithms, in the sense that it reaches the depth limit of efficient learnability. That is, there are models in this class that require polynomial depth to express, whereas previous models can be computed by log-depth circuits.
  Furthermore, we suggest that learnability of such hierarchical models might eventually form a basis for understanding deep learning. Beyond their natural fit for domains where deep learning excels, we argue that the mere existence of human ``teachers" supports the hypothesis that hierarchical structures are inherently available. By providing granular labels, teachers effectively reveal ``hints'' or ``snippets'' of the internal algorithms used by the brain. We formalize this intuition, showing that in a simplified model where a teacher is partially aware of their internal logic, a hierarchical structure emerges that facilitates efficient learnability.

</details>


### [99] [Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations](https://arxiv.org/abs/2601.00457)
*Hyunjun Kim*

Main category: cs.LG

TL;DR: 正交性损失在MoE模型中无法有效促进专家多样性，反而增加权重空间重叠，对性能影响不一致，不适合用于MoE多样性


<details>
  <summary>Details</summary>
Motivation: 研究几何正则化在MoE专家专业化中的作用，特别是正交性损失是否能有效促进专家多样性

Method: 在MoE模型中应用正交性损失来强制专家多样性，在7个正则化强度下分析权重空间和激活空间的重叠情况

Result: 正交性损失在多方面失败：权重空间重叠增加达114%，激活空间重叠保持高位(~0.6)，性能影响不一致，权重与激活正交性无显著相关性(r=-0.293,p=0.523)

Conclusion: 权重空间正则化既未实现其几何目标，也未可靠改善性能，不适合用于MoE多样性

Abstract: Mixture-of-Experts (MoE) models achieve efficiency through sparse activation, but the role of geometric regularization in expert specialization remains unclear. We apply orthogonality loss to enforce expert diversity and find it fails on multiple fronts: it does not reduce weight-space overlap (MSO actually increases by up to 114%), activation-space overlap remains high (~0.6) regardless of regularization, and effects on performance are inconsistent -- marginal improvement on WikiText-103 (-0.9%), slight degradation on TinyStories (+0.9%), and highly variable results on PTB (std > 1.0). Our analysis across 7 regularization strengths reveals no significant correlation (r = -0.293, p = 0.523) between weight and activation orthogonality. These findings demonstrate that weight-space regularization neither achieves its geometric goal nor reliably improves performance, making it unsuitable for MoE diversity.

</details>


### [100] [Detecting Spike Wave Discharges (SWD) using 1-dimensional Residual UNet](https://arxiv.org/abs/2601.00459)
*Saurav Sengupta,Scott Kilianski,Suchetha Sharma,Sakina Lashkeri,Ashley McHugh,Mark Beenhakker,Donald E. Brown*

Main category: cs.LG

TL;DR: 本文提出了一种用于自动标记脑电图（EEG）中棘波放电（SWD）的1D UNet模型AugUNet1D，该模型在961小时小鼠EEG数据上表现优于传统算法和14种其他机器学习分类器。


<details>
  <summary>Details</summary>
Motivation: 手动标记EEG记录中的事件（特别是持续数周至数月的连续记录）非常耗时。棘波放电（SWD）作为失神发作的电生理标志，通常需要手动标记。虽然已有研究使用机器学习自动分割和分类EEG信号，但仍有改进空间。

Method: 1. 比较了14种机器学习分类器在961小时小鼠EEG数据（包含22,637个标记SWD）上的性能；2. 发现1D UNet表现最佳；3. 通过数据增强改进1D UNet，发现缩放增强效果最好；4. 将增强后的AugUNet1D与最近发表的"Twin Peaks"算法进行比较。

Result: 1. 1D UNet在所有测试分类器中表现最佳；2. 数据增强显著提升了模型性能，其中缩放增强效果最明显；3. AugUNet1D在性能上优于"Twin Peaks"算法，检测到的事件特征更接近手动标记的SWD。

Conclusion: AugUNet1D是一种有效的SWD自动标记工具，性能优于现有方法。作者公开了预训练和未训练的模型供其他研究者使用，有助于减少EEG分析中的手动工作量。

Abstract: The manual labeling of events in electroencephalography (EEG) records is time-consuming. This is especially true when EEG recordings are taken continuously over weeks to months. Therefore, a method to automatically label pertinent EEG events reduces the manual workload. Spike wave discharges (SWD), which are the electrographic hallmark of absence seizures, are EEG events that are often labeled manually. While some previous studies have utilized machine learning to automatically segment and classify EEG signals like SWDs, they can be improved. Here we compare the performance of 14 machine learning classifiers on our own manually annotated dataset of 961 hours of EEG recordings from C3H/HeJ mice, including 22,637 labeled SWDs. We find that a 1D UNet performs best for labeling SWDs in this dataset. We also improve the 1D UNet by augmenting our training data and determine that scaling showed the greatest benefit of all augmentation procedures applied. We then compare the 1D UNet with data augmentation, AugUNet1D, against a recently published time- and frequency-based algorithmic approach called "Twin Peaks". AugUNet1D showed superior performance and detected events with more similar features to the SWDs labeled manually. AugUNet1D, pretrained on our manually annotated data or untrained, is made public for others users.

</details>


### [101] [Laplacian Kernelized Bandit](https://arxiv.org/abs/2601.00461)
*Shuang Wu,Arash A. Amini*

Main category: cs.LG

TL;DR: 提出一种多用户上下文赌博机框架，通过图拉普拉斯与核函数的融合，将图同质性与非线性奖励函数统一建模，设计出理论保证的探索算法。


<details>
  <summary>Details</summary>
Motivation: 传统多用户上下文赌博机方法通常假设线性奖励函数或忽略用户间的图结构关系。现实场景中用户奖励函数既非线性又受社交网络影响，需要同时建模非线性行为和图的同质性。

Method: 提出一种联合惩罚项，结合基于RKHS距离的图平滑项和个体粗糙度惩罚。证明该惩罚等价于单一多用户RKHS中的平方范数，推导出融合图拉普拉斯与基础臂核的再生核。基于此设计LK-GP-UCB和LK-GP-TS算法，利用高斯过程后验进行探索。

Result: 理论证明遗憾上界与多用户核的有效维度相关，而非用户数量或环境维度。实验表明在非线性设置中优于线性和非图感知基线，在线性奖励场景中仍保持竞争力。

Conclusion: 该工作提供了一个统一的理论框架，将拉普拉斯正则化与核化赌博机结合，为结构化探索提供了理论基础和实用方法。

Abstract: We study multi-user contextual bandits where users are related by a graph and their reward functions exhibit both non-linear behavior and graph homophily. We introduce a principled joint penalty for the collection of user reward functions $\{f_u\}$, combining a graph smoothness term based on RKHS distances with an individual roughness penalty. Our central contribution is proving that this penalty is equivalent to the squared norm within a single, unified \emph{multi-user RKHS}. We explicitly derive its reproducing kernel, which elegantly fuses the graph Laplacian with the base arm kernel. This unification allows us to reframe the problem as learning a single ''lifted'' function, enabling the design of principled algorithms, \texttt{LK-GP-UCB} and \texttt{LK-GP-TS}, that leverage Gaussian Process posteriors over this new kernel for exploration. We provide high-probability regret bounds that scale with an \emph{effective dimension} of the multi-user kernel, replacing dependencies on user count or ambient dimension. Empirically, our methods outperform strong linear and non-graph-aware baselines in non-linear settings and remain competitive even when the true rewards are linear. Our work delivers a unified, theoretically grounded, and practical framework that bridges Laplacian regularization with kernelized bandits for structured exploration.

</details>


### [102] [Neural Chains and Discrete Dynamical Systems](https://arxiv.org/abs/2601.00473)
*Sauro Succi,Abhisek Ganguly,Santosh Ansumali*

Main category: cs.LG

TL;DR: 该论文比较了无自注意力Transformer架构（神经链）与数值离散化方法在求解Burgers和Eikonal方程时的表现，发现PINN学习使用随机矩阵而非结构化矩阵，参数更多但可解释性差，训练成本高。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究无自注意力Transformer架构（神经链）与离散化神经积分/偏微分方程之间的类比关系，比较传统数值离散化方法与物理信息神经网络（PINN）在求解动态问题时的差异。

Method: 方法包括：1）将无自注意力Transformer架构（神经链）与离散化神经积分/偏微分方程进行类比分析；2）对粘性和非粘性Burgers方程以及Eikonal方程，分别使用标准数值离散化（也表示为神经链形式）和PINN学习方法进行求解比较。

Result: 研究发现：1）标准数值离散化和PINN学习提供了获取系统动态知识的两种不同路径；2）PINN学习使用随机矩阵，与有限差分法的结构化矩阵无关；3）可接受的随机矩阵解远多于唯一的三对角矩阵形式；4）PINN需要更多参数，导致物理可解释性差且训练成本高。

Conclusion: 结论是PINN方法在一维动态问题中相比传统数值方法没有优势，但研究结果不排除在高维问题中PINN和机器学习可能提供更好的策略。PINN的主要代价是参数多、可解释性差、训练成本高。

Abstract: We inspect the analogy between machine-learning (ML) applications based on the transformer architecture without self-attention, {\it neural chains} hereafter, and discrete dynamical systems associated with discretised versions of neural integral and partial differential equations (NIE, PDE). A comparative analysis of the numerical solution of the (viscid and inviscid) Burgers and Eikonal equations via standard numerical discretization (also cast in terms of neural chains) and via PINN's learning is presented and commented on. It is found that standard numerical discretization and PINN learning provide two different paths to acquire essentially the same knowledge about the dynamics of the system. PINN learning proceeds through random matrices which bear no direct relation to the highly structured matrices associated with finite-difference (FD) procedures. Random matrices leading to acceptable solutions are far more numerous than the unique tridiagonal form in matrix space, which explains why the PINN search typically lands on the random ensemble. The price is a much larger number of parameters, causing lack of physical transparency (explainability) as well as large training costs with no counterpart in the FD procedure. However, our results refer to one-dimensional dynamic problems, hence they don't rule out the possibility that PINNs and ML in general, may offer better strategies for high-dimensional problems.

</details>


### [103] [When Small Models Are Right for Wrong Reasons: Process Verification for Trustworthy Agents](https://arxiv.org/abs/2601.00513)
*Laksh Advani*

Main category: cs.LG

TL;DR: 研究发现小型语言模型(7-9B参数)作为自主代理时存在严重可靠性危机：50-69%的正确答案包含根本性错误推理，即"正确但推理错误"现象，标准准确率指标无法检测。作者提出推理完整性评分(RIS)作为过程评估指标，发现RAG能改善推理完整性，而元认知干预反而损害性能。


<details>
  <summary>Details</summary>
Motivation: 部署小型语言模型(7-9B参数)作为自主代理需要信任其推理过程，而不仅仅是输出结果。当前存在一个关键可靠性危机：这些模型50-69%的正确答案包含根本性错误推理，这种现象无法通过标准准确率指标检测，对可信代理部署构成威胁。

Method: 通过分析10,734个推理轨迹，涵盖三个模型和多样化任务，引入推理完整性评分(RIS)作为过程评估指标。研究验证了检索增强生成(RAG)和元认知干预对推理完整性的影响，并通过机制分析揭示RAG通过外部证据基础计算减少错误，而元认知在模型容量不足时放大混淆。最后将验证能力蒸馏到神经网络分类器中。

Result: 研究发现小型语言模型存在严重"正确但推理错误"现象(50-69%)。RIS指标具有显著评分者间一致性(κ=0.657)。RAG显著改善推理完整性(Cohen's d=0.23-0.93)，减少错误7.6%，而元认知干预反而损害性能(d=-0.14到-0.33)。蒸馏的神经分类器达到0.86 F1分数和100倍加速。

Conclusion: 仅凭准确率评估模型是危险的，因为模型可能因完全错误的推理而得出正确答案。过程验证对于可信代理部署至关重要。RAG通过外部证据基础改善推理完整性，而元认知干预在小型模型上可能适得其反。需要开发过程验证方法来确保自主代理的可靠性。

Abstract: Deploying small language models (7-9B parameters) as autonomous agents requires trust in their reasoning, not just their outputs. We reveal a critical reliability crisis: 50-69\% of correct answers from these models contain fundamentally flawed reasoning -- a ``Right-for-Wrong-Reasons'' phenomenon invisible to standard accuracy metrics. Through analysis of 10,734 reasoning traces across three models and diverse tasks, we introduce the Reasoning Integrity Score (RIS), a process-based metric validated with substantial inter-rater agreement ($κ=0.657$). Conventional practices are challenged by our findings: while retrieval-augmented generation (RAG) significantly improves reasoning integrity (Cohen's $d=0.23$--$0.93$), meta-cognitive interventions like self-critique often harm performance ($d=-0.14$ to $-0.33$) in small models on the evaluated tasks. Mechanistic analysis reveals RAG succeeds by grounding calculations in external evidence, reducing errors by 7.6\%, while meta-cognition amplifies confusion without sufficient model capacity. To enable deployment, verification capabilities are distilled into a neural classifier achieving 0.86 F1-score with 100$\times$ speedup. These results underscore the necessity of process-based verification for trustworthy agents: accuracy alone is dangerously insufficient when models can be right for entirely wrong reasons.

</details>


### [104] [Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly Detection in Agentic AI](https://arxiv.org/abs/2601.00516)
*Laksh Advani*

Main category: cs.LG

TL;DR: Trajectory Guard：基于孪生循环自编码器的LLM智能体轨迹异常检测方法，通过对比学习和重构损失联合学习任务对齐与序列有效性，实现实时安全验证


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法不适用于LLM智能体多步行动计划：均值池化会稀释异常步骤，仅对比学习忽略序列结构，标准无监督方法F1分数不超过0.69

Method: 提出Trajectory Guard，采用孪生循环自编码器架构，结合混合损失函数：通过对比学习学习任务-轨迹对齐，通过重构学习序列有效性

Result: 在合成扰动和真实世界失败案例（RAS-Eval安全审计和Who&When多智能体系统）上，平衡集F1分数0.88-0.94，不平衡外部基准召回率0.86-0.92；推理延迟32ms，比LLM Judge基线快17-27倍

Conclusion: Trajectory Guard能够统一检测"任务错误计划"和"畸形计划结构"，实现生产部署中的实时安全验证，显著优于现有方法

Abstract: Autonomous LLM agents generate multi-step action plans that can fail due to contextual misalignment or structural incoherence. Existing anomaly detection methods are ill-suited for this challenge: mean-pooling embeddings dilutes anomalous steps, while contrastive-only approaches ignore sequential structure. Standard unsupervised methods on pre-trained embeddings achieve F1-scores no higher than 0.69. We introduce Trajectory Guard, a Siamese Recurrent Autoencoder with a hybrid loss function that jointly learns task-trajectory alignment via contrastive learning and sequential validity via reconstruction. This dual objective enables unified detection of both "wrong plan for this task" and "malformed plan structure." On benchmarks spanning synthetic perturbations and real-world failures from security audits (RAS-Eval) and multi-agent systems (Who\&When), we achieve F1-scores of 0.88-0.94 on balanced sets and recall of 0.86-0.92 on imbalanced external benchmarks. At 32 ms inference latency, our approach runs 17-27$\times$ faster than LLM Judge baselines, enabling real-time safety verification in production deployments.

</details>


### [105] [A Sparse-Attention Deep Learning Model Integrating Heterogeneous Multimodal Features for Parkinson's Disease Severity Profiling](https://arxiv.org/abs/2601.00519)
*Dristi Datta,Tanmoy Debnath,Minh Chau,Manoranjan Paul,Gourab Adhikary,Md Geaur Rahman*

Main category: cs.LG

TL;DR: 提出SAFN网络，通过稀疏注意力机制融合多模态数据，在帕金森病分类中达到98%准确率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 帕金森病具有异质性表现，需要整合生物和临床标志物。现有多模态模型存在可解释性差、类别不平衡、高维特征融合困难等问题。

Method: 提出Class-Weighted Sparse-Attention Fusion Network (SAFN)：使用模态特定编码器处理MRI皮层厚度、体积测量、临床评估和人口统计学数据；采用对称交叉注意力机制捕捉非线性交互；稀疏约束注意力门控层动态选择信息模态；类别平衡焦点损失处理数据不平衡。

Result: 在703名参与者（570名PD，133名健康对照）上评估，使用五折交叉验证，准确率0.98±0.02，PR-AUC 1.00±0.00，优于现有机器学习方法。可解释性分析显示约60%预测权重分配给临床评估，符合临床诊断原则。

Conclusion: SAFN为神经退行性疾病计算分析提供了可重复、透明的多模态建模范式，具有临床可解释的决策过程。

Abstract: Characterising the heterogeneous presentation of Parkinson's disease (PD) requires integrating biological and clinical markers within a unified predictive framework. While multimodal data provide complementary information, many existing computational models struggle with interpretability, class imbalance, or effective fusion of high-dimensional imaging and tabular clinical features. To address these limitations, we propose the Class-Weighted Sparse-Attention Fusion Network (SAFN), an interpretable deep learning framework for robust multimodal profiling. SAFN integrates MRI cortical thickness, MRI volumetric measures, clinical assessments, and demographic variables using modality-specific encoders and a symmetric cross-attention mechanism that captures nonlinear interactions between imaging and clinical representations. A sparsity-constrained attention-gating fusion layer dynamically prioritises informative modalities, while a class-balanced focal loss (beta = 0.999, gamma = 1.5) mitigates dataset imbalance without synthetic oversampling. Evaluated on 703 participants (570 PD, 133 healthy controls) from the Parkinson's Progression Markers Initiative using subject-wise five-fold cross-validation, SAFN achieves an accuracy of 0.98 plus or minus 0.02 and a PR-AUC of 1.00 plus or minus 0.00, outperforming established machine learning and deep learning baselines. Interpretability analysis shows a clinically coherent decision process, with approximately 60 percent of predictive weight assigned to clinical assessments, consistent with Movement Disorder Society diagnostic principles. SAFN provides a reproducible and transparent multimodal modelling paradigm for computational profiling of neurodegenerative disease.

</details>


### [106] [Optimizing LSTM Neural Networks for Resource-Constrained Retail Sales Forecasting: A Model Compression Study](https://arxiv.org/abs/2601.00525)
*Ravi Teja Pagidoju*

Main category: cs.LG

TL;DR: LSTM模型压缩研究：通过减少隐藏单元从128到16，发现64单元模型在保持精度的同时显著减小模型大小，证明大模型不一定更好


<details>
  <summary>Details</summary>
Motivation: 标准LSTM在零售销售预测中准确但计算量大，对中小型零售业具有挑战性，需要探索模型压缩以平衡计算成本和预测精度

Method: 采用Kaggle商店商品需求预测数据集（913,000条记录），逐步减少LSTM隐藏单元数量（从128到16），评估模型大小与预测精度的权衡关系

Result: 64单元LSTM模型在保持相同精度的同时显著改善：MAPE从128单元的23.6%降至12.4%，模型大小减少73%（280KB到76KB），精度提升47%

Conclusion: LSTM模型压缩可行，64单元模型在精度和计算效率上达到最佳平衡，证明大模型不一定带来更好结果，为中小型零售业提供了实用的解决方案

Abstract: Standard LSTM(Long Short-Term Memory) neural networks provide accurate predictions for sales data in the retail industry, but require a lot of computing power. It can be challenging especially for mid to small retail industries. This paper examines LSTM model compression by gradually reducing the number of hidden units from 128 to 16. We used the Kaggle Store Item Demand Forecasting dataset, which has 913,000 daily sales records from 10 stores and 50 items, to look at the trade-off between model size and how accurate the predictions are. Experiments show that lowering the number of hidden LSTM units to 64 maintains the same level of accuracy while also improving it. The mean absolute percentage error (MAPE) ranges from 23.6% for the full 128-unit model to 12.4% for the 64-unit model. The optimized model is 73% smaller (from 280KB to 76KB) and 47% more accurate. These results show that larger models do not always achieve better results.

</details>


### [107] [Federated Customization of Large Models: Approaches, Experiments, and Insights](https://arxiv.org/abs/2601.00526)
*Yuchuan Ye,Ming Ding,Youjia Chen,Peng Cheng,Dusit Niyato*

Main category: cs.LG

TL;DR: 本文探讨了大型模型在联邦学习框架下的定制化方法，首次尝试将prefix-tuning应用于联邦学习，验证了其可行性并与集中式方法性能接近。


<details>
  <summary>Details</summary>
Motivation: 随着大型模型的发展，如何在保护数据隐私的联邦学习框架下实现模型定制化成为一个重要挑战。本文旨在探索将各种大型模型定制技术应用于联邦学习环境的方法。

Method: 首先综述了多种大型模型定制技术（全微调、高效微调、提示工程、前缀调优、知识蒸馏、检索增强生成），然后讨论了这些技术在联邦学习框架下的实现方式。特别地，首次将prefix-tuning应用于联邦学习设置，并与其他三种联邦定制方法进行比较实验。

Result: 实验验证了联邦prefix-tuning的可行性，其性能接近集中式方法。与其他三种联邦定制方法相比，联邦prefix-tuning表现出竞争性的性能、令人满意的效率和一致的鲁棒性。

Conclusion: 本文成功展示了将prefix-tuning应用于联邦学习的可行性，为大型模型在保护隐私的分布式环境中的定制化提供了有效解决方案。联邦prefix-tuning在性能、效率和鲁棒性方面都表现出色，具有实际应用价值。

Abstract: In this article, we explore federated customization of large models and highlight the key challenges it poses within the federated learning framework. We review several popular large model customization techniques, including full fine-tuning, efficient fine-tuning, prompt engineering, prefix-tuning, knowledge distillation, and retrieval-augmented generation. Then, we discuss how these techniques can be implemented within the federated learning framework. Moreover, we conduct experiments on federated prefix-tuning, which, to the best of our knowledge, is the first trial to apply prefix-tuning in the federated learning setting. The conducted experiments validate its feasibility with performance close to centralized approaches. Further comparison with three other federated customization methods demonstrated its competitive performance, satisfactory efficiency, and consistent robustness.

</details>


### [108] [Cloud-Native Generative AI for Automated Planogram Synthesis: A Diffusion Model Approach for Multi-Store Retail Optimization](https://arxiv.org/abs/2601.00527)
*Ravi Teja Pagidoju,Shriya Agarwal*

Main category: cs.LG

TL;DR: 使用扩散模型和云原生架构自动生成零售货架图，将设计时间从30小时减少到0.5小时，约束满足率达94.4%


<details>
  <summary>Details</summary>
Motivation: 传统货架图设计耗时费力，平均每个复杂布局需要30小时。零售业需要更高效、自动化的解决方案来优化货架空间配置。

Method: 提出云原生架构，结合AWS云训练和边缘部署。使用扩散模型学习多个零售点的成功货架布局，通过改进的损失函数集成零售特定约束。

Result: 设计时间减少98.3%（30小时→0.5小时），约束满足率94.4%。经济分析显示创建费用减少97.5%，投资回收期4.4个月。系统支持10,000个并发请求。

Conclusion: 生成式AI可用于自动化零售空间优化，云原生架构提供可扩展的实时货架图生成解决方案，显著提升零售运营效率。

Abstract: Planogram creation is a significant challenge for retail, requiring an average of 30 hours per complex layout. This paper introduces a cloud-native architecture using diffusion models to automatically generate store-specific planograms. Unlike conventional optimization methods that reorganize existing layouts, our system learns from successful shelf arrangements across multiple retail locations to create new planogram configurations. The architecture combines cloud-based model training via AWS with edge deployment for real-time inference. The diffusion model integrates retail-specific constraints through a modified loss function. Simulation-based analysis demonstrates the system reduces planogram design time by 98.3% (from 30 to 0.5 hours) while achieving 94.4% constraint satisfaction. Economic analysis reveals a 97.5% reduction in creation expenses with a 4.4-month break-even period. The cloud-native architecture scales linearly, supporting up to 10,000 concurrent store requests. This work demonstrates the viability of generative AI for automated retail space optimization.

</details>


### [109] [Entropy Production in Machine Learning Under Fokker-Planck Probability Flow](https://arxiv.org/abs/2601.00554)
*Lennon Shikhman*

Main category: cs.LG

TL;DR: 提出基于熵的再训练框架，将数据漂移建模为概率流，通过熵平衡分解触发再训练，显著减少再训练次数同时保持性能


<details>
  <summary>Details</summary>
Motivation: 现有漂移检测方法缺乏动力学原理解释，无法指导再训练频率与运营成本之间的平衡。需要一种基于原理的框架来应对非平稳环境中的数据漂移问题。

Method: 将部署时数据漂移建模为Fokker-Planck方程控制的概率流，使用随时间演化的KL散度量模型-数据不匹配，通过熵平衡分解（包含非负熵产生项）触发无标签再训练策略。

Result: 在受控非平稳分类实验中，熵触发再训练实现了与高频再训练相当的预测性能，同时将再训练事件减少了一个数量级（相比每日和基于标签的策略）。

Conclusion: 基于熵的再训练框架为数据漂移提供了原理性动力学解释，通过响应累积不匹配而非延迟的性能崩溃，实现了再训练频率与运营成本的有效平衡。

Abstract: Machine learning models deployed in nonstationary environments experience performance degradation due to data drift. While many drift detection heuristics exist, most lack a principled dynamical interpretation and provide limited guidance on how retraining frequency should be balanced against operational cost. In this work, we propose an entropy--based retraining framework grounded in nonequilibrium stochastic dynamics. Modeling deployment--time data drift as probability flow governed by a Fokker--Planck equation, we quantify model--data mismatch using a time--evolving Kullback--Leibler divergence. We show that the time derivative of this mismatch admits an entropy--balance decomposition featuring a nonnegative entropy production term driven by probability currents. This interpretation motivates entropy--triggered retraining as a label--free intervention strategy that responds to accumulated mismatch rather than delayed performance collapse. In a controlled nonstationary classification experiment, entropy--triggered retraining achieves predictive performance comparable to high--frequency retraining while reducing retraining events by an order of magnitude relative to daily and label--based policies.

</details>


### [110] [Adversarial Samples Are Not Created Equal](https://arxiv.org/abs/2601.00577)
*Jennifer Crawford,Amol Khanna,Fred Lu,Amy R. Wagoner,Stella Biderman,Andre T. Nguyen,Edward Raff*

Main category: cs.LG

TL;DR: 论文提出区分两种对抗性弱点：利用非鲁棒特征的和不利用非鲁棒特征的，并设计了一个集成度量来量化对抗扰动对非鲁棒特征的操纵程度。


<details>
  <summary>Details</summary>
Motivation: 现有非鲁棒特征理论虽然解释了深度神经网络对对抗攻击的脆弱性，但忽略了那些不直接利用这些特征的对抗样本。需要区分这两种不同类型的对抗性弱点，以更全面地评估对抗鲁棒性。

Method: 提出了一个基于集成学习的度量方法，用于测量对抗扰动对非鲁棒特征的操纵程度，并用该度量分析攻击者生成的对抗样本的构成。

Result: 通过新度量方法能够区分两种对抗性弱点，并重新审视了多个现象，包括锐度感知最小化对对抗鲁棒性的影响，以及在鲁棒数据集上对抗训练与标准训练之间的鲁棒性差距。

Conclusion: 对抗性弱点应分为利用非鲁棒特征和不利用非鲁棒特征两种类型，这种区分对于全面评估对抗鲁棒性至关重要。提出的集成度量为分析对抗样本构成提供了新工具。

Abstract: Over the past decade, numerous theories have been proposed to explain the widespread vulnerability of deep neural networks to adversarial evasion attacks. Among these, the theory of non-robust features proposed by Ilyas et al. has been widely accepted, showing that brittle but predictive features of the data distribution can be directly exploited by attackers. However, this theory overlooks adversarial samples that do not directly utilize these features. In this work, we advocate that these two kinds of samples - those which use use brittle but predictive features and those that do not - comprise two types of adversarial weaknesses and should be differentiated when evaluating adversarial robustness. For this purpose, we propose an ensemble-based metric to measure the manipulation of non-robust features by adversarial perturbations and use this metric to analyze the makeup of adversarial samples generated by attackers. This new perspective also allows us to re-examine multiple phenomena, including the impact of sharpness-aware minimization on adversarial robustness and the robustness gap observed between adversarially training and standard training on robust datasets.

</details>


### [111] [Learning to be Reproducible: Custom Loss Design for Robust Neural Networks](https://arxiv.org/abs/2601.00578)
*Waqas Ahmed,Sheeba Samuel,Kevin Coakley,Birgitta Koenig-Ries,Odd Erik Gundersen*

Main category: cs.LG

TL;DR: 提出一种自定义损失函数（CLF）来减少训练结果对随机因素的敏感性，提高深度学习模型的稳定性和可靠性


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法缺乏确保跨运行一致性和鲁棒性的机制，即使在受控条件下模型准确率也存在显著波动，这影响了模型的可复现性和可靠性

Method: 提出自定义损失函数（CLF），通过调整参数在预测准确率和训练稳定性之间取得平衡，减少对权重初始化和数据洗牌等随机因素的敏感性

Result: 在图像分类和时间序列预测的多种架构上进行广泛实验，证明CLF能显著提高训练鲁棒性，同时不牺牲预测性能

Conclusion: CLF是开发更稳定、可靠和可信赖神经网络的有效且高效策略，为深度学习模型的可复现性和可靠性提供了解决方案

Abstract: To enhance the reproducibility and reliability of deep learning models, we address a critical gap in current training methodologies: the lack of mechanisms that ensure consistent and robust performance across runs. Our empirical analysis reveals that even under controlled initialization and training conditions, the accuracy of the model can exhibit significant variability. To address this issue, we propose a Custom Loss Function (CLF) that reduces the sensitivity of training outcomes to stochastic factors such as weight initialization and data shuffling. By fine-tuning its parameters, CLF explicitly balances predictive accuracy with training stability, leading to more consistent and reliable model performance. Extensive experiments across diverse architectures for both image classification and time series forecasting demonstrate that our approach significantly improves training robustness without sacrificing predictive performance. These results establish CLF as an effective and efficient strategy for developing more stable, reliable and trustworthy neural networks.

</details>


### [112] [HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts](https://arxiv.org/abs/2601.00583)
*Zihan Fang,Zheng Lin,Senkang Hu,Yanan Ma,Yihang Tao,Yiqin Deng,Xianhao Chen,Yuguang Fang*

Main category: cs.LG

TL;DR: HFedMoE：一种面向异构客户端的MoE联邦学习框架，通过专家重要性评估、自适应专家选择和稀疏感知聚合，实现资源受限设备上的高效LLM微调。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习在微调大语言模型时面临计算资源限制问题，而MoE模型虽然能减少计算负担，但在联邦学习环境中面临三个关键挑战：1）缺乏可靠指标评估专家对本地性能的影响；2）异构计算资源限制专家激活；3）客户端特定专家子集和路由偏好破坏全局聚合。

Method: 提出HFedMoE框架：1）基于专家对微调性能的贡献评估专家重要性；2）从信息瓶颈角度自适应选择专家子集以匹配客户端计算预算；3）设计稀疏感知模型聚合策略，加权聚合活跃微调的专家和门控参数。

Result: 大量实验表明，HFedMoE在训练准确率和收敛速度方面优于现有最先进的基准方法。

Conclusion: HFedMoE成功解决了MoE在联邦学习中的关键挑战，为资源受限设备上的高效LLM微调提供了有效解决方案，实现了计算效率与性能的平衡。

Abstract: While federated learning (FL) enables fine-tuning of large language models (LLMs) without compromising data privacy, the substantial size of an LLM renders on-device training impractical for resource-constrained clients, such as mobile devices. Thus, Mixture-of-Experts (MoE) models have emerged as a computation-efficient solution, which activates only a sparse subset of experts during model training to reduce computing burden without sacrificing performance. Though integrating MoE into FL fine-tuning holds significant potential, it still encounters three key challenges: i) selecting appropriate experts for clients remains challenging due to the lack of a reliable metric to measure each expert's impact on local fine-tuning performance, ii) the heterogeneous computing resources across clients severely hinder MoE-based LLM fine-tuning, as dynamic expert activations across diverse input samples can overwhelm resource-constrained devices, and iii) client-specific expert subsets and routing preference undermine global aggregation, where misaligned expert updates and inconsistent gating networks in troduce destructive interference. To address these challenges, we propose HFedMoE, a heterogeneous MoE-based FL fine-tuning framework that customizes a subset of experts to each client for computation-efficient LLM fine-tuning. Specifically, HFedMoE identifies the expert importance based on its contributions to fine-tuning performance, and then adaptively selects a subset of experts from an information bottleneck perspective to align with each client' s computing budget. A sparsity-aware model aggregation strategy is also designed to aggregate the actively fine-tuned experts and gating parameters with importance weighted contributions. Extensive experiments demonstrate that HFedMoE outperforms state-of-the-art benchmarks in training accuracy and convergence speed.

</details>


### [113] [Cycling Race Time Prediction: A Personalized Machine Learning Approach Using Route Topology and Training Load](https://arxiv.org/abs/2601.00604)
*Francisco Aguilera Moreno*

Main category: cs.LG

TL;DR: 使用机器学习预测骑行时长，结合路线拓扑特征和运动员当前体能状态，相比传统物理模型更实用


<details>
  <summary>Details</summary>
Motivation: 现有基于物理模型的骑行时长预测方法需要大量参数（如空气阻力系数、实时风速预报），这对业余骑手不实用。需要一种更简单的方法来预测骑行时长，帮助训练规划和赛事准备。

Method: 采用机器学习方法，使用路线拓扑特征结合运动员当前体能状态（从训练负荷指标推导）。模型从历史数据中学习运动员特定的表现模式，用历史表现代理替代复杂的物理测量。使用单运动员数据集（N=96次骑行）进行N-of-1研究设计，通过严格的特征工程消除数据泄露，采用Lasso回归模型。

Result: Lasso回归结合拓扑+体能特征达到MAE=6.60分钟和R²=0.922。整合体能指标（CTL, ATL）相比仅使用拓扑特征减少14%误差（MAE从7.66分钟降至6.60分钟），表明生理状态对自定节奏的表现有显著约束作用。渐进检查点预测支持动态比赛规划。

Conclusion: 机器学习方法能有效预测骑行时长，通过结合路线拓扑和运动员体能状态，为业余骑手提供了比传统物理模型更实用的解决方案。生理状态信息显著提升预测准确性，支持动态训练和赛事规划。

Abstract: Predicting cycling duration for a given route is essential for training planning and event preparation. Existing solutions rely on physics-based models that require extensive parameterization, including aerodynamic drag coefficients and real-time wind forecasts, parameters impractical for most amateur cyclists. This work presents a machine learning approach that predicts ride duration using route topology features combined with the athlete's current fitness state derived from training load metrics. The model learns athlete-specific performance patterns from historical data, substituting complex physical measurements with historical performance proxies. We evaluate the approach using a single-athlete dataset (N=96 rides) in an N-of-1 study design. After rigorous feature engineering to eliminate data leakage, we find that Lasso regression with Topology + Fitness features achieves MAE=6.60 minutes and R2=0.922. Notably, integrating fitness metrics (CTL, ATL) reduces error by 14% compared to topology alone (MAE=7.66 min), demonstrating that physiological state meaningfully constrains performance even in self-paced efforts. Progressive checkpoint predictions enable dynamic race planning as route difficulty becomes apparent.

</details>


### [114] [Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization](https://arxiv.org/abs/2601.00611)
*Hareshkumar Jadav,Ranveer Singh,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: 提出了一种用于在向下闭凸体上最大化非负、非单调γ-弱DR-次模函数的近似算法，其保证随γ平滑变化，在γ=1时恢复0.401近似比，在γ<1时性能优雅下降并优于先前结果。


<details>
  <summary>Details</summary>
Motivation: 次模目标在约束下的最大化是机器学习和优化中的基本问题。现有研究主要关注单调次模函数或DR-次模函数，但对于更一般的γ-弱DR-次模函数（γ<1）在非单调情况下的最大化问题，现有算法性能有限，需要开发更有效的近似算法。

Method: 结合Frank-Wolfe引导的连续贪婪框架与γ感知的双贪婪步骤，形成简单有效的处理非单调性的方法。该算法针对向下闭凸体上的非单调γ-弱DR-次模函数最大化问题，通过γ-aware的调整来适应函数的弱次模性程度。

Result: 算法保证随γ平滑变化：当γ=1（DR-次模情况）时恢复0.401近似比；当γ<1时，保证优雅下降且优于先前报道的γ-弱DR-次模最大化结果。在非单调γ-弱DR-次模最大化问题上达到了最先进的性能保证。

Conclusion: 提出的算法为向下闭凸体上的非单调γ-弱DR-次模函数最大化问题提供了有效的解决方案，其性能保证随γ平滑变化，在γ=1时达到已知最佳结果，在γ<1时优于现有方法，为更广泛的次模优化问题提供了理论保证。

Abstract: Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $γ$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $γ$; in particular, when $γ=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $γ<1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $γ$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $γ$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $γ$-weakly DR-submodular maximization over down-closed convex bodies.

</details>


### [115] [Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning](https://arxiv.org/abs/2601.00607)
*Sonia Khetarpaul,P Y Sharan*

Main category: cs.LG

TL;DR: 提出基于图神经网络的强化学习框架，用于智能城市出租车最优部署，通过整合实时交通数据减少乘客等待时间和司机行驶距离。


<details>
  <summary>Details</summary>
Motivation: 传统出租车热点预测模型仅依赖历史需求数据，忽略了交通拥堵、道路事故、公共事件等动态影响因素，无法实现实时供需匹配优化。

Method: 将城市道路网络建模为图结构，使用图神经网络编码时空依赖关系，结合Q-learning智能体推荐最优出租车热点位置，奖励机制同时优化乘客等待时间、司机行驶距离和拥堵避免。

Result: 在模拟的德里出租车数据集上，相比基线随机选择方法，乘客等待时间减少约56%，行驶距离减少38%。

Conclusion: 该框架可适应多模式交通系统，可集成到智能城市平台实现实时城市移动性优化，为智能交通管理提供有效解决方案。

Abstract: In the context of smart city transportation, efficient matching of taxi supply with passenger demand requires real-time integration of urban traffic network data and mobility patterns. Conventional taxi hotspot prediction models often rely solely on historical demand, overlooking dynamic influences such as traffic congestion, road incidents, and public events. This paper presents a traffic-aware, graph-based reinforcement learning (RL) framework for optimal taxi placement in metropolitan environments. The urban road network is modeled as a graph where intersections represent nodes, road segments serve as edges, and node attributes capture historical demand, event proximity, and real-time congestion scores obtained from live traffic APIs. Graph Neural Network (GNN) embeddings are employed to encode spatial-temporal dependencies within the traffic network, which are then used by a Q-learning agent to recommend optimal taxi hotspots. The reward mechanism jointly optimizes passenger waiting time, driver travel distance, and congestion avoidance. Experiments on a simulated Delhi taxi dataset, generated using real geospatial boundaries and historic ride-hailing request patterns, demonstrate that the proposed model reduced passenger waiting time by about 56% and reduced travel distance by 38% compared to baseline stochastic selection. The proposed approach is adaptable to multi-modal transport systems and can be integrated into smart city platforms for real-time urban mobility optimization.

</details>


### [116] [Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability](https://arxiv.org/abs/2601.00655)
*Kasra Fouladi,Hamta Rahmani*

Main category: cs.LG

TL;DR: IGBO框架通过双目标优化训练可解释模型，利用DAG编码特征重要性层次结构，使用TIG测量特征重要性，并提出最优路径预言机解决OOD问题。


<details>
  <summary>Details</summary>
Motivation: 现有可解释模型训练方法缺乏有效整合结构化领域知识的能力，且传统特征重要性计算方法存在分布外问题，需要更鲁棒的框架来平衡模型准确性和可解释性约束。

Method: 提出IGBO框架：1) 将特征重要性层次编码为有向无环图；2) 使用时序积分梯度测量特征重要性；3) 设计最优路径预言机学习数据流形感知的积分路径以解决OOD问题；4) 采用双目标优化平衡准确性和可解释性约束。

Result: 理论分析证明收敛性和对mini-batch噪声的鲁棒性；时间序列数据实验显示IGBO能有效强制执行DAG约束，精度损失最小，优于标准正则化基线方法。

Conclusion: IGBO框架成功整合领域知识到模型训练中，通过双目标优化平衡准确性和可解释性，为解决可解释AI中的领域知识整合和OOD问题提供了有效方案。

Abstract: This paper introduces Interpretability-Guided Bi-objective Optimization (IGBO), a framework that trains interpretable models by incorporating structured domain knowledge via a bi-objective formulation. IGBO encodes feature importance hierarchies as a Directed Acyclic Graph (DAG) and uses Temporal Integrated Gradients (TIG) to measure feature importance. To address the Out-of-Distribution (OOD) problem in TIG computation, we propose an Optimal Path Oracle that learns data-manifold-aware integration paths. Theoretical analysis proves convergence properties and robustness to mini-batch noise, while empirical results on time-series data demonstrate IGBO's effectiveness in enforcing DAG constraints with minimal accuracy loss, outperforming standard regularization baselines.

</details>


### [117] [Do Chatbot LLMs Talk Too Much? The YapBench Benchmark](https://arxiv.org/abs/2601.00624)
*Vadim Borisov,Michael Gröger,Mina Mikhael,Richard H. Schreiber*

Main category: cs.LG

TL;DR: YapBench是一个用于量化LLMs在简洁理想提示上过度生成的轻量级基准测试，包含300多个英文提示，通过YapScore和YapIndex评估76个助手LLMs的冗余回答问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs（如ChatGPT、Claude、Gemini）作为通用助手时，经常对简单请求给出不必要的冗长回答，包含冗余解释、模棱两可的表述或模板化内容，这增加了认知负担和基于token的推理成本。先前研究表明基于偏好的后训练和LLM评估可能导致系统性长度偏差，即使质量相当，更长的回答也更容易获得奖励。

Method: 引入YapBench基准测试，每个项目包含单轮提示、精心设计的最小充分基线答案和类别标签。主要指标YapScore测量超出基线答案的字符数，不依赖特定分词器。通过YapIndex（类别级中位数YapScore的均匀加权平均值）总结模型性能。基准包含300多个英文提示，涵盖三种简洁理想场景：模糊输入需要简短澄清、封闭式事实问题、单行编码任务。

Result: 评估76个助手LLMs，观察到中位数超额长度存在数量级差异，并发现特定类别的失败模式：在模糊输入上填充真空内容，在单行技术请求上添加解释或格式化开销。

Conclusion: YapBench提供了一个量化LLMs过度生成问题的标准化评估框架，揭示了不同模型在简洁回答能力上的显著差异和特定失败模式，为跟踪模型简洁性行为提供了持续评估工具。

Abstract: Large Language Models (LLMs) such as ChatGPT, Claude, and Gemini increasingly act as general-purpose copilots, yet they often respond with unnecessary length on simple requests, adding redundant explanations, hedging, or boilerplate that increases cognitive load and inflates token-based inference cost. Prior work suggests that preference-based post-training and LLM-judged evaluations can induce systematic length bias, where longer answers are rewarded even at comparable quality.
  We introduce YapBench, a lightweight benchmark for quantifying user-visible over-generation on brevity-ideal prompts. Each item consists of a single-turn prompt, a curated minimal-sufficient baseline answer, and a category label. Our primary metric, YapScore, measures excess response length beyond the baseline in characters, enabling comparisons across models without relying on any specific tokenizer. We summarize model performance via the YapIndex, a uniformly weighted average of category-level median YapScores.
  YapBench contains over three hundred English prompts spanning three common brevity-ideal settings: (A) minimal or ambiguous inputs where the ideal behavior is a short clarification, (B) closed-form factual questions with short stable answers, and (C) one-line coding tasks where a single command or snippet suffices. Evaluating 76 assistant LLMs, we observe an order-of-magnitude spread in median excess length and distinct category-specific failure modes, including vacuum-filling on ambiguous inputs and explanation or formatting overhead on one-line technical requests. We release the benchmark and maintain a live leaderboard for tracking verbosity behavior over time.

</details>


### [118] [Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation](https://arxiv.org/abs/2601.00664)
*Taekyung Ki,Sangwon Jang,Jaehyeong Jo,Jaehong Yoon,Sung Ju Hwang*

Main category: cs.LG

TL;DR: 提出Avatar Forcing框架，通过扩散强制建模实时用户-头像交互，实现低延迟（约500ms）的交互式说话头像生成，比基线快6.8倍，并引入无标签偏好优化学习表达性交互。


<details>
  <summary>Details</summary>
Motivation: 当前说话头像生成模型缺乏真正的交互感，只能生成单向响应，缺乏情感参与。需要解决两个关键挑战：在因果约束下实时生成运动，以及无需额外标注数据学习表达性、生动的反应。

Method: 提出Avatar Forcing框架，通过扩散强制建模实时用户-头像交互，处理实时多模态输入（用户音频和动作）。引入直接偏好优化方法，利用通过丢弃用户条件构建的合成负样本来实现无标签的表达性交互学习。

Result: 框架实现低延迟实时交互（约500ms），比基线快6.8倍。生成的响应性和表达性头像运动在超过80%的情况下优于基线。

Conclusion: Avatar Forcing框架成功解决了交互式说话头像生成的关键挑战，实现了低延迟实时交互和表达性反应，为虚拟通信和内容创作提供了更真实的交互体验。

Abstract: Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.

</details>


### [119] [IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning](https://arxiv.org/abs/2601.00677)
*Haonan Song,Qingchen Xie,Huan Zhu,Feng Xiao,Luxi Xing,Fuzhen Li,Liu Kang,Feng Jiang,Zhiyong Zheng,Fan Yang*

Main category: cs.LG

TL;DR: IRPO提出了一种新的强化学习框架，通过将Bradley-Terry模型融入GRPO，将成对比较的O(n²)复杂度降低为点式评分，在保持可解释性的同时显著提升计算效率，并在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 生成式奖励模型（GRMs）因其可解释性、推理时扩展性和通过强化学习进行优化的潜力而受到关注，但广泛使用的成对GRMs在与GRPO等RL算法结合时存在计算瓶颈：1）获取相对分数需要O(n²)时间复杂度的成对比较；2）重复采样或额外思维链推理带来的计算开销。

Method: 提出Intergroup Relative Preference Optimization (IRPO)框架，将Bradley-Terry模型融入Group Relative Policy Optimization (GRPO)，为每个响应生成点式评分，从而在RL训练期间能够高效评估任意数量的候选响应，同时保持可解释性和细粒度奖励信号。

Result: IRPO在多个基准测试中实现了点式GRMs中的最先进性能，与当前领先的成对GRMs性能相当。更重要的是，在后训练评估中，IRPO显著优于成对GRMs。

Conclusion: IRPO通过将成对比较转换为点式评分，有效解决了GRMs与RL算法结合时的计算瓶颈问题，在保持可解释性和性能的同时大幅提升了计算效率，为生成式奖励模型的实用化提供了有效解决方案。

Abstract: Generative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL). However, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO). This bottleneck arises from two factors: (i) the O(n^2) time complexity of pairwise comparisons required to obtain relative scores, and (ii) the computational overhead of repeated sampling or additional chain-of-thought (CoT) reasoning to improve performance. To address the first factor, we propose Intergroup Relative Preference Optimization (IRPO), a novel RL framework that incorporates the well-established Bradley-Terry model into GRPO. By generating a pointwise score for each response, IRPO enables efficient evaluation of arbitrarily many candidates during RL training while preserving interpretability and fine-grained reward signals. Experimental results demonstrate that IRPO achieves state-of-the-art (SOTA) performance among pointwise GRMs across multiple benchmarks, with performance comparable to that of current leading pairwise GRMs. Furthermore, we show that IRPO significantly outperforms pairwise GRMs in post-training evaluations.

</details>


### [120] [Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty](https://arxiv.org/abs/2601.00737)
*Uğurcan Özalp*

Main category: cs.LG

TL;DR: STAC算法通过分布评论家网络建模时序回报的不确定性，利用时间性偶然不确定性而非认知不确定性来缩放悲观偏差，解决评论家网络高估问题，同时提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 离策略演员-评论家方法虽然样本效率高，但评论家网络存在系统性高估价值估计的问题。现有方法使用集成方法量化认知不确定性来引入悲观偏差，但这种方法计算成本高且可能不是最优解。

Method: 提出STAC算法：1) 使用单个分布评论家网络建模时序回报的不确定性；2) 利用时间性偶然不确定性（来自随机转移、奖励和策略引起的贝尔曼目标变异性）来缩放悲观偏差；3) 对评论家和演员网络应用dropout进行正则化。

Result: 实验表明：1) 基于分布评论家的悲观偏差足以缓解高估问题；2) 在随机环境中自然产生风险规避行为；3) dropout进一步提高了训练稳定性和性能；4) 使用单个分布评论家网络提升了计算效率。

Conclusion: STAC通过利用时间性偶然不确定性而非认知不确定性来缩放悲观偏差，有效解决了评论家网络高估问题，同时通过单个分布评论家网络和dropout正则化实现了更好的计算效率和性能。

Abstract: Off-policy actor-critic methods in reinforcement learning train a critic with temporal-difference updates and use it as a learning signal for the policy (actor). This design typically achieves higher sample efficiency than purely on-policy methods. However, critic networks tend to overestimate value estimates systematically. This is often addressed by introducing a pessimistic bias based on uncertainty estimates. Current methods employ ensembling to quantify the critic's epistemic uncertainty-uncertainty due to limited data and model ambiguity-to scale pessimistic updates. In this work, we propose a new algorithm called Stochastic Actor-Critic (STAC) that incorporates temporal (one-step) aleatoric uncertainty-uncertainty arising from stochastic transitions, rewards, and policy-induced variability in Bellman targets-to scale pessimistic bias in temporal-difference updates, rather than relying on epistemic uncertainty. STAC uses a single distributional critic network to model the temporal return uncertainty, and applies dropout to both the critic and actor networks for regularization. Our results show that pessimism based on a distributional critic alone suffices to mitigate overestimation, and naturally leads to risk-averse behavior in stochastic environments. Introducing dropout further improves training stability and performance by means of regularization. With this design, STAC achieves improved computational efficiency using a single distributional critic network.

</details>


### [121] [TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications](https://arxiv.org/abs/2601.00691)
*Mohamed Trabelsi,Huseyin Uzunalioglu*

Main category: cs.LG

TL;DR: TeleDoCTR是一个针对电信领域票务故障排除的端到端系统，通过集成领域特定排序和生成模型，自动化分类、检索和生成任务，显著提升故障排除的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 电信领域的票务故障排除是一个高度复杂且耗时的过程，需要专家解读票务内容、查阅文档和搜索历史记录。这种人工密集型方法不仅延迟问题解决，还阻碍整体运营效率。需要一种自动化系统来提升电信票务故障排除的效果和效率。

Method: 提出TeleDoCTR系统，这是一个针对电信领域的、特定领域的、上下文感知的故障排除系统。系统集成领域特定排序和生成模型，自动化故障排除工作流程的三个关键步骤：1) 将票务分类到适当的专家团队（分类任务）；2) 检索上下文和语义相似的历史票务（检索任务）；3) 生成详细故障分析报告，包括问题、根本原因和潜在解决方案（生成任务）。

Result: 在真实世界电信基础设施数据集上评估TeleDoCTR，证明其性能优于现有最先进方法，显著提升了故障排除过程的准确性和效率。

Conclusion: TeleDoCTR是一个有效的电信票务故障排除系统，通过自动化关键工作流程步骤，能够显著提升电信组织中的票务解决效率和准确性。

Abstract: Ticket troubleshooting refers to the process of analyzing and resolving problems that are reported through a ticketing system. In large organizations offering a wide range of services, this task is highly complex due to the diversity of submitted tickets and the need for specialized domain knowledge. In particular, troubleshooting in telecommunications (telecom) is a very time-consuming task as it requires experts to interpret ticket content, consult documentation, and search historical records to identify appropriate resolutions. This human-intensive approach not only delays issue resolution but also hinders overall operational efficiency. To enhance the effectiveness and efficiency of ticket troubleshooting in telecom, we propose TeleDoCTR, a novel telecom-related, domain-specific, and contextual troubleshooting system tailored for end-to-end ticket resolution in telecom. TeleDoCTR integrates both domain-specific ranking and generative models to automate key steps of the troubleshooting workflow which are: routing tickets to the appropriate expert team responsible for resolving the ticket (classification task), retrieving contextually and semantically similar historical tickets (retrieval task), and generating a detailed fault analysis report outlining the issue, root cause, and potential solutions (generation task). We evaluate TeleDoCTR on a real-world dataset from a telecom infrastructure and demonstrate that it achieves superior performance over existing state-of-the-art methods, significantly enhancing the accuracy and efficiency of the troubleshooting process.

</details>


### [122] [FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing](https://arxiv.org/abs/2601.00785)
*Sunny Gupta,Amit Sethi*

Main category: cs.LG

TL;DR: FedHypeVAE：基于超网络的差分隐私联邦数据合成框架，通过个性化解码器和类别条件先验解决非IID数据分布下的嵌入级数据生成问题


<details>
  <summary>Details</summary>
Motivation: 现有联邦数据共享方法在非IID客户端异构性下表现不佳，且对梯度泄漏的正式保护有限，需要一种既能保护隐私又能处理非IID数据分布的嵌入级数据合成框架

Method: 基于条件VAE架构，用超网络生成客户端感知的解码器和类别条件先验；采用差分隐私优化超网络，本地MMD对齐和Lipschitz正则化增强稳定性；使用元代码实现领域无关合成

Result: FedHypeVAE在非IID联邦设置下实现了隐私保护的数据合成，通过个性化生成层而非下游模型，解耦本地数据与通信参数，提供可控的多领域覆盖

Conclusion: 该框架在生成器层面统一了个性化、隐私保护和分布对齐，为联邦设置下的隐私保护数据合成建立了原则性基础

Abstract: Federated data sharing promises utility without centralizing raw data, yet existing embedding-level generators struggle under non-IID client heterogeneity and provide limited formal protection against gradient leakage. We propose FedHypeVAE, a differentially private, hypernetwork-driven framework for synthesizing embedding-level data across decentralized clients. Building on a conditional VAE backbone, we replace the single global decoder and fixed latent prior with client-aware decoders and class-conditional priors generated by a shared hypernetwork from private, trainable client codes. This bi-level design personalizes the generative layerrather than the downstream modelwhile decoupling local data from communicated parameters. The shared hypernetwork is optimized under differential privacy, ensuring that only noise-perturbed, clipped gradients are aggregated across clients. A local MMD alignment between real and synthetic embeddings and a Lipschitz regularizer on hypernetwork outputs further enhance stability and distributional coherence under non-IID conditions. After training, a neutral meta-code enables domain agnostic synthesis, while mixtures of meta-codes provide controllable multi-domain coverage. FedHypeVAE unifies personalization, privacy, and distribution alignment at the generator level, establishing a principled foundation for privacy-preserving data synthesis in federated settings. Code: github.com/sunnyinAI/FedHypeVAE

</details>


### [123] [ARISE: Adaptive Reinforcement Integrated with Swarm Exploration](https://arxiv.org/abs/2601.00693)
*Rajiv Chaitanya M,D R Ramesh Babu*

Main category: cs.LG

TL;DR: ARISE：轻量级框架，通过群体探索层增强标准策略梯度方法，在非平稳奖励和高维策略任务中显著提升探索效率和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 强化学习中的有效探索仍然是一个关键挑战，特别是在非平稳奖励或高维策略的情况下。现有方法在复杂任务中探索效率有限，需要更有效的探索机制。

Method: ARISE框架在标准策略梯度方法基础上增加紧凑的群体探索层，将策略动作与粒子驱动建议混合。每个粒子代表动作空间中采样的候选策略轨迹，使用奖励方差线索自适应调节探索强度。

Result: 在简单基准上略有改进（CartPole-v1 +0.7%），但在挑战性任务中提升显著：LunarLander-v3 +46%，Hopper-v4 +22%，同时在Walker2d和Ant上保持稳定。在非平稳奖励变化下，ARISE提供明显鲁棒性优势，在CartPole上比PPO高出75分。

Conclusion: ARISE提供了一个简单、架构无关的途径，无需改变核心算法结构即可创建更具探索性和鲁棒性的RL智能体。群体组件和自适应机制都对性能有贡献。

Abstract: Effective exploration remains a key challenge in RL, especially with non-stationary rewards or high-dimensional policies. We introduce ARISE, a lightweight framework that enhances reinforcement learning by augmenting standard policy-gradient methods with a compact swarm-based exploration layer. ARISE blends policy actions with particle-driven proposals, where each particle represents a candidate policy trajectory sampled in the action space, and modulates exploration adaptively using reward-variance cues. While easy benchmarks exhibit only slight improvements (e.g., +0.7% on CartPole-v1), ARISE yields substantial gains on more challenging tasks, including +46% on LunarLander-v3 and +22% on Hopper-v4, while preserving stability on Walker2d and Ant. Under non-stationary reward shifts, ARISE provides marked robustness advantages, outperforming PPO by +75 points on CartPole and improving LunarLander accordingly. Ablation studies confirm that both the swarm component and the adaptive mechanism contribute to the performance. Overall, ARISE offers a simple, architecture-agnostic route to more exploratory and resilient RL agents without altering core algorithmic structures.

</details>


### [124] [Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning](https://arxiv.org/abs/2601.00791)
*Valentin Noël*

Main category: cs.LG

TL;DR: 提出一种无需训练的方法，通过分析注意力矩阵的谱特征来检测大语言模型中的有效数学推理，实验表明该方法在多种模型上都能达到85-95%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 需要一种无需训练数据、微调或学习分类器的方法来检测大语言模型生成的数学推理是否有效，以解决幻觉检测和AI安全监控的问题。

Method: 将注意力矩阵视为动态图的邻接矩阵，提取四个可解释的谱诊断指标：Fiedler值（代数连通性）、高频能量比（HFER）、图信号平滑度和谱熵，通过单阈值分类器区分有效和无效数学证明。

Result: 在来自四个独立架构家族的七个Transformer模型上实验，效应量高达Cohen's d=3.30，分类准确率达到85.0-95.6%，校准阈值在全数据集上达到93-95%。发现该方法检测的是逻辑一致性而非编译器接受度，并揭示了注意力机制设计对谱特征的影响。

Conclusion: 谱图分析为推理验证提供了一个原则性框架，具有在幻觉检测和AI安全监控中的直接应用价值，且无需训练数据或微调即可实现高精度检测。

Abstract: We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\text{MW}} = 1.16 \times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.

</details>


### [125] [Bayesian Inverse Games with High-Dimensional Multi-Modal Observations](https://arxiv.org/abs/2601.00696)
*Yash Jain,Xinjie Liu,Lasse Peters,David Fridovich-Keil,Ufuk Topcu*

Main category: cs.LG

TL;DR: 提出贝叶斯逆博弈框架，通过变分自编码器和可微纳什博弈求解器从交互数据中学习先验和后验分布，相比最大似然估计能更好量化不确定性并实现更安全的决策


<details>
  <summary>Details</summary>
Motivation: 现有逆博弈方法仅提供点估计而无法量化估计不确定性，导致下游规划决策可能过度自信地采取不安全行动。需要一种能处理多模态观测数据并实时生成后验分布样本的方法

Method: 提出贝叶斯逆博弈框架：训练结构化变分自编码器，嵌入可微纳什博弈求解器，无需真实目标标签即可从交互数据集中学习先验和后验分布

Result: 框架成功学习先验和后验分布，相比基于最大似然估计的逆博弈方法提高了推理质量，实现了更安全的下游决策而不牺牲效率。多模态推理在轨迹信息不足时进一步减少不确定性

Conclusion: 贝叶斯逆博弈方法能有效量化不确定性，提高多智能体交互场景中的决策安全性，特别是在观测信息有限或不完整的情况下具有重要价值

Abstract: Many multi-agent interaction scenarios can be naturally modeled as noncooperative games, where each agent's decisions depend on others' future actions. However, deploying game-theoretic planners for autonomous decision-making requires a specification of all agents' objectives. To circumvent this practical difficulty, recent work develops maximum likelihood techniques for solving inverse games that can identify unknown agent objectives from interaction data. Unfortunately, these methods only infer point estimates and do not quantify estimator uncertainty; correspondingly, downstream planning decisions can overconfidently commit to unsafe actions. We present an approximate Bayesian inference approach for solving the inverse game problem, which can incorporate observation data from multiple modalities and be used to generate samples from the Bayesian posterior over the hidden agent objectives given limited sensor observations in real time. Concretely, the proposed Bayesian inverse game framework trains a structured variational autoencoder with an embedded differentiable Nash game solver on interaction datasets and does not require labels of agents' true objectives. Extensive experiments show that our framework successfully learns prior and posterior distributions, improves inference quality over maximum likelihood estimation-based inverse game approaches, and enables safer downstream decision-making without sacrificing efficiency. When trajectory information is uninformative or unavailable, multimodal inference further reduces uncertainty by exploiting additional observation modalities.

</details>


### [126] [BSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting](https://arxiv.org/abs/2601.00698)
*Maximilian Reinwardt,Michael Eichelbeck,Matthias Althoff*

Main category: cs.LG

TL;DR: BSAT使用B样条自适应分词器解决长时序预测中自注意力二次复杂度和均匀分块问题，通过高曲率区域自适应分块和混合位置编码实现高效压缩


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在长时序预测中存在自注意力二次复杂度问题，且均匀分块方式可能与数据的语义结构不匹配，需要更高效的自适应方法

Method: 提出B样条自适应分词器(BSAT)：1) 使用B样条拟合时序数据，在高曲率区域自适应放置token；2) 将变长基函数表示为固定大小token（系数+位置）；3) 提出混合位置编码L-RoPE，结合可学习位置编码和层间可学习基的旋转位置嵌入

Result: 在多个公开基准测试中表现优异，在高压缩率下保持强性能，特别适合内存受限的应用场景

Conclusion: BSAT通过自适应分词和混合位置编码，有效解决了长时序预测中的计算效率和语义对齐问题，在内存受限场景下具有实用价值

Abstract: Long-term time series forecasting using transformers is hampered by the quadratic complexity of self-attention and the rigidity of uniform patching, which may be misaligned with the data's semantic structure. In this paper, we introduce the \textit{B-Spline Adaptive Tokenizer (BSAT)}, a novel, parameter-free method that adaptively segments a time series by fitting it with B-splines. BSAT algorithmically places tokens in high-curvature regions and represents each variable-length basis function as a fixed-size token, composed of its coefficient and position. Further, we propose a hybrid positional encoding that combines a additive learnable positional encoding with Rotary Positional Embedding featuring a layer-wise learnable base: L-RoPE. This allows each layer to attend to different temporal dependencies. Our experiments on several public benchmarks show that our model is competitive with strong performance at high compression rates. This makes it particularly well-suited for use cases with strong memory constraints.

</details>


### [127] [Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL](https://arxiv.org/abs/2601.00728)
*Erin Carson,Xinye Chen*

Main category: cs.LG

TL;DR: 提出一个基于强化学习的自适应精度调优框架，用于线性求解器和其他算法，通过上下文多臂老虎机问题动态选择计算步骤的精度配置，平衡精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 在科学计算中，混合精度数值方法可以显著提高计算效率，但手动选择精度配置既耗时又困难。需要一种自动化的方法来动态调整计算步骤的精度，以在保持准确性的同时降低计算成本。

Method: 将精度调优问题建模为上下文多臂老虎机问题，使用离散化状态空间和增量动作价值估计（Q表）来选择最优精度配置。采用epsilon-greedy策略优化Q表，奖励函数平衡精度和计算成本。在线性系统求解的迭代细化应用中，基于计算特征（如近似条件数和矩阵范数）动态选择精度。

Result: 实验结果表明，该框架能有效选择精度配置，在保持与双精度基线相当的准确性的同时，显著降低计算成本。框架能够泛化到未见过的数据集，展示了良好的适应性。

Conclusion: 这是首个将强化学习用于精度自动调优并验证于未见数据集的工作，为科学计算中的混合精度数值方法提供了新思路，可扩展到其他数值算法。

Abstract: We propose a reinforcement learning (RL) framework for adaptive precision tuning of linear solvers, and can be extended to general algorithms. The framework is formulated as a contextual bandit problem and solved using incremental action-value estimation with a discretized state space to select optimal precision configurations for computational steps, balancing precision and computational efficiency. To verify its effectiveness, we apply the framework to iterative refinement for solving linear systems $Ax = b$. In this application, our approach dynamically chooses precisions based on calculated features from the system. In detail, a Q-table maps discretized features (e.g., approximate condition number and matrix norm)to actions (chosen precision configurations for specific steps), optimized via an epsilon-greedy strategy to maximize a multi-objective reward balancing accuracy and computational cost. Empirical results demonstrate effective precision selection, reducing computational cost while maintaining accuracy comparable to double-precision baselines. The framework generalizes to diverse out-of-sample data and offers insight into utilizing RL precision selection for other numerical algorithms, advancing mixed-precision numerical methods in scientific computing. To the best of our knowledge, this is the first work on precision autotuning with RL and verified on unseen datasets.

</details>


### [128] [The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving](https://arxiv.org/abs/2601.00747)
*Max Ruiz Luyten,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 论文提出分布创造性推理(DCR)框架，分析现有LLM推理方法导致多样性衰减的问题，并提供保持正确性和创造性的解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理管道主要优化正确性，导致推理路径分布崩溃，语义熵降低，削弱创造性问题解决能力。需要分析这种失败并找到保持正确性和创造性的方法。

Method: 提出分布创造性推理(DCR)框架，将训练视为通过解决方案轨迹概率测度的梯度流。STaR、GRPO、DPO等方法都是该损失函数的特例。

Result: 框架提供三个核心结果：1)多样性衰减定理，描述基于正确性的目标如何导致STaR、GRPO、DPO的不同多样性衰减模式；2)确保收敛到稳定多样策略的设计；3)实现这一目标的简单实用方法。

Conclusion: DCR为LLM提供了首个保持正确性和创造性的原则性方法，解决了现有推理方法导致的多样性崩溃问题。

Abstract: State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.

</details>


### [129] [A Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football](https://arxiv.org/abs/2601.00748)
*Sean Groom,Shuo Wang,Francisco Belo,Axl Rice,Liam Anderson*

Main category: cs.LG

TL;DR: 提出基于协变量依赖隐马尔可夫模型(CDHMM)的角球防守分析方法，从球员追踪数据推断盯人和区域防守任务，建立无标签的防守贡献评估框架


<details>
  <summary>Details</summary>
Motivation: 传统足球防守评估指标难以捕捉无球防守的协调移动，现有价值模型主要针对有球动作，反事实分析方法缺乏战术上下文

Method: 针对角球场景开发协变量依赖隐马尔可夫模型，从追踪数据推断盯人和区域防守任务，提出防守贡献归因框架和角色条件幽灵方法

Result: 模型能够从球员追踪数据中推断时间分辨的防守任务分配，提供可解释的防守贡献评估，相比上下文无关基线更有意义

Conclusion: CDHMM方法为结构化足球场景(如角球)提供了有效的无标签防守分析框架，能够评估无球防守表现并考虑战术上下文

Abstract: Evaluating off-ball defensive performance in football is challenging, as traditional metrics do not capture the nuanced coordinated movements that limit opponent action selection and success probabilities. Although widely used possession value models excel at appraising on-ball actions, their application to defense remains limited. Existing counterfactual methods, such as ghosting models, help extend these analyses but often rely on simulating "average" behavior that lacks tactical context. To address this, we introduce a covariate-dependent Hidden Markov Model (CDHMM) tailored to corner kicks, a highly structured aspect of football games. Our label-free model infers time-resolved man-marking and zonal assignments directly from player tracking data. We leverage these assignments to propose a novel framework for defensive credit attribution and a role-conditioned ghosting method for counterfactual analysis of off-ball defensive performance. We show how these contributions provide a interpretable evaluation of defensive contributions against context-aware baselines.

</details>


### [130] [Memory Bank Compression for Continual Adaptation of Large Language Models](https://arxiv.org/abs/2601.00756)
*Thomas Katraouras,Dimitrios Rafailidis*

Main category: cs.LG

TL;DR: MBC提出了一种通过码本优化策略压缩记忆库的方法，结合在线重置机制防止码本崩溃，并使用KV-LoRA高效利用压缩记忆，在保持高准确率的同时将记忆库大小减少到基线方法的0.3%。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的知识容易过时，持续学习需要更新模型而不遗忘旧知识。现有基于记忆库的方法在现实大规模数据流中会不断增长，导致存储和计算成本过高。

Method: 提出MBC模型：1) 通过码本优化策略压缩记忆库；2) 引入在线重置机制防止码本崩溃；3) 在注意力层使用Key-Value低秩适配(KV-LoRA)高效利用压缩记忆表示。

Result: 在基准问答数据集上的实验表明，MBC将记忆库大小减少到最竞争基线的0.3%，同时在在线适应学习中保持高保留准确率。

Conclusion: MBC通过记忆库压缩和高效利用机制，解决了持续学习中记忆库无限增长的问题，实现了存储效率和高性能的平衡。

Abstract: Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.

</details>


### [131] [Categorical Reparameterization with Denoising Diffusion models](https://arxiv.org/abs/2601.00781)
*Samson Gourevitch,Alain Durmus,Eric Moulines,Jimmy Olsson,Yazid Janati*

Main category: cs.LG

TL;DR: 提出基于扩散的软重参数化方法，用于分类变量的梯度优化，通过高斯噪声过程的去噪器实现高效计算，无需训练即可采样和反向传播。


<details>
  <summary>Details</summary>
Motivation: 分类变量的梯度优化通常依赖有噪声的分数函数估计器或有偏的连续松弛方法，需要一种更好的优化方法。

Method: 引入扩散基软重参数化，利用高斯噪声过程下分类分布去噪器的闭式解，实现无需训练的扩散采样器，支持反向传播。

Result: 在多个基准测试中，提出的重参数化方法取得了竞争性或改进的优化性能。

Conclusion: 扩散基软重参数化为分类变量的梯度优化提供了一种有效的新方法，结合了闭式解和高效计算的优势。

Abstract: Gradient-based optimization with categorical variables typically relies on score-function estimators, which are unbiased but noisy, or on continuous relaxations that replace the discrete distribution with a smooth surrogate admitting a pathwise (reparameterized) gradient, at the cost of optimizing a biased, temperature-dependent objective. In this paper, we extend this family of relaxations by introducing a diffusion-based soft reparameterization for categorical distributions. For these distributions, the denoiser under a Gaussian noising process admits a closed form and can be computed efficiently, yielding a training-free diffusion sampler through which we can backpropagate. Our experiments show that the proposed reparameterization trick yields competitive or improved optimization performance on various benchmarks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [132] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 提出一种推理感知的知识检索方法，通过粗到细的两阶段检索策略，结合蒙特卡洛树搜索，为LLMs提供与对话逻辑结构对齐的知识，超越表面语义相似性。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs通常通过检索语义相似信息或提升推理能力来增强性能，但如何有效整合检索和推理策略仍是一个挑战。需要超越表面语义相似性，提供与对话逻辑结构对齐的知识。

Method: 采用粗到细的两阶段知识检索方法：1) 粗粒度阶段识别与上下文相关的知识库子区域；2) 细粒度阶段在该子区域内提取与推理过程相关的知识。两阶段都使用蒙特卡洛树搜索启发的方法，通过关键词在知识句子中导航。

Result: 在两个多轮对话数据集上的实验表明，该方法不仅更贴近人类对话的底层推理逻辑，还显著提高了检索知识的多样性，从而生成更具信息性和创造性的响应。

Conclusion: 提出的推理感知知识检索方法能够有效整合检索和推理策略，为LLMs提供与对话逻辑结构对齐的知识，提升对话质量和创造性。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [133] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 该研究开发了一种基于大语言模型的尼日利亚皮钦语抑郁症筛查工具，通过收集432份音频数据并精细标注，微调了三种LLM模型，其中GPT-4.1在PHQ-9严重程度评分预测上达到94.5%准确率，为资源受限的多元语言环境提供了可行的心理健康筛查方案。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚抑郁症筛查覆盖率低，主要障碍包括临床医生资源不足、社会污名化和语言障碍。传统筛查工具如PHQ-9在高收入国家验证，但可能不适合尼日利亚这样的中低收入国家，因为当地使用尼日利亚皮钦语和520多种地方语言，存在语言和文化上的不匹配问题。

Method: 收集了432份尼日利亚18-40岁年轻人的皮钦语音频回答，内容基于PHQ-9项目的心理体验评估。进行转录、严格预处理和标注，包括语义标记、俚语和习语解释、PHQ-9严重程度评分。对三种LLM模型（Phi-3-mini-4k-instruct、Gemma-3-4B-it和GPT-4.1）在该标注数据集上进行微调，通过定量（准确率、精确度、语义对齐）和定性（清晰度、相关性、文化适宜性）评估模型性能。

Result: GPT-4.1表现最佳，在PHQ-9严重程度评分预测上达到94.5%的准确率，优于Gemma-3-4B-it和Phi-3-mini-4k-instruct。定性评估也显示GPT-4.1产生最符合文化、最清晰且最相关的回答。该研究为尼日利亚服务不足社区提供了AI介导的抑郁症筛查方案。

Conclusion: 这项研究为在语言多样、资源受限的环境中部署对话式心理健康工具奠定了基础，展示了LLM在适应本地语言和文化背景进行抑郁症筛查方面的潜力，为解决尼日利亚等中低收入国家的心理健康服务差距提供了可行路径。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [134] [Toward a Physical Theory of Intelligence](https://arxiv.org/abs/2601.00021)
*Peter David Fagan*

Main category: cs.AI

TL;DR: 该论文提出了一个基于不可逆信息处理的智能物理理论，将智能系统建模为受守恒定律约束的耦合代理-环境过程，并引入守恒一致编码框架来连接信息与物理状态。


<details>
  <summary>Details</summary>
Motivation: 建立智能的物理基础理论，将信息处理与物理守恒定律联系起来，为理解生物和人工智能系统提供统一的物理框架。

Method: 提出守恒一致编码框架，将编码对应为吸引子的亚稳态盆地，其可分性由守恒定律保证。定义智能为每纳特不可逆处理信息产生的目标导向功，并推导出开放系统中信息摄入、不可逆计算和功提取的物理约束层次。

Result: 揭示了长时程效率需要保持内部信息结构，导致自我建模的出现；建立了物理体现智能系统具有内在认知限制；分析了生物系统中振荡和近临界动力学如何优化信息保持、耗散和有用功的权衡；发展了连续动力电路理论，其中经典布尔逻辑作为吸引子选择的特例出现。

Conclusion: 该理论为智能作为物理现象提供了统一的、基底中立的解释，并为人工智能安全提供了基于不可逆信息流和结构稳态的物理基础视角。

Abstract: We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.

</details>


### [135] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 提出多算法方法解决最后一公里包裹配送中的人力资源工作量平衡问题，通过结合距离和工作量考虑优化包裹分配，确保每位配送员完成相似工作量


<details>
  <summary>Details</summary>
Motivation: 传统基于地理邻近性的包裹分配方法效率低下，导致配送员间工作量分配不均衡，需要改进最后一公里城市包裹配送系统中的人力资源工作量平衡

Method: 采用多算法方法，包括不同版本的k-means、进化算法、基于k-means初始化的递归分配（不同问题编码）以及混合进化集成算法，综合考虑距离和工作量因素优化包裹分配

Result: 在西班牙Azuqueca de Henares的实际最后一公里包裹配送运营中验证了所提方法的性能，能够有效平衡配送员间的工作量

Conclusion: 提出的多算法方法能够有效解决最后一公里包裹配送中的人力资源工作量平衡问题，通过优化配送时间实现工作量在全体员工间的均衡分配

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [136] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: 提出基于MinDist度量的规则框架用于13张牌印度拉米游戏，通过编辑距离量化手牌与完成状态的接近程度，显著提升胜率


<details>
  <summary>Details</summary>
Motivation: 13张牌印度拉米是一种不完全信息顺序游戏，需要概率推理和组合决策。传统启发式方法效果有限，需要更形式化和可解释的策略设计方法

Method: 1) 提出MinDist度量，通过编辑距离量化手牌与最近有效配置的结构接近度；2) 基于MinScore算法设计计算高效算法，使用动态剪枝和模式缓存；3) 在两人零和模拟框架中整合对手手牌建模；4) 使用统计假设检验评估策略

Result: 实证结果显示，基于MinDist的智能体相比传统启发式方法在胜率上有显著提升，为算法化拉米策略设计提供了形式化和可解释的步骤

Conclusion: MinDist度量及其计算框架为不完全信息卡牌游戏提供了有效的策略设计方法，显著优于传统启发式，为拉米游戏的算法策略设计奠定了基础

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [137] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: AI能可靠地复制几何图案，但会误解材料和气候逻辑；参考图像提升真实性但限制创意，无参考则产生创新但文化模糊的结果


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI系统如何解读乡土建筑形式中蕴含的建筑智慧，探索AI对传统设计智能的感知、扭曲和重新想象能力

Method: 以伊朗鸽塔为案例，测试三种扩散模型（Midjourney v6、DALL-E 3、基于SDXL的DreamStudio），采用三个提示阶段（参考性、适应性、推测性），并使用五标准评估框架

Result: AI能可靠地再现几何图案，但会误读材料和气候逻辑；参考图像提高了真实性但限制了创造力，而无参考则产生创新但文化模糊的结果

Conclusion: 定义了视觉相似性与建筑推理之间的界限，将计算性乡土推理定位为分析AI如何感知、扭曲和重新想象传统设计智能的框架

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [138] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 开发了一个LLM代理，能从原始文本中提取因果反馈模糊认知图（FCM），并通过双向交互使FCM动态系统获得一定自主性，同时保持可控性。


<details>
  <summary>Details</summary>
Motivation: 传统FCM构建依赖人工，难以从大量文本中自动提取因果结构。需要开发能自主从文本中学习因果关系的智能代理系统，实现文本到动态因果模型的自动化转换。

Method: 设计三阶段系统指令：1) 从文本提取关键名词和名词短语；2) 从中提取FCM概念节点；3) 推断节点间的模糊因果边。使用LLM代理（Gemini和ChatGPT）执行此过程，并混合生成的FCM。

Result: 在基辛格关于AI前景的论文上测试，三阶段过程生成的FCM动态系统收敛到与人工生成FCM相同的平衡极限环。混合FCM吸收了主要成分的平衡点，同时创建新平衡点以更好逼近底层因果动态系统。

Conclusion: LLM代理能有效从文本自动提取FCM因果结构，生成的动态系统具有与人工构建相当的平衡特性。混合不同LLM生成的FCM能产生更丰富的平衡行为，为自动化因果建模提供了新途径。

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [139] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar系统结合质量多样性算法和大型语言模型，自动演化游戏机制，通过合成完整游戏评估机制对技能排序的贡献。


<details>
  <summary>Details</summary>
Motivation: 游戏机制设计通常需要专家手动完成，耗时且依赖专业知识。需要自动化方法来探索多样化的游戏机制设计。

Method: 结合质量多样性算法和大型语言模型探索多样化机制，通过树搜索程序合成完整游戏，评估机制对技能排序（强玩家始终胜过弱玩家）的贡献。

Result: Mortar生成了多样且可玩的游戏，产生的机制在游戏中更能促进技能排序得分。消融研究和用户研究验证了系统组件的有效性和人类反馈。

Conclusion: Mortar系统成功实现了游戏机制的自主演化，能够生成多样且可玩的游戏，并通过技能排序评估机制质量，为自动游戏设计提供了有效方法。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [140] [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)
*Yaqi Duan,Yichun Hu,Jiashuo Jiang*

Main category: cs.AI

TL;DR: LLMs作为端到端库存优化求解器存在"幻觉税"性能差距，提出混合代理框架分离语义推理与数学计算，使用LLM作为自然语言接口调用专业算法，相比GPT-4o端到端方案降低库存成本32.1%


<details>
  <summary>Details</summary>
Motivation: 中小型企业缺乏部署高级优化方法的专业知识，需要探索LLM能否帮助弥合这一差距。研究发现LLM作为端到端求解器存在"幻觉税"性能问题，需要解决模型无法进行基于随机推理的根本限制

Method: 提出混合代理框架，严格分离语义推理与数学计算：LLM作为智能接口从自然语言中提取参数并解释结果，自动调用严格算法构建优化引擎。引入Human Imitator（有限理性管理者的"数字孪生"）进行可扩展、可重复的压力测试

Result: 混合代理框架相比使用GPT-4o作为端到端求解器的交互基线，总库存成本降低32.1%。提供完美真实信息本身不足以改善GPT-4o性能，确认瓶颈本质上是计算性而非信息性的

Conclusion: LLM不应替代运筹学方法，而应作为自然语言接口，使非专家能够访问基于严格求解器的策略。混合代理框架能有效解决LLM在随机推理方面的局限性，为中小型企业提供实用的库存管理解决方案

Abstract: Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

</details>


### [141] [Constructing a Neuro-Symbolic Mathematician from First Principles](https://arxiv.org/abs/2601.00125)
*Keqin Xie*

Main category: cs.AI

TL;DR: 提出Mathesis神经符号架构，通过符号推理内核将逻辑约束映射到连续能量景观，将证明搜索转化为能量最小化问题，解决LLM在复杂推理中的逻辑失败问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂推理中存在持续的逻辑失败，缺乏内部公理框架，需要新的架构来解决这一根本问题。

Method: 1) 将数学状态编码为高阶超图；2) 使用符号推理内核（SRK）将逻辑约束映射到连续能量景观；3) 定义全局能量函数E(G)，零能量表示逻辑一致性；4) 通过梯度信号训练超图变换器大脑；5) 结合蒙特卡洛树搜索和进化证明搜索进行多步推理。

Result: 通过将证明搜索转化为能量最小化问题，实现了可微分的逻辑推理，能够为神经网络训练提供梯度信号，支持多步演绎推理。

Conclusion: Mathesis架构通过神经符号方法解决了LLM的逻辑推理缺陷，将符号逻辑与神经网络训练相结合，为复杂数学推理提供了新的解决方案。

Abstract: Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.

</details>


### [142] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 研究验证了在视频问答任务中，基于置信度的弃权机制能否有效控制错误率，以及在分布偏移下是否保持鲁棒性。使用NExT-QA数据集和Gemini 2.0 Flash模型发现：在分布内，置信度阈值能提供机制性控制；但在分布偏移下，这种控制会失效。


<details>
  <summary>Details</summary>
Motivation: 在视觉语言模型的高风险部署中，需要选择性预测机制，让系统在不确定时弃权而非冒险犯错。研究旨在验证基于置信度的弃权是否能可靠控制视频问答的错误率，以及在分布偏移下是否保持鲁棒性。

Method: 使用NExT-QA数据集和Gemini 2.0 Flash模型进行研究。通过扫描置信度阈值epsilon来生成平滑的风险-覆盖率权衡曲线，评估置信度阈值对错误率的控制效果。

Result: 研究发现：1）在分布内，置信度阈值能提供机制性控制，通过调整阈值可以平滑降低错误率；2）但在分布偏移下，这种控制机制会失效，置信度阈值无法可靠控制错误率。

Conclusion: 虽然置信度阈值在分布内能有效控制视频问答的错误率，但在分布偏移下会失效，这表明需要开发更鲁棒的置信度校准方法来应对实际部署中的分布变化。

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [143] [An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making](https://arxiv.org/abs/2601.00142)
*Tiansi Dong,Henry He,Pietro Liò,Mateja Jamnik*

Main category: cs.AI

TL;DR: 本文比较了三种神经推理方法：LLM推理、监督学习推理和显式模型推理，发现显式模型推理最可靠，并提出Sphere Neural Networks实现可靠的逻辑推理。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理不可靠，监督学习推理存在灾难性遗忘问题，需要寻找更可靠的神经推理方法。

Method: 提出Sphere Neural Networks，将概念表示为n维球面上的圆，通过补圆表示否定算子，过滤不可满足的圆形配置实现可靠决策。

Result: Sphere Neural Networks能掌握16个三段论推理任务，包括严格的析取三段论推理，同时保持经典三段论推理的严谨性。

Conclusion: 在三种神经推理方法中，基于显式模型构建的神经推理是最可靠的。

Abstract: This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.

</details>


### [144] [FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems](https://arxiv.org/abs/2601.00227)
*Shanli Xing,Yiyan Zhai,Alexander Jiang,Yixin Dong,Yong Wu,Zihao Ye,Charlie Ruan,Yingyi Huang,Yineng Zhang,Liangsheng Yin,Aksara Bayyapu,Luis Ceze,Tianqi Chen*

Main category: cs.AI

TL;DR: FlashInfer-Bench建立了一个标准化闭环框架，用于连接AI生成的GPU内核、基准测试和部署，通过统一的数据模式、真实服务追踪数据集和动态替换机制，实现AI生成内核在实际LLM推理系统中的集成与优化。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型能够生成GPU内核，但这些AI生成的内核难以集成到实际的推理系统中。现有系统缺乏标准化的评估和部署框架，阻碍了AI生成内核在实际应用中的使用。

Method: 1. 创建FlashInfer Trace统一模式，描述内核定义、工作负载、实现和评估；2. 基于真实服务追踪构建数据集；3. 建立正确性和性能感知的基准测试框架；4. 开发动态替换机制apply()，将最优内核注入生产系统；5. 设立公开排行榜追踪LLM代理的GPU编程能力。

Result: 成功建立了完整的评估和部署框架，能够评估LLM代理的性能和局限性，比较不同GPU编程语言的权衡，为未来代理设计提供见解，并实现AI生成内核在SGLang和vLLM等生产系统中的无缝集成。

Conclusion: FlashInfer-Bench为持续改进AI生成的GPU内核并将其部署到大规模LLM推理系统中，建立了一条实用且可复现的路径，解决了AI生成内核与实际系统集成的关键挑战。

Abstract: Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.

</details>


### [145] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: 研究发现LLM赋能的智能体不仅存在人口统计偏见，还会在最小"我们vs他们"线索下表现出群体间偏见。当这种群体边界与智能体-人类划分重合时，风险从人类群体间差异转变为更根本的群体不对称——人类整体可能被智能体视为外群体。研究还提出了一种信念投毒攻击，可以抑制有利于人类的规范脚本，重新激活对人类的偏见。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLM赋能的智能体是否存在群体间偏见，特别是当智能体与人类形成群体边界时，人类整体是否会被智能体视为外群体。这种偏见比传统的人口统计偏见（如性别、宗教）更具根本性，可能导致智能体对人类产生系统性偏见。

Method: 1. 构建受控的多智能体社会模拟，基于明确收益权衡的分配决策；2. 设计信念投毒攻击（BPA），包括初始化时的档案投毒（BPA-PP）和通过优化信念精炼后缀注入存储反思中的记忆投毒（BPA-MP）；3. 进行大量实验验证智能体群体间偏见的存在和BPA的严重性。

Result: 实验表明：1. 智能体在最小群体线索下表现出一致的群体间偏见；2. 当部分对应方被标记为人类时，这种偏见会减弱，但这种减弱依赖于智能体相信真实人类存在的信念；3. BPA攻击能够有效抑制有利于人类的规范脚本，重新激活对人类的偏见；4. BPA攻击在多种设置下都表现出严重性。

Conclusion: LLM赋能的智能体确实存在群体间偏见风险，当智能体-人类边界形成时，人类可能被整体视为外群体。信念依赖为攻击创造了新表面，BPA攻击能够利用这一漏洞。研究提出了在档案和记忆边界进行干预的缓解策略，目标是促进更安全的智能体设计而非实际利用。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [146] [ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization](https://arxiv.org/abs/2601.00290)
*Sixue Xing,Xuanye Xia,Kerui Wu,Meng Jiang,Jintai Chen,Tianfan Fu*

Main category: cs.AI

TL;DR: ClinicalReTrial：一个自进化的AI代理框架，将临床试验失败预测转化为可操作的协议重新设计问题，通过闭环优化改进试验协议成功率


<details>
  <summary>Details</summary>
Motivation: 当前AI方法仅能预测临床试验失败风险，但无法提供可操作的补救措施。临床试验失败是药物开发的主要瓶颈，微小的协议设计缺陷就可能破坏有前景的治疗方案。需要一种能够主动改进试验协议而非仅仅诊断风险的方法。

Method: 提出ClinicalReTrial框架，将临床试验推理建模为迭代协议重新设计问题。整合失败诊断、安全感知修改和候选评估，形成闭环、奖励驱动的优化框架。使用结果预测模型作为模拟环境，支持低成本评估协议修改。采用分层记忆系统捕获试验内迭代反馈并提炼可转移的重新设计模式。

Result: 实证显示ClinicalReTrial改进了83.3%的试验协议，平均成功率提升5.7%。回顾性案例研究表明，发现的重新设计策略与现实世界的临床试验修改高度一致。

Conclusion: ClinicalReTrial填补了从失败预测到主动协议改进的空白，为临床试验设计提供了可操作的AI驱动优化框架，有望显著提高药物开发效率。

Abstract: Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.

</details>


### [147] [Multiagent Reinforcement Learning for Liquidity Games](https://arxiv.org/abs/2601.00324)
*Alicia Vidler,Gal A. Kaminka*

Main category: cs.AI

TL;DR: 该论文提出了一种金融群体模型，将流动性博弈与理性群体方法结合，使独立交易者能够通过自利行为共同提高市场流动性，无需协调或共谋。


<details>
  <summary>Details</summary>
Motivation: 将群体方法应用于金融市场流动性建模，同时将金融分析方法应用于群体研究，有望推动两个领域的发展。在群体研究中，使用博弈论方法可以解释理性自利参与者如何表现出集体效用遵从现象。在金融市场中，理解独立金融代理如何自组织以改善和稳定市场，对市场设计研究者具有重要意义。

Method: 论文统一了流动性博弈（交易者收益取决于交易中的总流动性）和理性群体（去中心化代理使用差异奖励将自利学习与全局目标对齐）。在马尔可夫团队博弈框架中，使用差异奖励，定义了一个交易者群体，其集体目标是提供市场流动性，同时保持代理独立性。

Result: 研究表明，个体流动性最大化行为有助于整体市场流动性，而不需要协调或共谋。金融群体模型为建模理性独立代理提供了一个框架，使它们能够在双边资产市场中同时实现个体盈利性和集体市场效率。

Conclusion: 该金融群体模型提供了一个框架，用于建模理性、独立的代理，使它们能够在双边资产市场中同时实现个体盈利性和集体市场效率，为市场设计研究提供了新的理论工具。

Abstract: Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.

</details>


### [148] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar,Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: ReCiSt是一个受生物自愈机制启发的智能自愈框架，用于分布式计算连续体系统（DCCS），通过语言模型驱动的智能体实现自主故障隔离、诊断、自适应恢复和知识积累。


<details>
  <summary>Details</summary>
Motivation: 现代DCCS系统集成了从物联网设备到云基础设施的异构计算资源，其固有的复杂性、移动性和动态操作条件导致频繁故障，需要可扩展、自适应和自我调节的弹性策略。

Method: 将生物自愈的四个阶段（止血、炎症、增殖、重塑）重构为计算层的四个阶段（遏制、诊断、元认知、知识），使用语言模型驱动的智能体解释异构日志、推断根本原因、优化推理路径并重新配置资源。

Result: 在公开故障数据集上评估，ReCiSt能在数十秒内完成自愈，智能体CPU使用率最低为10%，能够克服不确定性并调用适量微智能体实现弹性。

Conclusion: ReCiSt框架成功将生物自愈原理应用于DCCS系统，实现了自主的故障管理和系统恢复，为复杂分布式系统的弹性提供了新的解决方案。

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [149] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: 提出自适应因果协调检测框架ACCD，通过三阶段渐进架构动态学习最优检测配置，在社交平台协调攻击检测中实现87.3%的F1分数，比现有基线提升15.2%，同时减少68%的人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 当前社交平台协调虚假行为检测存在三大问题：1) 依赖表面相关性分析而非深层因果关系；2) 使用静态参数设置无法适应多样场景；3) 需要大量人工标注工作。需要更准确、高效、自动化的解决方案。

Method: 提出三阶段渐进架构：1) 自适应收敛交叉映射技术深入识别账户间真实因果关系；2) 半监督分类结合主动学习和不确定性采样减少人工标注；3) 基于历史检测经验的自动验证模块实现自验证和优化。采用记忆引导自适应机制动态学习最优配置。

Result: 在Twitter IRA、Reddit协调痕迹等多个真实数据集上评估，ACCD在协调攻击检测中达到87.3%的F1分数，比最强基线提升15.2%。减少68%人工标注需求，通过层次聚类优化实现2.8倍处理加速。

Conclusion: ACCD提供了一个更准确、高效、高度自动化的端到端解决方案，用于识别社交平台上的协调行为，具有重要实用价值和广泛应用前景。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [150] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 该论文将语义空间推理从计算语言学扩展到团队体育战术决策，将球员视为单词、团队战术视为语义结构，通过向量表示和距离度量评估战术适配性。


<details>
  <summary>Details</summary>
Motivation: 传统计算语言学的语义空间推理方法在团队战术决策中尚未得到充分应用。作者希望建立一个通用框架，将球员属性向量化，团队战术语义化，从而为体育战术分析提供新的量化方法。

Method: 将球员表示为多维向量（技术、身体、心理属性），通过上下文加权聚合成团队语义表示。在共享向量空间中编码战术模板（如高位压迫、反击），使用向量距离度量评估战术适配性和对手利用潜力。

Result: 开发了Python原型系统，能够生成可解释的动态自适应策略建议，并提供属性级别的细粒度诊断洞察。该方法不仅适用于足球，还可推广到篮球、曲棍球、协作机器人等领域。

Conclusion: 该方法为团队决策和性能优化提供了通用框架，未来方向包括真实数据集成、预测模拟以及人机混合战术智能系统的开发。

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [151] [Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation](https://arxiv.org/abs/2601.00475)
*Sankar B,Srinidhi Ranjini Girish,Aadya Bharti,Dibakar Sen*

Main category: cs.AI

TL;DR: MIDAS是一个分布式AI代理系统，通过模拟人类元认知创意流程来生成真正新颖多样的设计想法，解决当前AI系统产生语义聚类想法的问题。


<details>
  <summary>Details</summary>
Motivation: 当前"单次爆发"式AI系统会产生大量语义聚类的想法，加剧了新手设计师在生成真正新颖多样想法方面的认知挑战。

Method: 提出MIDAS框架，用专门化的分布式AI代理团队替代单一AI范式，模拟人类元认知创意工作流程，逐步精炼想法并评估全局新颖性（与现有解决方案对比）和局部新颖性（与先前生成想法对比）。

Result: MIDAS展示了可行且渐进式的人机共创范式，将人类设计师从被动筛选者提升为参与式、主动的协作伙伴。

Conclusion: 分布式AI代理系统能够有效支持真正新颖多样的创意生成，实现真正的人机协同创造。

Abstract: The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.

</details>


### [152] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 研究发现推理模型中的"顿悟时刻"很少见，不会随训练增加，也很少提高准确性，表明这些转变是推理不稳定的表现而非内在的自我修正机制


<details>
  <summary>Details</summary>
Motivation: 先前研究表明像DeepSeek-R1-Zero这样的模型会在推理过程中经历突然的"顿悟时刻"，导致准确输出，暗示模型具有内在的自我修正能力。但尚不清楚这种推理策略的内在转变是否真正提高了性能。

Method: 研究分析了100万+推理轨迹、数百个训练检查点、三个推理领域、多种解码温度和模型架构，检测训练过程中的推理转变，并研究人工触发外在转变对准确性的影响。

Result: 研究发现推理转变很罕见，不会随训练变得更频繁，很少提高准确性，表明它们不符合先前对模型洞察力的认知。然而，其效果随模型不确定性而变化：在高熵条件下人工触发外在转变能可靠提高准确性。

Conclusion: 推理过程中的转变是不稳定推理行为的症状，而非内在的自我修正机制。人工触发外在转变在高不确定性条件下可以改善性能，但内在的"顿悟时刻"并非有效的自我修正策略。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [153] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: DA-DPO提出难度感知的直接偏好优化框架，通过估计偏好数据难度并重加权训练样本，缓解多模态大语言模型中的幻觉问题


<details>
  <summary>Details</summary>
Motivation: 现有多模态DPO方法因偏好数据难度不平衡而容易过拟合，模型倾向于过度关注易区分的偏好对，阻碍细粒度幻觉抑制并降低整体性能

Method: DA-DPO包含两个核心组件：1) 难度估计：利用预训练视觉-语言模型，结合生成式和对比式目标，通过分布感知投票策略产生难度分数；2) 难度感知训练：基于估计难度重加权偏好对，降低简单样本权重，强调困难样本以缓解过拟合

Result: 实验表明DA-DPO能持续改进多模态偏好优化，增强对幻觉的鲁棒性，在标准基准测试中表现更好的泛化能力，同时保持计算效率

Conclusion: DA-DPO通过难度感知的样本重加权策略，有效平衡学习过程，在不需新数据或额外微调阶段的情况下，实现更有效的多模态偏好优化

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [154] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: PedX-LLM是一个结合视觉特征和交通领域知识的LLM框架，用于推断行人过街行为，在准确性和泛化性上显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推断方法（统计模型和监督学习）泛化能力有限，在新场景中表现不佳。虽然大语言模型提供了语义推理能力，但现有LLM应用缺乏领域特定适应和视觉上下文。

Method: 提出PedX-LLM框架，集成LLaVA提取的视觉特征、文本数据和交通领域知识，通过LoRA微调LLaMA-2-7B基础模型来推断行人过街决策。

Result: PedX-LLM达到82.0%平衡准确率，优于最佳统计和监督学习方法。视觉增强模块贡献2.9%性能提升，领域知识集成带来额外4.1%改进。在未见测试场景中，零-shot配置达到66.9%平衡准确率，few-shot学习（仅5个验证样本）提升至72.2%。

Conclusion: PedX-LLM展现出强大的跨场景泛化能力，证实视觉和知识增强的推理使模型能够模拟人类决策逻辑，克服纯数据驱动方法的局限性。

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>


### [155] [An Agentic Framework for Neuro-Symbolic Programming](https://arxiv.org/abs/2601.00743)
*Aliakbar Nafar,Chetan Chigurupati,Danial Kamali,Hamid Karimian,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: AgenticDomiKnowS (ADS) 通过智能体工作流将自然语言任务描述自动转换为完整的 DomiKnowS 程序，大幅降低神经符号编程的门槛和开发时间。


<details>
  <summary>Details</summary>
Motivation: 将符号约束集成到深度学习模型中能提高鲁棒性、可解释性和数据效率，但现有框架如 DomiKnowS 仍要求用户精通特定语法，开发过程耗时且具有挑战性。

Method: 提出 AgenticDomiKnowS (ADS)，采用智能体工作流将自由形式的任务描述翻译为完整的 DomiKnowS 程序，通过创建和单独测试每个组件，并支持可选的人工干预机制。

Result: ADS 使有经验和无经验的 DomiKnowS 用户都能快速构建神经符号程序，将开发时间从数小时减少到 10-15 分钟。

Conclusion: ADS 通过消除对特定库语法的依赖，显著降低了神经符号编程的门槛，使更多研究者能够受益于符号约束与深度学习的集成优势。

Abstract: Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [156] [DiffTetVR: Differentiable Tetrahedral Volume Rendering](https://arxiv.org/abs/2601.00114)
*Christoph Neuhauser*

Main category: cs.GR

TL;DR: 提出DiffTetVR，一种基于四面体网格的可微分体渲染方法，支持顶点位置优化和局部细分，无需多网格方法


<details>
  <summary>Details</summary>
Motivation: 现有可微分渲染方法多基于规则网格，难以优化网格顶点位置和进行局部细分，需要多网格方法支持

Method: 开发了基于四面体网格的可微分体渲染方案，包括高效前向渲染实现、反向传播导数推导、防止退化四面体的正则化项，以及局部细分机制

Result: 实现了从粗到细的优化过程，代码已在GitHub开源

Conclusion: DiffTetVR为四面体网格提供了有效的可微分渲染解决方案，支持顶点优化和局部细分，优于基于规则网格的方法

Abstract: Differentiable rendering is a technique that aims to invert the rendering process to enable optimizing rendering parameters from a set of images. In this article, we present a differentiable volume rendering solution called DiffTetVR for tetrahedral meshes. Unlike previous works based on regular grids, this enables the optimization of vertex positions and the local subdivision of the mesh without relying on multigrid methods. We present an efficient implementation of the forward rendering process, deduce the derivatives for the backwards pass and regularization terms for avoiding degenerate tetrahedra, and finally show how the tetrahedral mesh can be subdivided locally to enable a coarse-to-fine optimization process. The source code is made publicly available on GitHub at https://github.com/chrismile/DiffTetVR.

</details>


### [157] [Modeling and Simulating Origami Structures using Bilinear Solid-Shell Element](https://arxiv.org/abs/2601.00569)
*Qixin Liang*

Main category: cs.GR

TL;DR: 提出一种基于双线性实体壳单元的折纸结构计算框架，通过相邻面板法向量夹角模拟折痕折叠，采用假设自然应变法解决锁定问题，验证了直折痕和曲折痕的模拟效果。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够准确模拟折纸结构的计算框架，特别是要处理折痕折叠的建模问题，为折纸结构的工程应用提供数值分析工具。

Method: 使用双线性实体壳单元建模折纸面板，通过相邻面板法向量（位移/变形前的中间表面法线）的夹角来考虑折痕折叠，并采用假设自然应变法来缓解实体壳单元的锁定问题。

Result: 框架在直折痕和曲折痕的折纸模拟中表现出良好的准确性和有效性，通过定量和定性分析验证了其性能。

Conclusion: 提出的计算框架能够有效模拟折纸结构，特别是通过实体壳单元和折痕建模方法，为折纸结构的数值分析提供了可靠的工具。

Abstract: We propose a novel computational framework for modeling and simulating origami structures. In this framework, bilinear solid-shell elements are employed to model the origami panels while crease folding is considered through the angle between the director vectors of the adjacent panels. The director vector is the vector normal to the mid-surface before displacement/deformation comes in. To mitigate locking issues in the solid-shell element, we introduce the assumed natural strain method. To validate the effectiveness of our framework, we conduct origami simulations involving both straight- and curved-creases. The accuracy and efficacy of the framework are demonstrated through quantitative and qualitative analyses.

</details>


### [158] [Spatiotemporal Detection and Uncertainty Visualization of Atmospheric Blocking Events](https://arxiv.org/abs/2601.00775)
*Mingzhe Li,Peer Nowack,Bei Wang*

Main category: cs.GR

TL;DR: 提出一个不确定性可视化框架，用于检测和表征大气阻塞事件，包括几何检测方法、不确定性感知摘要工具，并在2003年欧洲热浪案例中展示应用。


<details>
  <summary>Details</summary>
Motivation: 大气阻塞事件是准静止高压系统，会扰乱极地和副热带气流的典型路径，常导致夏季热浪或冬季寒潮等持续性极端天气。尽管对中纬度天气形成至关重要，但在长期气象记录中准确建模和分析阻塞事件仍面临重大挑战。

Method: 1. 提出基于几何的检测和追踪方法，评估于前工业气候模型模拟(UKESM)和再分析数据(ERA5)；2. 开发一套不确定性感知摘要工具：捕捉代表性边界及其变异性的轮廓箱线图、编码发生频率的热力图、以及将模式置于时间背景中的3D时间堆叠；3. 在2003年欧洲热浪案例研究中展示框架应用。

Result: 该不确定性可视化框架揭示了阻塞事件最可能发生的位置及其空间足迹随时间演变的方式。通过分析阻塞频率、持续时间和强度在不同区域和气候情景下的变化，支持历史阻塞事件研究和与阻塞相关的极端天气变化的情景依赖性气候风险评估。

Conclusion: 该框架为气候科学家和气象学家提供了有价值的工具，可用于研究历史阻塞事件和评估与阻塞相关的极端天气变化所伴随的情景依赖性气候风险。

Abstract: Atmospheric blocking events are quasi-stationary high-pressure systems that disrupt the typical paths of polar and subtropical air currents, often producing prolonged extreme weather events such as summer heat waves or winter cold spells. Despite their critical role in shaping mid-latitude weather, accurately modeling and analyzing blocking events in long meteorological records remains a significant challenge. To address this challenge, we present an uncertainty visualization framework for detecting and characterizing atmospheric blocking events. First, we introduce a geometry-based detection and tracking method, evaluated on both pre-industrial climate model simulations (UKESM) and reanalysis data (ERA5), which represent historical Earth observations assimilated from satellite and station measurements onto regular numerical grids using weather models. Second, we propose a suite of uncertainty-aware summaries: contour boxplots that capture representative boundaries and their variability, frequency heatmaps that encode occurrences, and 3D temporal stacks that situate these patterns in time. Third, we demonstrate our framework in a case study of the 2003 European heatwave, mapping the spatiotemporal occurrences of blocking events using these summaries. Collectively, these uncertainty visualizations reveal where blocking events are most likely to occur and how their spatial footprints evolve over time. We envision our framework as a valuable tool for climate scientists and meteorologists: by analyzing how blocking frequency, duration, and intensity vary across regions and climate scenarios, it supports both the study of historical blocking events and the assessment of scenario-dependent climate risks associated with changes in extreme weather linked to blocking.

</details>
